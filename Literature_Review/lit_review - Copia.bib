@article{takami_flanagan_dai_ogata_2023, title={Personality-based tailored explainable recommendation for trustworthy smart learning system in the age of artificial intelligence}, volume={10}, ISSN={2196-7091}, DOI={10.1186/s40561-023-00282-6}, number={1}, journal={Smart Learning Environments}, publisher={Smart Learning Environments}, author={Takami, Kyosuke and Flanagan, Brendan and Dai, Yiling and Ogata, Hiroaki}, year={2023} }

@article{lin_zhang_lin_zeng_zhou_wu_2024, title={Knowledge-aware reasoning with self-supervised reinforcement learning for explainable recommendation in MOOCs}, volume={36}, ISSN={0941-0643}, DOI={10.1007/s00521-023-09257-7}, number={8}, journal={Neural Computing and Applications}, publisher={Neural Computing and Applications}, author={Lin, Yuanguo and Zhang, Wei and Lin, Fan and Zeng, Wenhua and Zhou, Xiuze and Wu, Pengcheng}, year={2024}, pages={4115–4132} }

@inbook{zanon_da_rocha_manzato_2024, title={Model-Agnostic Knowledge Graph Embedding Explanations for Recommender Systems}, ISSN={1865-0929}, DOI={10.1007/978-3-031-63797-1_1}, booktitle={Communications in Computer and Information Science}, publisher={Communications in Computer and Information Science}, author={Zanon, André Levi and Da Rocha, Leonardo Chaves Dutra and Manzato, Marcelo Garcia}, year={2024}, pages={3–27} }

@inbook{samih_ghadi_fennan_2023, title={Knowledge Embeddings for Explainable Recommendation}, ISSN={2367-3370}, DOI={10.1007/978-3-031-28387-1_11}, booktitle={Lecture Notes in Networks and Systems}, publisher={Lecture Notes in Networks and Systems}, author={Samih, Amina and Ghadi, Abderrahim and Fennan, Abdelhadi}, year={2023}, pages={116–126} }

@inbook{li_liu_zhang_kou_liu_qu_2025, title={Integrating User Sentiment and Behavior for Explainable Recommendation}, ISSN={1865-0929}, DOI={10.1007/978-981-96-0055-7_12}, booktitle={Communications in Computer and Information Science}, publisher={Communications in Computer and Information Science}, author={Li, Dong and Liu, Zhicong and Zhang, Qingyu and Kou, Yue and Liu, Tingting and Qu, Haoran}, year={2025}, pages={135–148} }

@article{wen_liu_jing_yu_2024, title={Learning-based counterfactual explanations for recommendation}, volume={67}, ISSN={1674-733X}, DOI={10.1007/s11432-023-3974-2}, number={8}, journal={Science China Information Sciences}, publisher={Science China Information Sciences}, author={Wen, Jingxuan and Liu, Huafeng and Jing, Liping and Yu, Jian}, year={2024} }

@inbook{long_jin_2024, title={Prompt Tuning Models on Sentiment-Aware for Explainable Recommendation}, ISSN={0302-9743}, DOI={10.1007/978-3-031-51671-9_9}, booktitle={Lecture Notes in Computer Science}, publisher={Lecture Notes in Computer Science}, author={Long, Xiuhua and Jin, Ting}, year={2024}, pages={116–132} }

@inbook{balloccu_boratto_fenu_malloci_marras_2024, title={Explainable Recommender Systems with Knowledge Graphs and Language Models}, ISSN={0302-9743}, DOI={10.1007/978-3-031-56069-9_46}, booktitle={Lecture Notes in Computer Science}, publisher={Lecture Notes in Computer Science}, author={Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Malloci, Francesca Maridina and Marras, Mirko}, year={2024}, pages={352–357} }

@inbook{jendal_le_lauw_lissandrini_dolog_hose_2024, title={Hypergraphs with Attention on Reviews for Explainable Recommendation}, ISSN={0302-9743}, DOI={10.1007/978-3-031-56027-9_14}, booktitle={Lecture Notes in Computer Science}, publisher={Lecture Notes in Computer Science}, author={Jendal, Theis E. and Le, Trung-Hoang and Lauw, Hady W. and Lissandrini, Matteo and Dolog, Peter and Hose, Katja}, year={2024}, pages={230–246} }

@inbook{zhong_negre_2022, title={Context-Aware Explanations in Recommender Systems}, ISSN={2367-3370}, DOI={10.1007/978-3-030-98531-8_8}, booktitle={Lecture Notes in Networks and Systems}, publisher={Lecture Notes in Networks and Systems}, author={Zhong, Jinfeng and Negre, Elsa}, year={2022}, pages={76–85} }

@article{alizadeh_noughabi_behkamal_zarrinkalam_kahani_2024, title={Persuasive explanations for path reasoning recommendations}, ISSN={0925-9902}, DOI={10.1007/s10844-024-00896-3}, journal={Journal of Intelligent Information Systems}, publisher={Journal of Intelligent Information Systems}, author={Alizadeh Noughabi, Havva and Behkamal, Behshid and Zarrinkalam, Fattane and Kahani, Mohsen}, year={2024} }

@article{zharova_tsurkov_2024, title={Application of Boosting in Recommender Systems}, volume={63}, ISSN={1064-2307}, DOI={10.1134/s1064230724700680}, number={6}, journal={Journal of Computer and Systems Sciences International}, publisher={Journal of Computer and Systems Sciences International}, author={Zharova, M. A. and Tsurkov, V. I.}, year={2024}, pages={922–940} }

@article{ma_ziegler_2024, title={Investigating meta-intents: user interaction preferences in conversational recommender systems}, volume={34}, ISSN={0924-1868}, DOI={10.1007/s11257-024-09411-3}, number={5}, journal={User Modeling and User-Adapted Interaction}, publisher={User Modeling and User-Adapted Interaction}, author={Ma, Yuan and Ziegler, Jürgen}, year={2024}, pages={1535–1580} }

@inbook{zhang_zhu_wang_2023, title={Neighborhood Constraints Based Bayesian Personalized Ranking for Explainable Recommendation}, ISSN={0302-9743}, DOI={10.1007/978-3-031-25201-3_12}, booktitle={Lecture Notes in Computer Science}, publisher={Lecture Notes in Computer Science}, author={Zhang, Tingxuan and Zhu, Li and Wang, Jie}, year={2023}, pages={166–173} }

@article{zheng_chen_cao_peng_huang_2024, title={Explainable recommendation based on fusion representation of multi-type feature embedding}, volume={80}, ISSN={0920-8542}, DOI={10.1007/s11227-023-05831-x}, number={8}, journal={The Journal of Supercomputing}, publisher={The Journal of Supercomputing}, author={Zheng, Jianxing and Chen, Sen and Cao, Feng and Peng, Furong and Huang, Mingqing}, year={2024}, pages={10370–10393} }

@article{wang_xie_ding_chen_xiang_2025, title={Reinforced logical reasoning over KGs for interpretable recommendation system}, volume={114}, ISSN={0885-6125}, DOI={10.1007/s10994-024-06646-4}, number={4}, journal={Machine Learning}, publisher={Machine Learning}, author={Wang, Shirui and Xie, Bohan and Ding, Ling and Chen, Jianting and Xiang, Yang}, year={2025} }

@article{sang_yang_zhang_liao_2025, title={A user preference knowledge graph incorporating spatio-temporal transfer features for next POI recommendation}, volume={55}, ISSN={0924-669X}, DOI={10.1007/s10489-025-06290-y}, number={6}, journal={Applied Intelligence}, publisher={Applied Intelligence}, author={Sang, Chun-Yan and Yang, Yang and Zhang, Yi-Bo and Liao, Shi-Gen}, year={2025} }

@INPROCEEDINGS{9811151,
  author={Zarzour, Hafed and Alsmirat, Mohammad and Jararweh, Yaser},
  booktitle={2022 13th International Conference on Information and Communication Systems (ICICS)}, 
  title={Using Deep Learning for Positive Reviews Prediction in Explainable Recommendation Systems}, 
  year={2022},
  volume={},
  number={},
  pages={358-362},
  abstract={In the recent years, recommender systems have begun to attract the attention of many online-based companies. While these systems are being developed to provide users with better recommendations, they suffer from the lack of explain-ability. The explainable recommendation systems are developed to solve the problem of why certain products or services are recommended to a particular user. However, less attention has been attracted for predicting positive reviews from the whole data in the context of explainable recommendation. Therefore, in this paper, we focus on developing a model that uses deep learning for predicting positive reviews in explainable recommendation systems. It enables users to get not only intuitive explanations for the recommended items, but also to get more transparency by investigating whether the explanations are positive ones. To evaluate the proposed model, we conduct experiments on a benchmark dataset from Amazon. Experimental results demonstrate the efficacy of the proposed model against the baselines.},
  keywords={Deep learning;Communication systems;Companies;Predictive models;Benchmark testing;Recommender systems;Deep learning;Deep neural network;Recommender system;Explainable recommendation;Machine learning;Prediction model},
  doi={10.1109/ICICS55353.2022.9811151},
  ISSN={2573-3346},
  month={June},}

@INPROCEEDINGS{8622439,
  author={Suzuki, Takafumi and Oyama, Satoshi and Kurihara, Masahito},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data}, 
  year={2018},
  volume={},
  number={},
  pages={3549-3551},
  abstract={Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as "customers who purchased this item also purchased....". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.},
  keywords={Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems},
  doi={10.1109/BigData.2018.8622439},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{10741116,
  author={Tohidi, Nasim and Beheshti, Maedeh},
  booktitle={2024 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Enhanced Explanations in Recommendation Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Recommendation Systems (RSs) play a crucial role in assisting users in making decisions and finding their desired items in various domains, such as movies, music, and hotels. However, their complex algorithms often raise concerns about transparency, fairness, and user trust. To address these challenges, we tried to propose a theoretical approach that combines SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) techniques to enhance the transparency and interpretability of RSs. We present a methodology for applying this approach in the context of movie recommendation, where SHAP values quantify global feature importance, and LIME explanations provide localized insights. This work can contribute to the advancement of transparent and user-centric RSs, with implications for a wide range of applications.},
  keywords={Additives;Filtering;Motion pictures;Modeling;Recommender systems;recommendation system;explainability;interpretability;collaborative filtering},
  doi={10.1109/ISSE63315.2024.10741116},
  ISSN={2687-8828},
  month={Oct},}

@INPROCEEDINGS{10004187,
  author={Xie, Lijie and Jin, Yaqing and Cui, Zhihua and Wang, Lifang},
  booktitle={2022 IEEE International Conference on Networking, Sensing and Control (ICNSC)}, 
  title={Research on Explainable Recommendation Model Based on Knowledge Graph}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to further obtain the best explanation paths and recommendation items that satisfy the preferences of users accurately and efficiently, a many-objective explainable recommendation model GrEA-ERS based on preferences of users is proposed, which designs pruning strategies to delete unsatisfied paths in knowledge graph based on on preferences of users, so as to reduce the search paths. Combined with the many-objective optimization algorithm GrEA, the paths in knowledge graph are used as decision variables, at which different explained paths correspond to different recommended items, and accuracy, diversity, novelty and explainability are optimized to obtain explained paths and their corresponding recommended items. Through extensive experiments, the model GrEA-ERS always outperforms other algorithms in terms of accuracy, novelty, diversity, and explainability.},
  keywords={Knowledge engineering;Semantics;Sensors;Optimization;knowledge graph;recommendation system;explainability;pruning algorithm},
  doi={10.1109/ICNSC55942.2022.10004187},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{9607106,
  author={Vultureanu-Albişi, Alexandra and Bădică, Costin},
  booktitle={2021 25th International Conference on System Theory, Control and Computing (ICSTCC)}, 
  title={Explainable Collaborative Filtering Recommendations Enriched with Contextual Information}, 
  year={2021},
  volume={},
  number={},
  pages={701-706},
  abstract={Today, the most important requirement of intelligent systems is to be able to explain their decisions to the end-user. Fulfilling this requirement is the goal of explainable AI (XAI) that proposes to produce explainable models that enable end-users to understand and trust the models. This research addresses the explainability of the recommendations. This paper presents an explainable recommender system for point of interest recommendations taking into account the context of the user. In our experiments we have used the STS (South Tyrol Suggests) dataset. The following major steps are part of our methodology: i) presenting the dataset, ii) using Restricted Boltzmann Machine based collaborative filtering recommendations, iii) using contextual information, and iv) extracting and presenting explanations for recommendations based on contextual information. The novelty that we propose in explainable recommender systems is a new explainable recommendation technique, which is quantitative and qualitative, providing both the list of top-n recommendations and the explanations of the recommendations based on context. This paper also provides an overview of research on this topic.},
  keywords={Collaborative filtering;Computational modeling;Neural networks;Information filters;Control systems;Data mining;Usability;recommender systems;collaborative filtering;Restricted Boltzmann Machine;contextual information},
  doi={10.1109/ICSTCC52150.2021.9607106},
  ISSN={2372-1618},
  month={Oct},}

@INPROCEEDINGS{9317519,
  author={Farooq Butt, Muhammad Hassan and Li, Jian Ping and Saboor, Tehreem},
  booktitle={2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, 
  title={A Tunable and Explainable Attributes (TEA) for Recommendation System}, 
  year={2020},
  volume={},
  number={},
  pages={39-43},
  abstract={Recommender system in information retrieval systems recommends relevant items to consumers by inspecting the consumer's preferences and objective behaviours. We received recommendations daily regarding what to take in as food, buy, and choices about the wear trends. However, we can understand our recommendations, and even less, we can tune our preferences efficiently. One main concern is those undesired or irrelevant recommendations, not only wasting our time, but they also cost media companies millions of dollars every year. Considering this issue, we proposed a tunable and explainable recommendation system where the attributes that determined the recommendations are explainable and tunable for every individual consumer. Irrelevant recommendations waste the consumer's time and the company's money, but if we put the power of the recommendations in the consumer's hands, we have a win-win situation. The suggested method addresses recommendation algorithms issues, which creates negative feedback loops and allows consumers to be aware of the profile they are building and tune it to see the content that interests them most.},
  keywords={Motion pictures;Measurement;Matrix decomposition;Training;Semantics;Recommender systems;Predictive models;Recommender System;Information Retrieval;Tunable Preferences;Explainable Recommendations},
  doi={10.1109/ICCWAMTIP51612.2020.9317519},
  ISSN={2576-8964},
  month={Dec},}

@INPROCEEDINGS{9260076,
  author={Lonjarret, Corentin and Robardet, Céline and Plantevit, Marc and Auburtin, Roch and Atzmueller, Martin},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Why Should I Trust This Item? Explaining the Recommendations of any Model}, 
  year={2020},
  volume={},
  number={},
  pages={526-535},
  abstract={Explainable AI has received a lot of attention over the past decade, with the proposal of many methods explaining black box classifiers such as neural networks. Despite the ubiquity of recommender systems in the digital world, only few researchers have attempted to explain their functioning, whereas it raises e.g., ethical issues. Indeed, recommender systems direct user choices to a large extent and their impact is important as they give access to only a small part of the range of items (e.g., products and/or services), as the submerged part of the iceberg. Consequently, they limit access to other resources. The potentially negative effects of these systems have been pointed out as phenomena like echo chambers and winner-take-all effects, because the internal logic of these systems is to likely enclose the consumer in a "dej́ a vu" loop. Therefore, it is crucial to provide explanations' of such recommender systems and to identify the user data that led the system to make a specific recommendation. This makes it possible to evaluate recommender systems not only regarding their efficiency (i.e., their capability to recommend an item that was actually chosen by the user), but also w.r.t. the diversity, relevance and timeliness of the active data used to make the recommendation. In this paper, we propose a deep analysis of 7 state-of-the-art models learnt on 6 datasets based on the identification of the items or the sequences of items actively used by the models. The proposed method, which is based on subgroup discovery with different pattern languages (i.e., itemsets and sequences), provides interpretable explanations of the recommendations - useful to compare different models and explain the reasons behind the recommendation to the user.},
  keywords={Recommender systems;History;Data science;Analytical models;Perturbation methods;Numerical models;Machine learning;Recommender systems;Explainable AI;Subgroup discovery},
  doi={10.1109/DSAA49011.2020.00067},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{10776491,
  author={Praseptiawan, Mugi and Muchtarom, M. Fikri Damar and Putri, Nabila Muthia and Pee, Ahmad Naim Che and Zakaria, Mohd Hafiz and Untoro, Meida Cahyo},
  booktitle={2024 11th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Mooc Course Recommendation System Model with Explainable AI (XAI) Using Content Based Filtering Method}, 
  year={2024},
  volume={},
  number={},
  pages={144-147},
  abstract={Massive Open Online Course (MOOC) is a type of online course that has been designed and can be accessed by all individuals via the internet. The problem that is often found in MOOCs is the lack of a recommendation system provided by the algorithm of the MOOC. This research is conducted to analyze a recommendation system that applies the Content Based Filtering approach in order to solve the problems that occur. The recommendation system analyzed will function as a media that provides recommendations to users based on their preferences. By utilizing content-based methods, the recommendations given are expected to be exactly what the user wants. The level of explainability of the recommendation system is further emphasized by XAI using ELI5. By getting a concise explanation when a recommendation is given, the system will gain more trust from users for providing an appropriate recommendation. The assessment of the accuracy of the recommendation system model is measured using MAE. By researching this recommendation system using XAI, it is hoped that it can help future systems to improve the quality of the course recommendation system.},
  keywords={Electrical engineering;Computer science;Computer aided instruction;Electronic learning;Filtering;Explainable AI;Media;Data models;Informatics;Recommender systems;MODC;content-based filtering;XAI;recommender system},
  doi={10.1109/EECSI63442.2024.10776491},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{9005590,
  author={Suzuki, Takafumi and Oyama, Satoshi and Kurihara, Masahito},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)}, 
  title={Explainable Recommendation Using Review Text and a Knowledge Graph}, 
  year={2019},
  volume={},
  number={},
  pages={4638-4643},
  abstract={Recommender systems using a knowledge graph can comprehensively organize users and items and their attributes and thereby improve recommendation performance. In addition, the relationship between users and items can be easily interpreted on the basis of entities and relations, thus giving explanations to recommendations. The algorithms and knowledge graphs used for generating explanations have not utilized review text. We have developed a recommendation method for predicting interactions between users and items using a knowledge graph and review text. The underlying user-item relationships are reflected and explanations are generated by predicting user-item interactions from the paths between a user and an item. The modeling is done using a recurrent neural network or a factorization machine. Items' aspects that interest users are extracted from review text and leveraged using an attention-like mechanism. Since the path between a user and an item can be easily interpreted, and the important aspects between a user and an item can be interpreted by observing the attention weight, the proposed model can generate a reasonable recommendation explanation. Testing using a real-world dataset demonstrated that the proposed model can explain the recommendations.},
  keywords={Big Data;Machine-to-machine communications;Conferences;Recommendation;Knowledge Graph;Explainability;Review text;Recurent Neural Network},
  doi={10.1109/BigData47090.2019.9005590},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{10260804,
  author={Rani, Neha and Qian, Yadi and Chu, Sharon Lynn},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Explanation for User Trust in Context-Aware Recommender Systems for Search-As-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={47-49},
  abstract={Learning through web browsing, often termed Search-as-Learning (SaL), can create information overload, due to thousands of search results. SaL can be made more efficient by developing context-aware tools that recommend items to the user and minimize information overload. However, to use context-aware recommender systems (CARS) users need to trust it. Literature has proposed explanations as a feature that helps to build trust. We investigate the impact of explanation on user trust and user experience for using CARS for SaL. Our study results show that people trust a CARS without explanation more during the first use, but for a CARS with explanations, user trust is significant only after multiple uses. Through interviews, we also uncovered the interesting paradox that even though users do not perceive that explanations add to their learning outcomes, they still prefer to use a CARS with explanations over one without.},
  keywords={User experience;Automobiles;Interviews;Recommender systems;Explanation;Trust;User Experience;Context-Aware Recommender System},
  doi={10.1109/ICALT58122.2023.00019},
  ISSN={2161-377X},
  month={July},}

@INPROCEEDINGS{10683822,
  author={Vultureanu-Albişi, Alexandra and Murareţu, Ionuţ and Bădică, Costin},
  booktitle={2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={A Trustworthy and Explainable AI Recommender System: Job Domain Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Finding a job these days is challenging because of the size, diversity, and goals of the market in a society impacted by pandemics, economic crises, or military hostilities. Trust is the most crucial factor in the job domain after performance expectations. It is particularly significant for women, less active job seekers, and people who did not experience job recommendations. Since recommender systems (RS) are one of the most frequently encountered human-centered and online applications in our daily lives, it is important to note that sound principles of trusting the environment of Artificial Intelligence (AI) systems are also required to characterize the trustworthiness of recommender systems. Otherwise, inadequate advice, high expectations and bad interpretations could lead to making bad choices or to demotivating job seekers. This paper expands on previous research, highlighting the point of view of trustworthiness in job recommender systems (JRS) and providing an overview of the dimensions of AI trustworthiness for the job domain. The purpose of this study is to investigate how trustworthy and suggestive outputs can improve the communication between a job mediator and a job seeker by enhancing the credibility of the information provided to job applicants and increasing customer satisfaction.},
  keywords={Economics;Technological innovation;Pandemics;Explainable AI;Customer satisfaction;Cultural differences;Intelligent systems;job recommender system;trustworthiness;explainability;fairness},
  doi={10.1109/INISTA62901.2024.10683822},
  ISSN={2768-7295},
  month={Sep.},}

@INPROCEEDINGS{9079084,
  author={Zarzour, Hafed and Jararweh, Yaser and Hammad, Mahmoud M. and Al-Smadi, Mohammed},
  booktitle={2020 11th International Conference on Information and Communication Systems (ICICS)}, 
  title={A long short-term memory deep learning framework for explainable recommendation}, 
  year={2020},
  volume={},
  number={},
  pages={233-237},
  abstract={Due to the growing quantity of information available on the Web, recommender systems have become crucial component for the success of online shopping stores. However, most of the existing recommender systems were only designed to improve the recommendation results and ignore the explainable recommendation aspect. Therefore, in this paper we propose a long short-term memory deep learning framework for explainable recommendation, that is able to generate an efficient explanation for any rating made by users for a recommended item. Such a framework would help users to choose a product with confident after reading the automatically generated explanation by our framework. The generated explanation is a concise sentence that shows the reason behind a recommendation, i.e., why a user should select that product. Extensive experiments on a real-world dataset from Amazon are conducted with the goal to evaluate the effectiveness of the proposed method in terms of loss and accuracy metrics. The experimental results demonstrate the effectiveness of our method according to the diversity in generating explainable recommendation.},
  keywords={Deep learning;Measurement;Communication systems;Memory management;Electronic commerce;Recommender systems;long short-term memory (LSTM);deep learning;explainable recommendation;recommender system;machine learning},
  doi={10.1109/ICICS49469.2020.239553},
  ISSN={2573-3346},
  month={April},}

@INPROCEEDINGS{9836983,
  author={Walek, Bogdan and Fajmon, Petr},
  booktitle={2022 3rd International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={A Recommender System for Recommending Suitable Products in E-shop Using Explanations}, 
  year={2022},
  volume={},
  number={},
  pages={16-20},
  abstract={This article proposes a recommender system for recommending relevant products in e-shop using explanations. The proposed system consists of three recommender modules called VIEW, RATING, and PURCHASE. The recommender modules use a content-based filtering approach and a collaborative filtering approach. The proposed recommender system works with explanations that contain arguments why the system recommended the specific product. Based on these explanations the user sees why specific products are recommended by the system. The proposed system was experimentally verified and the results of the experimental verification are discussed.},
  keywords={Filtering;Collaborative filtering;Control systems;Artificial intelligence;Recommender systems;Robots;Testing;recommender system;e-shop recommender system;hybrid recommender system;explanations;content-based filtering;collaborative filtering},
  doi={10.1109/AIRC56195.2022.9836983},
  ISSN={},
  month={May},}

@INPROCEEDINGS{10873804,
  author={Xiaolong, Zhou and Shijiao, Han and Zhenze, Li},
  booktitle={2024 21st International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, 
  title={Explainable Recommendation System Based on Aspect-Based Sentiment Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={At information age, the rapid increase of information caused Information Overload problem, which made recommendation system (RS) come into being and push forward the quick development. Nowadays RS has been widely used in human society. Meanwhile, RS also faces challenges like data sparsity and poor explainability. An effective way to address data sparsity challenge is to exploit content information (like review data) for modeling users and items. By further mining content information, deep relationship between user-item interactions can be uncovered and therefore the explanation for recommendation results can be provided. In order to fully mine the information in review data and make precise recommendation with corresponding explanation, a recommendation model for rating prediction task is proposed in this paper. It exploits aspect-based sentiment analysis related theory to mine review features, incorporates the modeling of user preference and item properties with fine-grained sentiment information, which solves problems that previous model has poor context feature extraction ability and the sentiment analysis results are lack of reliability. Extensive experiments show that this model outperforms baseline models in rating prediction task and can provide explanations for the rating prediction results in view of sentiment.},
  keywords={Analytical models;Sentiment analysis;Reviews;Computational modeling;Predictive models;Feature extraction;Wavelet analysis;Data models;Recommender systems;Context modeling;Recommender system;Review-based recommendation;Aspect-based sentiment analysis;Explainable recommendation},
  doi={10.1109/ICCWAMTIP64812.2024.10873804},
  ISSN={2576-8964},
  month={Dec},}

@INPROCEEDINGS{8594883,
  author={Wang, Xiting and Chen, Yiru and Yang, Jie and Wu, Le and Wu, Zhengtao and Xie, Xing},
  booktitle={2018 IEEE International Conference on Data Mining (ICDM)}, 
  title={A Reinforcement Learning Framework for Explainable Recommendation}, 
  year={2018},
  volume={},
  number={},
  pages={587-596},
  abstract={Explainable recommendation, which provides explanations about why an item is recommended, has attracted increasing attention due to its ability in helping users make better decisions and increasing users' trust in the system. Existing explainable recommendation methods either ignore the working mechanism of the recommendation model or are designed for a specific recommendation model. Moreover, it is difficult for existing methods to ensure the presentation quality of the explanations (e.g., consistency). To solve these problems, we design a reinforcement learning framework for explainable recommendation. Our framework can explain any recommendation model (model-agnostic) and can flexibly control the explanation quality based on the application scenario. To demonstrate the effectiveness of our framework, we show how it can be used for generating sentence-level explanations. Specifically, we instantiate the explanation generator in the framework with a personalized-attention-based neural network. Offline experiments demonstrate that our method can well explain both collaborative filtering methods and deep-learning-based models. Evaluation with human subjects shows that the explanations generated by our method are significantly more useful than the explanations generated by the baselines.},
  keywords={Reinforcement learning;Recommender systems;Quality control;Collaboration;Predictive models;Neural networks;Transforms;Explainable recommendation, reinforcement learning, personalized explanation, attention networks},
  doi={10.1109/ICDM.2018.00074},
  ISSN={2374-8486},
  month={Nov},}

@ARTICLE{10048787,
  author={Yang, Zhe-Rui and He, Zhen-Yu and Wang, Chang-Dong and Lai, Jian-Huang and Tian, Zhihong},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Collaborative Meta-Path Modeling for Explainable Recommendation}, 
  year={2024},
  volume={11},
  number={2},
  pages={1805-1815},
  abstract={Although recommender systems have achieved considerable success, sometimes it is difficult to convince users due to the failure to explain the recommendation results. For this reason, explainable recommender systems have drawn a lot of attention in recent years. Among explainable recommendation models, the meta-path-based model plays a significant role because it can reason over the path connecting a user–item pair to achieve explainability. However, it is difficult for the meta-path-based model to achieve such a common explanation in collaborative filtering as “a user similar to you has purchased item  $A$ ” because there is no such meta-path. In this article, we contribute a new model named collaborative meta-path modeling for explainable recommendation (COMPER). It models the similarity of user pairs and item pairs through rating information and constructs collaborative meta-paths for explainability. In addition, we design an attention mechanism to aggregate different paths connecting the target user and the target item. Moreover, the information of the subgraph composed of all paths connecting the target user and the target item is integrated for rating prediction. Extensive experiments on five real-world datasets demonstrate that COMPER achieves good performance in a variety of scenarios, achieving improvements over several baselines.},
  keywords={Collaborative filtering;Recommender systems;Predictive models;Computational modeling;Deep learning;Correlation coefficient;Recommender systems;Collaborative filtering;explainable recommendation;meta-path},
  doi={10.1109/TCSS.2023.3243939},
  ISSN={2329-924X},
  month={April},}

@INPROCEEDINGS{10446052,
  author={Zhang, Jingsen and Bo, Xiaohe and Wang, Chenxi and Dai, Quanyu and Dong, Zhenhua and Tang, Ruiming and Chen, Xu},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Active Explainable Recommendation with Limited Labeling Budgets}, 
  year={2024},
  volume={},
  number={},
  pages={5375-5379},
  abstract={Explainable recommendation has gained significant attention due to its potential to enhance user trust and system transparency. Previous studies primarily focus on refining model architectures to generate more informative explanations, assuming that the explanation data is sufficient and easy to acquire. However, in practice, obtaining the ground truth for explanations can be costly since individuals may not be inclined to put additional efforts to provide behavior explanations. In this paper, we study a novel problem in the field of explainable recommendation, that is, “given a limited budget to incentivize users to provide behavior explanations, how to effectively collect data such that the downstream models can be better optimized?” To solve this problem, we propose an active learning framework for recommender system, which consists of an acquisition function for sample collection and an explainable recommendation model to provide the final results. We consider both uncertainty and influence based strategies to design the acquisition function, which can determine the sample effectiveness from complementary perspectives. To demonstrate the effectiveness of our framework, we conduct extensive experiments based on real-world datasets.},
  keywords={Uncertainty;Refining;Self-supervised learning;Signal processing;Data models;Speech processing;Recommender systems;Explainable Recommendation;Recommender System;Active learning;Influence Function},
  doi={10.1109/ICASSP48485.2024.10446052},
  ISSN={2379-190X},
  month={April},}

@INPROCEEDINGS{10827288,
  author={Bhatti, Uzair Aslam and Yu, Yang Ke and Mamyrbayev, O.Zh. and Aitkazina, A.A. and Hao, Tang and Zhumazhan, N.O.},
  booktitle={2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Recommendations for Healthcare: An Interpretable Approach Using Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={529-535},
  abstract={This study introduces a novel approach to patient interpretation and diagnosis, utilizing Graph Neural Networks (GNNs) within a collaborative recommendation framework. Our proposed system employs GNN-based collaborative filtering to model complex patient-patient and patient-symptom relationships in a comprehensive graph structure. The system is designed to offer interpretable recommendations, explaining the reasoning behind diagnostic suggestions. The study focused on common chronic conditions in older adults, including high blood pressure, coronary heart disease, diabetes and stroke, as well as fractures, osteoporosis and arthritis. We used a graphical hybrid recommender system (GHRS) and a cooperative graph neural network (GCFNA and GCFYA) to predict hospital disease diagnosis. Encouragingly, both the GCFNA and GCFYA models achieved prediction accuracy rates of over 90%, highlighting the model's excellent performance in accurate predictions. The ultimate goal is to provide precise disease predictions for elderly patients, offer medical guidance, and enhance patient care in hospitals, particularly in managing chronic diseases.},
  keywords={Heart;Osteoporosis;Accuracy;Hospitals;Predictive models;Graph neural networks;Pattern recognition;Older adults;Recommender systems;Medical diagnostic imaging;Hypertension;Coronary heart disease;diabetes mellitus;chronic obstructive pulmonary disease;graph convolutional neural network},
  doi={10.1109/PRAI62207.2024.10827288},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{9482221,
  author={Song, Wei and Wang, Chenglong and Ning, Keqing},
  booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, 
  title={Generate Personalized Explanations for Recommendation based on Keywords}, 
  year={2021},
  volume={4},
  number={},
  pages={51-57},
  abstract={Explainable recommendation refers to providing users with recommended products and explaining to users the reasons for recommending the products. Recommendation explanations can greatly increase users’ trust and satisfaction with the recommender system, and to a certain extent can assist users make decisions efficiently. The current recommendation explanation is mainly templated sentences although this method is simple and easy to understand, it is relatively rigid, lacks flexibility, insufficient service, and requires a lot of manpower and material resources. Inspired by the above questions, by mining user comment information, we propose a method to generate multiple recommendations based on keywords. First, the keywords in the comment information are extracted through STF-IDF, and then the recommendation explanation is generated through the classic network GRU generated by natural language. Experiments show that our proposed method not only has better recommendation accuracy but is also has a higher quality of recommended interpretation compared to classic methods},
  keywords={Automation;Conferences;Natural languages;Information management;Data mining;Recommender systems;recommender systems;explainable recommendation;natural language generation;keyword extraction},
  doi={10.1109/IMCEC51613.2021.9482221},
  ISSN={2693-2776},
  month={June},}

@INPROCEEDINGS{10658914,
  author={Chun, Hong Wei and Ong, Rongqing Kenneth and Khong, Andy W. H.},
  booktitle={2024 IEEE 67th International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
  title={Reasonable Sense of Direction: Making Course Recommendations Understandable with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1408-1412},
  abstract={Course recommendation systems play an essential role in academic institutions for students to find courses that align with their interests and graduation requirements. However, due to their “black-box” nature, recommendation systems often lack transparency and interpretability, leading to challenges in trust and usability. Our proposed framework leverages Large Language Models (LLMs) to generate clear, human-readable explanations based on course content by drawing connections between the existing courses taken by the student and recommended courses.},
  keywords={Circuits and systems;Large language models;Closed box;Cognition;Usability;Integrated circuit modeling;Recommender systems;Course Recommendation Systems;Educational Technology;Large Language Models},
  doi={10.1109/MWSCAS60917.2024.10658914},
  ISSN={1558-3899},
  month={Aug},}

@INPROCEEDINGS{10334552,
  author={Chen, Zhanghui and Ai, Xinbo and Guo, Yanjun and Huang, Yitian and Yang, Jing},
  booktitle={2023 IEEE 11th International Conference on Computer Science and Network Technology (ICCSNT)}, 
  title={Explainable Recommendation for Hazard Inspection Reasoning Through Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={37-42},
  abstract={In the process of hazards inspecting in safety production, the number and types of hazard entities are often vast and varied. Introducing of existing recommendation algorithms may lead to low recommendation quality and lack of explain ability. To address these challenges, achieving dual improvement in accuracy and reliability of hazard inspection recommendations. We propose three metrics that represent the explanation quality of recommendation results: Inspection Recency of Hazard, Risk Level of Entity and Utilization Rate of Graph. And then we propose two optimization methods on model inner-training and post-training: Pruning-Strategy Optimization and Re-Rank Optimization. In hazards inspection dataset of safety production, hazard inspection recommendation NDCG@10 reaches 0.433(5.1 % higher than baseline) and overall path explanation metric scores reaches 1.928(74.8% higher than baseline). Compared with previous algorithms, our methods achieve higher recommendation performance and explainability quality.},
  keywords={Measurement;Computer science;Law enforcement;Optimization methods;Production;Knowledge graphs;Inspection;recommendation system;hazard inspection;ex- plainability},
  doi={10.1109/ICCSNT58790.2023.10334552},
  ISSN={2690-5892},
  month={Oct},}

@INPROCEEDINGS{10825771,
  author={Turgut, Özlem and Kök, İbrahim and Özdemir, Suat},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={AgroXAI: Explainable AI-Driven Crop Recommendation System for Agriculture 4.0}, 
  year={2024},
  volume={},
  number={},
  pages={7208-7217},
  abstract={Today, crop diversification in agriculture is a critical issue to meet the increasing demand for food and to improve food safety and quality. This issue is considered to be the most important challenge for the next generation of agriculture due to diminishing natural resources, limited arable land and unpredictable climatic conditions caused by climate change. In this paper, we employ emerging technologies such as the Internet of Things (IoT), machine learning (ML) and explainable artificial intelligence (XAI) to improve operational efficiency and productivity in the agricultural sector. Specifically, we propose an edge computing-based explainable crop recommendation system, AgroXAI, which suggests suitable crops for a region based on weather and soil conditions. In this system, we provide local and global explanations of ML model decisions with methods such as ELI5, LIME, SHAP, which we integrate into ML models. More importantly, we provide regional alternative crop recommendations with the Counterfactual explainability method. In this way, we envision that our proposed AgroXAI system will be a platform that provides regional crop diversity in the next generation agriculture.},
  keywords={Productivity;Explainable AI;Computational modeling;Crops;Soil;Agriculture;Internet of Things;Sustainable development;Recommender systems;Next generation networking;Explainable Artificial Intelligence (XAI);Agriculture 4.0;Internet of Things;edge computing;crop recommendation},
  doi={10.1109/BigData62323.2024.10825771},
  ISSN={2573-2978},
  month={Dec},}

@INPROCEEDINGS{10308154,
  author={Das, Samiran and Chatterjee, Sujoy},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Explainable Machine Learning for Crop Recommendation from Agriculture Sensor Data- a New Paradigm}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The dwindling agricultural earnings and decrease in crop yield in recent years due to improper crop selection and fluctuation/ uncertainty in weather necessitate proper machine learning-based analysis. Machine learning methods can potentially alleviate the predicament caused by the lack of appropriate soil testing, consultation, and bias in manual suggestion. This work attempted to comprehend the agricultural sensor data and weather conditions and formulated the task in terms of supervised classification. The work obtained accurate suggestions in the presence of missing data, noise, etc. by using advanced machine learning methods. But recommendation alone is insufficient to convince farmers and other stakeholders to adopt this approach. Hence, this paper introduced explainable machine learning to completely comprehend the decision-making process. This work quantified the importance of features, explained individual prediction outcomes, and uncovered the rationale for decisions. The work employed state-of-the-art local interpretable model-agnostic, post-hoc explanation methods to provide in-depth insights. The insights obtained from the explanations can help the farmers develop a knowledge base and assist the farmers in choosing the appropriate sensors for the task. The human interpretable analysis enables the farmers to obtain satisfactory yields in these ever-changing and extreme weather conditions and environmental degradation.},
  keywords={Uncertainty;Pollution control;Machine learning;Soil;Pollution measurement;Stakeholders;Resource management;Agricultural data analytics;Sensor data;Crop recommendation;Explainable machine learning},
  doi={10.1109/ICCCNT56998.2023.10308154},
  ISSN={2473-7674},
  month={July},}

@ARTICLE{10902109,
  author={Seol, Jinseok and Ko, Youngrok and Lee, Sang-Goo},
  journal={IEEE Access}, 
  title={Parameter-Efficiently Leveraging Session Information in Deep Learning-Based Session-Aware Sequential Recommendation}, 
  year={2025},
  volume={13},
  number={},
  pages={35555-35566},
  abstract={In recommender systems, leveraging user interaction history as sequential information has recently led to significant performance improvements. However, in many online services, user interactions are often grouped into sessions that inherently share user preferences, requiring a distinct approach from conventional sequence representation techniques. Existing studies have introduced various methods to integrate session information into sequential recommendation models, but most rely on complex network structures, such as hierarchical networks, or introduce substantial additional parameters. In this paper, we revisit the importance of incorporating session information in sequential recommendation models. We propose three methods to enhance recommendation performance by effectively utilizing session information while minimizing additional parameter overhead in deep learning-based sequential recommendation models: session token, session segment embeddings, and temporal self-attention. The proposing methods are designed to be easily integrated into both RNN-based and attention-based models. We demonstrate the effectiveness of the proposed methods through extensive experiments on real-world recommendation datasets, achieving up to a 10% performance improvement with only 1% additional parameters.},
  keywords={Vectors;History;Training;Natural language processing;Encoding;Computational modeling;Recommender systems;Adaptation models;Data models;Attention mechanisms;Session-aware recommendation;sequential recommendation;temporal self-attention},
  doi={10.1109/ACCESS.2025.3545243},
  ISSN={2169-3536},
  month={},}

@ARTICLE{10742303,
  author={Cao, Yang and Shang, Shuo and Wang, Jun and Zhang, Wei},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Explainable Session-Based Recommendation via Path Reasoning}, 
  year={2025},
  volume={37},
  number={1},
  pages={278-290},
  abstract={This paper explores explaining session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting nodes for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR and introduce path midpoint reward to enhance the exploration efficiency and accuracy in knowledge graphs. To improve the knowledge graph’s completeness and diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.},
  keywords={Cognition;Knowledge graphs;Accuracy;Reinforcement learning;Feature extraction;Matrix decomposition;Data mining;Attention mechanisms;Predictive models;Correlation;Explainable recommendation;hierarchical reinforcement learning;knowledge graph;session-based recommendation (SR)},
  doi={10.1109/TKDE.2024.3486326},
  ISSN={1558-2191},
  month={Jan},}

@ARTICLE{10623784,
  author={Guo, Feipeng and Wang, Zifan},
  journal={IEEE Internet of Things Journal}, 
  title={KEMB-Rec: Knowledge-Enhanced Explainable Multibehavior Recommendation With Graph Contrastive Learning}, 
  year={2025},
  volume={12},
  number={4},
  pages={3563-3576},
  abstract={In the era of Internet of Things (IoT), intelligent recommendation systems are crucial components for users to locate the items they require. Existing recommendation systems overlook the diversity of user behaviors and rely solely on utilizing a singular form of user-item interaction data. Multibehavior recommendation (MBR) works to solve this problem by utilizing multityped user behaviors to mine the heterogeneous relations between users and items to improve recommendation accuracy. Nevertheless, there are still challenges to be overcome, including capture of differences and commonalities between different types of behaviors, learning of users’ personalized behavioral patterns, consideration of semantic knowledge, and building of users’ trust in algorithms. In light of the aforementioned considerations, we propose a knowledge-enhanced explainable MBR model (KEMB-Rec) with graph contrastive learning, comprising two modules. The first is the user behavior-aware module, which mines user’s behavior pattern using the user behavior hyper meta-graphs and captures the differences and commonalities between different behaviors through graph contrastive learning. The second is the semantic knowledge-aware module, which is based on single behavior interaction graphs to mine the semantic relational knowledge, and makes full use of it to represent users and items. Then, we design contrastive learning task and recommendation task, and the two tasks are optimized jointly. At the same time, effective recommendation explanations are provided by mining paths and semantics between users and items as a way to enhance user trust and satisfaction. The proposed KEMB-Rec is evaluated in real-world data sets, with results indicating that KEMB-Rec outperforms various baselines.},
  keywords={Contrastive learning;Semantics;Task analysis;Internet of Things;Data mining;Recommender systems;Accuracy;Explanation;graph contrastive learning;graph neural network (GNN);multibehavior recommendation (MBR);semantic knowledge},
  doi={10.1109/JIOT.2024.3439527},
  ISSN={2327-4662},
  month={Feb},}

@INPROCEEDINGS{10895995,
  author={Dwivedi, Mridula and Pandey, Babita and Saxena, Vipin},
  booktitle={2024 IEEE International Conference on Intelligent Signal Processing and Effective Communication Technologies (INSPECT)}, 
  title={X-FedLP: Explainable Federated Learning-Based Approaches for Link Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid development of learning-based approaches in real life made Link Prediction a key network analysis tool. It has applications in social, biological, information, recommendation, and criminal networks. Many network applications require data security and privacy. Standard LP methods often lack scalability, privacy preservation, and interpretability. To overcome the constraints of standard LP approaches, this study offers Explainable Federated Learning-Based Link Prediction (X-FedLP) models, which integrate FL with XAI in LP. The revolutionary FL models FedNN, FedGNN, FedMF, and FedCF make up X-FedLP. These models are tailor-made for LP and deliver human-friendly results. X-FedLP models were tested using 5 real-world datasets, 3 evaluation criteria, and 8 performance assessment indicators. Prediction, performance, and interpretability are used to evaluate X-FedLP models. Tests show that FedMF and FedCF outperform FedNN and FedGNN.},
  keywords={Training;Privacy;Data privacy;Scalability;Data security;Network analyzers;Predictive models;Signal processing;Data models;Standards;Federated Learning;Link Prediction;FedNN;FedGNN;FedMF;FedCF;XAI;LIME},
  doi={10.1109/INSPECT63485.2024.10895995},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{10884422,
  author={Batmani, Sahar and Moradi, Parham and Heidari, Narges and Jalili, Mahdi},
  booktitle={2024 IEEE International Conference on Data Mining (ICDM)}, 
  title={An Explainable Recommender System by Integrating Graph Neural Networks and User Reviews}, 
  year={2024},
  volume={},
  number={},
  pages={669-674},
  abstract={This paper introduces an explainable Graph Neural Network (GNN)-based recommender system that integrates user-item interactions and user reviews to enhance recommendation accuracy and interpretability. The proposed method leverages Temporal Convolutional Networks (TCNs) as a language model to encode user reviews into vector representations, capturing temporal dynamics and contextual information. Additionally, it extracts opinion-aspect pairs from reviews, enabling the system to understand specific product features and user sentiments. Bipartite graphs are constructed to represent interactions between users/items and opinion aspects, facilitating the integration of user reviews into the GNN framework. A contrastive learning approach is employed to combine these graphs with TCN-generated review embeddings, enhancing the system's ability to capture complex relationships. Finally, a recommendation strategy is proposed which considers relevant opinion-aspects as explanations for recommendations. The experiments conducted on several benchmarks reveal that our method outperforms its competitors.},
  keywords={Reviews;Convolution;Contrastive learning;Feature extraction;Graph neural networks;Vectors;Bipartite graph;Data mining;Convolutional neural networks;Recommender systems;Recommender System;Explainability;Graph Neural Networks;Temporal Convolution Networks;User Reviews},
  doi={10.1109/ICDM59182.2024.00074},
  ISSN={2374-8486},
  month={Dec},}

@article{SHIMIZU2022107970,
title = {An explainable recommendation framework based on an improved knowledge graph attention network with massive volumes of side information},
journal = {Knowledge-Based Systems},
volume = {239},
pages = {107970},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107970},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121010959},
author = {Ryotaro Shimizu and Megumi Matsutani and Masayuki Goto},
keywords = {Explainable artificial intelligence, Explainable recommendation, Model-intrinsic approach, Knowledge graph attention network, Knowledge graph embedding, Knowledge graph enabled recommendation},
abstract = {In recent years, explainable recommendation has been a topic of active study. This is because the branch of the machine learning field related to methodologies is enabling human understanding of the reasons for the outputs of recommender systems. The realization of explainable recommendation is widely expected to increase both user satisfaction and the demand for explainable recommendation systems. Explainable recommendation utilizes a wealth of side information (such as sellers, brands, user ages and genders, and bookmark information, among others) to expound the decision-making reasoning applied by recommendation models. In explainable recommendation, although learning side information containing numerous variables leads to rich interpretability, learning too many variables presents a challenge because decreases the amount of learning that a given computational resource can perform, and the accuracy of the recommendation model may be degraded. However, numerous and diverse variables are included in the side information stored by the actual companies operating massive real-world services. Hence, to realize practical applications of this valuable information, it is necessary to resolve problems such as computational cost. In this study, we propose a new framework for explainable recommendation based on an improved knowledge graph attention network model, which utilizes the side information of items and realizes high recommendation accuracy. The proposed framework enables direct interpretation by visualizing the reasons for the recommendations provided. Experimental results show that the proposed framework reduced computational time requirements by approximately 80%, while maintaining recommendation accuracy by enabling the model to learn the probabilistically given edges included in the graph structure. Moreover, the results show that the proposed framework exhibited richer interpretability than the conventional model. Finally, a multifaceted analysis suggests that the proposed framework is not only effective as an explainable recommendation model but also provides a powerful tool for planning various marketing strategies.}
}

@article{BRUNOT2022102021,
title = {Preference-based and local post-hoc explanations for recommender systems},
journal = {Information Systems},
volume = {108},
pages = {102021},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2022.102021},
url = {https://www.sciencedirect.com/science/article/pii/S0306437922000254},
author = {Léo Brunot and Nicolas Canovas and Alexandre Chanson and Nicolas Labroche and Willème Verdeaux},
keywords = {Post-hoc explanation, Recommender systems, Locality, Pairwise preference},
abstract = {Post-hoc explanation aims at defining a simple local surrogate model to shed light on a prediction produced by a complex, generally black-box, model. In the general context of classification, it has been shown that local surrogates may not always be able to capture a local explanation, i.e. for a specific instance prediction, but rather depict more of a general behavior of the black-box. This problem is even more complex in a recommendation scenario where classes and decision boundaries are not explicitly defined and where data are very sparse by nature. We show in this paper that it is possible to tackle these problems with an efficient sampling around the recommendation instance to explain, to finally learn a proper local surrogate model. To this aim, this paper introduces several new approaches to capture efficiently local explanation models in the context of recommendation, all defined around a locality sample. Noticeably, and novel to this work, we show that it is possible to achieve a simple, yet better quality explanation model by not directly considering ratings, but rather implicit preferences as expressed by comparisons of pairs of ratings. We introduce to this extent a novel explainable model based on a pairwise loss RankNet architecture. Extensive experiments show that our methods can be better than state-of-the-art methods depending on the locality of the black-box model, and are much more efficient to retrieve meaningful explainable features locally.}
}

@article{TAO2022109300,
title = {Micro-behaviour with Reinforcement Knowledge-aware Reasoning for Explainable Recommendation},
journal = {Knowledge-Based Systems},
volume = {251},
pages = {109300},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109300},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006529},
author = {Shaohua Tao and Runhe Qiu and Bo Xu and Yuan Ping},
keywords = {Micro-behaviour, Knowledge graph, Deep reinforcement learning, Recommendation, Explanation},
abstract = {Existing practical recommendation scenarios involve multiple micro-behaviour user–item interactions, such as clicks, page views, add-to-favourites, and purchases, which provide fine-grained and a better in-depth understanding of the user’s preference. Furthermore, some recommendation methods have incorporated item knowledge into the micro-behaviour of user–item interaction. Although some have proved effective, two insights are often neglected. First, they fail to combine micro-behaviour with the relation of the knowledge graph (KG), and the semantic relationship between micro-behaviour and relation is not captured. Second, they do not provide explicit reasoning for micro-behaviour from user–item interaction data. These insights motivated us to propose a novel model of Micro-behaviour with Reinforcement Knowledge-aware Reasoning for Explainable Recommendation (MBKR), which incorporates micro-behaviour and the KG into reinforcement learning for explainable recommendation. Specifically, the model learns the behaviour by user–item propagation and the relation from the KG and combines the two to calculate the behavioural strength to mine user’s interests. In addition, we designed a Shawo-relational path that combines recommendation and interpretability by providing rational paths; these paths capture the semantics of behaviours and relations. Finally, we extensively evaluated our method on several large-scale benchmark datasets, and the results indicate that the proposed method is more effective in providing recommendations than state-of-the-art methods.}
}

@article{FAREED2024112140,
title = {Elevating recommender systems: Cutting-edge transfer learning and embedding solutions},
journal = {Applied Soft Computing},
volume = {166},
pages = {112140},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112140},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624009141},
author = {Aamir Fareed and Saima Hassan and Samir {Brahim Belhaouari} and Zahid Halim},
keywords = {Recommender systems, Deep transfer learning, Multimodal embedding, Data sparsity, Cold-start problem},
abstract = {In today’s information age and connected economy, Recommender Systems (RS) plays a vital role in managing information overload and delivering personalized suggestions to users. This paper introduces a multistage model that leverages multimodal data embedding and deep transfer learning to accurately capture user preferences and item characteristics, resulting in highly tailored recommendations. A key innovation in this model is the incorporation of an image dataset in the second phase, which addresses cold-start problems for new items by providing additional visual context. Our approach excels in overcoming challenges related to data sparsity and cold-start issues, thereby providing users with realistic and relevant product recommendations. To validate the effectiveness of the proposed model, we conducted extensive evaluations using three diverse datasets: data from Brazilian e-commerce platforms, the MovieLens 1M dataset, and the Amazon Product Review dataset. These evaluations involved comprehensive comparisons with standard RS methods to assess performance improvements. The results indicate that our proposed model significantly outperforms traditional RS techniques in terms of accuracy and reliability. Our model provides more accurate and meaningful recommendations by effectively addressing issues such as cold-start and data scarcity. Specifically, the model achieved Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) scores of 0.5883 and 0.4012, respectively, which demonstrate its superior performance metrics across all datasets tested.}
}

@article{TAO2021107217,
title = {Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation},
journal = {Knowledge-Based Systems},
volume = {227},
pages = {107217},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107217},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121004792},
author = {Shaohua Tao and Runhe Qiu and Yuan Ping and Hui Ma},
keywords = {Multi-modal knowledge graph, Knowledge graph, Image, Deep reinforcement learning, Recommendation},
abstract = {Knowledge graphs (KGs) can provide rich, structured information for recommendation systems as well as increase accuracy and perform explicit reasoning. Deep reinforcement learning (RL) has also sparked great interest in personalized recommendations. The combination of the two holds promise in carrying out interpretable causal inference procedures and improving the performance of graph-structured recommendation. However, most KG-based recommendation focus on rich semantic relationships between entities in a heterogeneous knowledge graph, and thus fail to fully make use of the image information corresponding to an entity. In order to address these issues, we proposed a novel Multi-modal Knowledge-aware Reinforcement Learning Network (MKRLN), which couples recommendation and interpretability by providing actual paths in multi-modal KG (MKG). The MKRLN can generate path representation by composing the structural and visual information of entities, and infers the underlying rational of agent-MKG interactions by leveraging the sequential dependencies within a path from the MKG. In addition, as KGs have too many attributes and entities, their combination with RL leads to too many action spaces and states in the reinforcement learning space, which complicates the search of action spaces. Furthermore, in order to solve this problem, we proposed a new hierarchical attention-path, which makes users focus their attention on the items they are interested in. This reduces the relations and entities in the KGs, which in turn reduces the action space and state in RL, shortens the path to the target entity, and improves the accuracy of recommendation. Our model has explicit explanation ability in knowledge and images. Finally, we extensively evaluated our model on several large-scale real-world benchmark datasets, and it yielded favorable results compared with state-of-the-art methods.}
}

@article{YANG2021106687,
title = {Accurate and Explainable Recommendation via Hierarchical Attention Network Oriented Towards Crowd Intelligence},
journal = {Knowledge-Based Systems},
volume = {213},
pages = {106687},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106687},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120308169},
author = {Chao Yang and Weixin Zhou and Zhiyu Wang and Bin Jiang and Dongsheng Li and Huawei Shen},
keywords = {Crowd intelligence, Explainable recommendation, Hierarchical attention, Review representation, Recommender system},
abstract = {Review-based recommendation algorithms can alleviate the data sparsity issue in collaborative filtering by combining user ratings and reviews in model learning. However, most existing methods simplify the feature extraction process from reviews by assuming that different granularities of information (e.g., word, review, and feature) are equally important, which cannot optimally leverage the most important information and thus achieves suboptimal recommendation accuracy. Besides, many existing works directly regard text features as users or items representations, which may not be enough to make precise representations due to the large amount of redundant information in reviews. To tackle the two problems mentioned above, we propose a deep learning-based method named Hierarchical Attention Network Oriented Towards Crowd Intelligence (HANCI). First, HANCI replaces the commonly-used topic models or CNN text processor with an RNN text processor in review feature extraction, which can fully exploit the advantages of the sequential dependencies of reviews by using the whole hidden layers of the bidirectional LSTM as outputs. Second, HANCI weighs the importance of features guided by crowd intelligence to more accurately represent each user on each item, and vice versa. Third, HANCI utilizes a hierarchical attention network based on multi-level review text analysis to extract more precise user preferences and item latent features, so that HANCI can explore the importance of words, the usefulness of reviews and the importance of features to achieve more accurate recommendation. Extensive experiments on three public datasets show that HANCI outperforms the state-of-the-art review-based recommendation algorithms in accuracy and meanwhile provides insightful explanations.}
}

@article{LIU2020102099,
title = {Dynamic attention-based explainable recommendation with textual and visual fusion},
journal = {Information Processing & Management},
volume = {57},
number = {6},
pages = {102099},
year = {2020},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2019.102099},
url = {https://www.sciencedirect.com/science/article/pii/S0306457319301761},
author = {Peng Liu and Lemei Zhang and Jon Atle Gulla},
keywords = {Dynamic explainable recommendation, Recurrent neural network, Attention mechanism, Semantic alignment, Multi-model fusion, User interests},
abstract = {Explainable recommendation, which provides explanations about why an item is recommended, has attracted growing attention in both research and industry communities. However, most existing explainable recommendation methods cannot provide multi-model explanations consisting of both textual and visual modalities or adaptive explanations tailored for the user’s dynamic preference, potentially leading to the degradation of customers’ satisfaction, confidence and trust for the recommender system. On the technical side, Recurrent Neural Network (RNN) has become the most prevalent technique to model dynamic user preferences. Benefit from the natural characteristics of RNN, the hidden state is a combination of long-term dependency and short-term interest to some degrees. But it works like a black-box and the monotonic temporal dependency of RNN is not sufficient to capture the user’s short-term interest. In this paper, to deal with the above issues, we propose a novel Attentive Recurrent Neural Network (Ante-RNN) with textual and visual fusion for the dynamic explainable recommendation. Specifically, our model jointly learns image representations with textual alignment and text representations with topical attention mechanism in a parallel way. Then a novel dynamic contextual attention mechanism is incorporated into Ante-RNN for modelling the complicated correlations among recent items and strengthening the user’s short-term interests. By combining the full latent visual-semantic alignments and a hybrid attention mechanism including topical and contextual attentions, Ante-RNN makes the recommendation process more transparent and explainable. Extensive experimental results on two real world datasets demonstrate the superior performance and explainability of our model.}
}

@article{KIM2025102253,
title = {Am I watching or being watched? Exploring the selective disclosure paradox in users’ self-censorship to dataveillance awareness in video recommender systems},
journal = {Telematics and Informatics},
volume = {98},
pages = {102253},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102253},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000152},
author = {Jooyoung Kim and Hangjung Zo},
keywords = {Dataveillance, Video recommender systems, Self-censorship, Privacy concerns, Protection motivation theory},
abstract = {In today’s rapidly evolving digital media landscape, video recommender systems have become central to enhancing user experiences by delivering personalized content. However, they also raise significant concerns about dataveillance—the continuous monitoring of user behavior. This study examines the complex relationship between dataveillance awareness, privacy concerns, perceived value of information disclosure, protective intentions, and self-censorship in video recommender systems. Using structural equation modeling based on data from an online scenario-based experiment (N = 385), our findings reveal that heightened dataveillance awareness significantly increases privacy concerns and diminishes the perceived value of sharing information. These privacy concerns drive users toward protective behaviors, such as self-censorship. Notably, the study reveals a selective disclosure paradox: where users are more likely to engage in self-censorship when they perceive their shared information as valuable, but when they become more aware of being monitored (dataveillance), they start to see their information as less valuable, which makes them less likely to self-censor. Grounded in privacy calculus and protection motivation theories, this research underscores the chilling effect of dataveillance and presents a comprehensive model that explains how perceived privacy risks shape user engagement. By shedding light on unconscious behaviors that may hinder recommender systems’ ability to optimize their algorithms, the findings offer both theoretical insights into digital user behavior and practical recommendations for designing systems that balance personalization with subtle management of perceived disclosure value, ultimately reducing self-censorship.}
}

@article{LIANG202194,
title = {O3ERS: An explainable recommendation system with online learning, online recommendation, and online explanation},
journal = {Information Sciences},
volume = {562},
pages = {94-115},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.12.070},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520312366},
author = {Qianqiao Liang and Xiaolin Zheng and Yan Wang and Mengying Zhu},
keywords = {Explainable recommendation systems, Online learning, Factorization bandit},
abstract = {Explainable recommendation systems (ERSs) have attracted increasing attention from researchers, which generate high-quality recommendations with intuitive explanations to help users make appropriate decisions. However, most of the existing ERSs are designed with an offline setting, which can hardly adjust their models using the online feedback instantly for improved performance. To overcome the limitations of ERSs with the offline setting, we propose a novel online setting for ERSs and devise an effective model called O3ERS in this online setting, which can perform online learning with good scalability and rigorous theoretical guides for better online recommendations and online explanations. O3ERS also addresses two challenging problems in real scenarios, namely, the sparsity and delay of online explanations’ feedback as well as the partialness and insufficiency of online recommendations’ feedback. Specifically, O3ERS not only instantly leverages the knowledge learned from the recommendations’ feedback to adjust the sparse and delayed explanations’ feedback for better explanations but also utilizes a novel exploitation–exploration strategy that incorporates the explanations’ feedback to adjust the partial and insufficient recommendations’ feedback for better recommendations. Our theoretical analysis and empirical studies on one simulated and two real-world datasets show that our model outperforms the state-of-the-art models in online scenarios remarkably.}
}

@article{ZANON2022109333,
title = {Balancing the trade-off between accuracy and diversity in recommender systems with personalized explanations based on Linked Open Data},
journal = {Knowledge-Based Systems},
volume = {252},
pages = {109333},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109333},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006682},
author = {André Levi Zanon and Leonardo Chaves Dutra da Rocha and Marcelo Garcia Manzato},
keywords = {Recommender systems, Collaborative filtering, Linked open data, Explainable AI},
abstract = {Collaborative filtering recommendation algorithms generate suggestions based on similar interactions between users. Although it provides accurate recommendations, the approach has two limitations: the popularity bias, which frequently suggests a small set of the most interacted items, and the systems’ black box functioning, as they are grounded on complex mathematical models. To improve such aspects in collaborative filtering algorithms, this paper introduces a multi-domain item reordering system based on the best explanation for an item, which are the best ranked paths extracted from a Linked Open Data knowledge graph connecting recommended and interacted items. To order paths, the algorithm assigns a value to the node attributes connecting two items by calculating the popularity of the property between interacted items that are rare in the full set of items. Results from two datasets of the movie and music domains comparing the proposed reordering system with six baselines of different collaborative filtering families showed that our easy-to-explain approach improved diversity and/or accuracy metrics.}
}

@article{PAZRUZA2024102497,
title = {Sustainable transparency on recommender systems: Bayesian ranking of images for explainability},
journal = {Information Fusion},
volume = {111},
pages = {102497},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102497},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002756},
author = {Jorge Paz-Ruza and Amparo Alonso-Betanzos and Bertha Guijarro-Berdiñas and Brais Cancela and Carlos Eiras-Franco},
keywords = {Machine Learning, Explainable Artificial Intelligence, Frugal AI, Dyadic data, Explainable recommendations, Recommender systems},
abstract = {Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using existing visual content created by users is a promising option to maximize transparency and user trust. State-of-the-art models that follow this approach, despite leveraging highly optimized architectures, employ surrogate learning tasks that do not efficiently model the objective of ranking images as explanations for a given recommendation; this leads to a suboptimal training process with high computational costs that may not be reduced without affecting model performance. This work presents BRIE, a novel model where we leverage Bayesian Pairwise Ranking to enhance the training process, allowing us to consistently outperform state-of-the-art models in six real-world datasets while reducing its model size by up to 64 times and its CO2 emissions by up to 75% in training and inference.}
}

@article{AI2025129692,
title = {An explainable recommendation algorithm based on content summarization and linear attention},
journal = {Neurocomputing},
volume = {630},
pages = {129692},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129692},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003649},
author = {Jun Ai and Haolin Li and Zhan Su and Fengyu Zhao},
keywords = {Content summary, Linear attention, Explainable recommendation algorithm, Vivaldi synthetic coordinate algorithm, Kolmogorov–Arnold neural network},
abstract = {Recommendation algorithms can alleviate the problem of information explosion and cater to the needs of users to quickly lock in preferred items, promote business development, and have important theoretical significance and broad theoretical value. Explainable recommendation algorithms can not only complete recommendation tasks, but also generate recommendation explanations, so that users can more easily accept preferences. Research related to natural language text generation has promoted the progress of explainable text generation technology for recommendation systems. This paper proposes an explainable recommendation algorithm based on content summarization and linear attention mechanism. The model uses the keyword extraction algorithm to extract key information from user comment text as an important feature of subsequent text generation tasks, and further introduces linear Transformer to improve the training speed of the model and enhance its scalability. In addition, the model also uses the Vivaldi synthetic coordinate algorithm to deeply mine user and item features and uses the Kolmogorov–Arnold neural network model to reduce the error of predicted ratings. Compared with existing leading algorithms, the algorithm in this paper has achieved significant improvements in text generation and recommendation rating prediction. This paper reveals that applying the linear attention mechanism to the explainable recommendation algorithm can greatly reduce the training cost and improve scalability, and the fusion of synthetic coordinates and attention can further mine the hidden information of the recommendation system, effectively improving the performance of the recommendation algorithm.}
}

@article{WEI2023202,
title = {ExpGCN: Review-aware Graph Convolution Network for explainable recommendation},
journal = {Neural Networks},
volume = {157},
pages = {202-215},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004087},
author = {Tianjun Wei and Tommy W.S. Chow and Jianghong Ma and Mingbo Zhao},
keywords = {Explainable recommendation, Recommender system, Graph Neural Network, Multi-task learning, Collaborative filtering},
abstract = {Existing works in recommender system have widely explored extracting reviews as explanations beyond user–item interactions, and formulated the explanation generation as a ranking task to enhance item recommendation performance. To associate explanations with users and items, graph neural networks (GNN) are usually employed to learn node representations on the heterogeneous user–item–explanation interaction graph. However, modeling heterogeneous graph convolution poses limitations in both message passing styles and computational efficiency, resulting in sub-optimal recommendation performance. To address the limitations, we propose an Explanation-aware Graph Convolution Network (ExpGCN). In particular, the heterogeneous interaction graph is divided to subgraphs regard to the edge types in ExpGCN. By aggregating information from distinct subgraphs, ExpGCN is capable of generating node representations for explanation ranking task and item recommendation task respectively. Task-oriented graph convolution can not only reduce the complexity of heterogeneous node aggregation, but also alleviate the performance degeneration caused by the conflicts between task learning objectives, which has been neglected in current studies. Extensive experiments on four public datasets show that ExpGCN significantly outperforms state-of-the-art baselines with high efficiency, demonstrating the effectiveness of ExpGCN in explainable recommendations.}
}

@article{KAUR2023100507,
title = {A deep learning knowledge graph neural network for recommender systems},
journal = {Machine Learning with Applications},
volume = {14},
pages = {100507},
year = {2023},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2023.100507},
url = {https://www.sciencedirect.com/science/article/pii/S2666827023000609},
author = {Gurinder Kaur and Fei Liu and Yi-Ping Phoebe Chen},
keywords = {Collaborative filtering, Graph neural network, Recommender system, Knowledge graph},
abstract = {Knowledge graphs are becoming the new state-of-the-art for recommender systems. This paper is based on knowledge graphs to alleviate the problem of data sparsity. Various methods have been recently deployed to solve this problem which largely attempts to study user-item representation and then recommend items to users based on these representations. Although these methods are effective, they lack explainability for recommendations and do not mine side information. In this paper, we propose the use of knowledge graphs which includes additional information about users and items in addition to the use of a user/item interaction matrix. The vital element of our model is neighbourhood aggregation for collaborative filtering. Every user and item are associated with an ID embedding, which is circulated on the interaction graph for users, items, and their attributes. We obtain the final embeddings by combining the embeddings learned at various hidden layers with a biased sum. Our model is easier to train and achieves better performance compared to graph neural network-based collaborative filtering (GCF) and other state-of-the-art recommender methods. We provide evidence for our argument by analytically comparing the knowledge graph convolution network (KGCN) with GCF and eight other state-of-the-art methods, using similar experimental settings and the same datasets.}
}

@article{YANG2020106194,
title = {HAGERec: Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation},
journal = {Knowledge-Based Systems},
volume = {204},
pages = {106194},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106194},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120304196},
author = {Zuoxi Yang and Shoubin Dong},
keywords = {Recommender system, Graph convolutional network, Hierarchical attention, Knowledge graph},
abstract = {Knowledge graph (KG) can provide auxiliary information for recommender system to alleviate the sparsity and cold start problems, while graph convolutional networks (GCN) has recently been established as the state-of-the-art representation learning method. The combination of them is a promising perspective to improve the performance of graph-structured recommendation. However, most of GCN-based recommendations focus on homogeneous graph or user/item-similarity graph, fail to fully make use of the complex and rich semantics between entities in heterogeneous knowledge graph. In this paper, we develop Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation (HAGERec) to explore users’ potential preferences from the high-order connectivity structure of heterogeneous knowledge graph. To exploit semantic information, HAGERec simultaneously learn the representations of users and items via a bi-directional information propagation strategy. Specifically, the entity’s representation can be aggregated through messages passing from its local proximity structure, and a hierarchical attention mechanism is developed to adaptively characterize and adjust collaborative signals. With the help of the attention mechanism, an attentive entity sampling strategy is proposed to select relevant neighbor entities, and the explainability is endowed to the model by building knowledge-aware connectivity. Experiments conducted on four real-world public datasets demonstrate the state-of-the-art performance and the strong explainability of HAGERec.}
}

@article{LI2024112042,
title = {An attention mechanism and residual network based knowledge graph-enhanced recommender system},
journal = {Knowledge-Based Systems},
volume = {299},
pages = {112042},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112042},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124006762},
author = {Weisheng Li and Hao Zhong and Junming Zhou and Chao Chang and Ronghua Lin and Yong Tang},
keywords = {Knowledge graph, Recommender system, Residual network, Attention mechanism},
abstract = {Recommender systems enhanced by a knowledge graph (KG) have attained widespread popularity and attention in recent years. However, traditional KG-based recommender systems encounter the challenge of gradient explosion as the network depth increases. Additionally, the abundance of unreliable paths in a KG has a detrimental impact on feature representation learning. In this article, we propose a KG-enhanced recommender system based on residual network and attention mechanism, which can capture high-order connectivity and long-range dependencies of the KG. Specifically, a resource allocation approach is employed to calculate the resource amount, which is subsequently utilized to evaluate the path reliability of the KG. After completing path extraction, we employ an attention mechanism to capture semantic correlations and structural information. To leverage the KG for enhancing recommender systems, we design a deep residual network with shortcut connections, effectively amalgamating advanced and abstract features using deep neural networks. The introduction of shortcut connections not only facilitates the fitting of residual mappings but also mitigates potential issues such as gradient explosion and convergence difficulties due to excessive network depth. Extensive experiments conducted on three standard datasets over baseline methods have demonstrated the superiority of our proposed recommender system.}
}

@article{WANG2020436,
title = {Learning user-item paths for explainable recommendation},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {5},
pages = {436-440},
year = {2020},
note = {3rd IFAC Workshop on Cyber-Physical & Human Systems CPHS 2020},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.04.119},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321002305},
author = {Tongxuan Wang and Xiaolong Zheng and Saike He and Zhu Zhang and Desheng Dash Wu},
keywords = {explainable recommendation, knowledge graph, deep neural networks},
abstract = {Knowledge graph based explainable recommendation system is a kind of personalized recommendation which uses side information to solve the reason why recommending an item. Previous study has not fully explored the connection between users and items in knowledge graph, especially the problem of overall semantic representation, and can not capture the high level semantic representation of the path, it is difficult for existing path-based methods to clarify the overall semantics of paths. Especially when the path contains similar entities but different relationship. In this paper, we propose a model named Meta-Path-based Explainable Recommendation System (MPERS) to represent the paths in the knowledge graph through the semantic information of entities and relationships, and distinguish the different contributions that different paths make to conduct users’ preference. The experimental study demonstrates the superiority of our method compared with the state-of-the-art ones}
}

@article{GUO2021185,
title = {TAERT: Triple-Attentional Explainable Recommendation with Temporal Convolutional Network},
journal = {Information Sciences},
volume = {567},
pages = {185-200},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521002772},
author = {Siyuan Guo and Ying Wang and Hao Yuan and Zeyu Huang and Jianwei Chen and Xin Wang},
keywords = {Recommender system, Explainable recommendation, Triple attention networks, Temporal Convolutional Network, Rating prediction},
abstract = {Explainable Recommendation aims at not only providing the recommended items to users, but also enabling users to be aware of why these items are recommended. To better understand the recommended results, textual reviews have been playing an increasingly important role in the recommender systems. However, how to learn the latent representation of user preferences and item features, and how to model the interactions between them effectively via specific aspects in the reviews are two crucial problems in the explainable recommendation. To this end, we propose a novel Triple-Attentional Explainable Recommendation with Temporal Convolutional Network, named TAERT, which is to jointly generate recommendation results and explanations. Specifically, we first explore a feature learning method based on Temporal Convolutional Network (TCN) to derive word-aware and review-aware vector representations. Then, we introduce three levels of attention networks to model word contribution, review usefulness and importance of latent factors, respectively. Finally, the predicted rating is inferred by the factor-level attention based prediction layer. Furthermore, the attention mechanism is also conducive to identifying the representative item reviews and highlighting the informative words to generate explanations. Compared with the state-of-the-art methods, comprehensive experiments on six real-world datasets are conducted to verify the effectiveness on both recommendation and explanation.}
}

@article{MARKCHOM2023110258,
title = {Scalable and explainable visually-aware recommender systems},
journal = {Knowledge-Based Systems},
volume = {263},
pages = {110258},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110258},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123000084},
author = {Thanet Markchom and Huizhi Liang and James Ferryman},
keywords = {Recommender system, Heterogeneous information network, Meta-path, Visual information, Scalability, Explainability},
abstract = {Recommender systems are popularly used to deal with an information overload issue. Existing systems mainly focus on user–item interactions and semantic information derived from metadata of users and items to improve recommendation accuracy. Item images provide useful information to infer users’ individual preferences, especially for those domains where visual factors are influential such as fashion items. However, this type of information has been ignored by most previous work. To bridge this gap and meet the requirements of performance from the aspects of Accuracy, Scalability, and Explainability evaluation metrics, this paper proposes a scalable and explainable visually-aware recommender system framework called SEV-RS. This framework contains a visually-augmented heterogeneous information network, a scalable meta-path feature extraction method for multi-hop relations, and a shallow explainable meta-path based Collaborative Filtering recommendation approach. We compared SEV-RS with the state-of-the-art models such as the deep learning model using Graph Attention Network on two real-world datasets and one synthetic dataset. The results show that SEV-RS produced more accurate and more explainable recommendations. Also, SEV-RS has substantially less computational time than the compared deep learning models.}
}

@article{HAO2025113113,
title = {IReGNN: Implicit review-enhanced graph neural network for explainable recommendation},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113113},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113113},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125001601},
author = {Qingbo Hao and Chundong Wang and Yingyuan Xiao and Wenguang Zheng},
keywords = {Explainable recommendations, Graph neural network, Implicit reviews, Topic extraction},
abstract = {Explainable recommendations can not only recommend items to users but also provide corresponding explanations, which is crucial for enhancing the transparency, credibility, and security of the system. Reviews, as an important information source for explainable recommendations, have received considerable attention. However, existing review-based explainable recommendations focus primarily on exploring user preferences and item features, as well as generating explanations from reviews, overlooking the limitations imposed by review sparsity on model performance. To address this issue, we propose an Implicit Review-enhanced Graph Neural Network (IReGNN) for explainable recommendations. Specifically, we construct a review network and a rating network, respectively. For the review network, we adopt an unsupervised approach to mine different topics of users and items, thereby enhancing node attribute representations. On the other hand, for the rating network, we extract implicit relationships between individuals and generate virtual reviews under the constraint of topics, which can effectively alleviate the data sparsity issue. Finally, we leverage a spatial graph neural network to learn node representations, generating accurate recommendations and high-quality explanations. Through a series of experiments on three publicly available datasets, results demonstrate that IReGNN outperforms eight baseline models in terms of rating prediction and explanation quality. Moreover, our model also has certain advantages in sparse data scenarios. The model and datasets are released at: https://github.com/SamuelZack/IReGNN.git.}
}

@article{KHAN2025128932,
title = {ConvSeq-MF: Convo-Sequential Matrix Factorization for recommender system},
journal = {Neurocomputing},
volume = {618},
pages = {128932},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128932},
url = {https://www.sciencedirect.com/science/article/pii/S092523122401703X},
author = {Zeeshan Khan and Zafran Khan and Naima Iltaf},
keywords = {Convolutional neural network, Semantics information, Textual embedding, Probabilistic matrix factorization, And hybrid collaborative filtering},
abstract = {In the domain of recommendation, the fusion of user historical preferences and item features has emerged as a promising field to enhance recommendation accuracy and mitigate the sparsity problem. This research presents a novel approach to recommendation systems by integrating both user and item content auxiliary information. By harnessing the rich contextual data associated with users and items, our hybrid approach ConvSeq-MF endeavors to provide more personalized and accurate recommendations. As the name indicates, it is based on a matrix factorization approach driven by joint venture of semantic and contextual information of both user’s and item’s. Series of experimentation on three real-world datasets shows the suggested methodology’s practicality and efficacy over other baselines. To the best of our knowledge, the data demonstrate that the suggested model works better than other state of the art frameworks.}
}

@article{LUO2025111496,
title = {Rank Gap Sensitive Deep AUC maximization for CTR prediction},
journal = {Pattern Recognition},
pages = {111496},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.111496},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325001566},
author = {Fangyuan Luo and Yankai Chen and Jun Wu and Yidong Li},
keywords = {Recommender system, Click-Through Rate prediction, Deep neural network, Learning to rank, AUC},
abstract = {Deep Neural Network (DNN) stands out as one widely adopted and effective technique for Click-Through Rate (CTR) prediction in live recommender systems. However, the prevalent DNN-based CTR methods exhibit two main drawbacks. On one hand, they fail to align their optimization objectives with the benchmark metric, such as the Area Under the ROC Curve (AUC), designed for ranking tasks. On the other hand, current DNN-based CTR solutions indiscriminately treat all positive-negative item pairs, ignoring the fact that each item pair differently contributes to AUC optimization. To this end, we propose Rank Gap Sensitive Deep AUC maximization method for accurate CTR prediction, namely RgsAUC. Specifically, we target AUC as the learning objective by relaxing the Heaviside function via sigmoid function to render it differentiable and thus can be optimized directly using gradient-descent methods, which is the de facto choice for solving DNN-based CTR tasks. Furthermore, we incorporate a rank gap sensitive weight in estimating gradients for items, aiming to assign greater significance to item pairs with substantial rank gaps during the learning process. In particular, we reduce the computational complexity from quadratic to linear through reformulation, enabling efficient deployment. Consequently, these designs sharply minimize the number of erroneously-ranked item pairs, which is beneficial to AUC optimization. Notably, RgsAUC is model-agnostic and we implement it in five classic DNN models for the CTR prediction task. Extensive experiments on six real-world datasets clearly demonstrate the effectiveness of our proposed method.}
}

@article{ROSENBERGER2025127043,
title = {CareerBERT: Matching resumes to ESCO jobs in a shared embedding space for generic job recommendations},
journal = {Expert Systems with Applications},
pages = {127043},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127043},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425006657},
author = {Julian Rosenberger and Lukas Wolfrum and Sven Weinzierl and Mathias Kraus and Patrick Zschech},
keywords = {Job consultation, Job markets, Job recommendation system, BERT, NLP},
abstract = {The rapidly evolving labor market, driven by technological advancements and economic shifts, presents significant challenges for traditional job matching and consultation services. In response, we introduce an advanced support tool for career counselors and job seekers based on CareerBERT, a novel approach that leverages the power of unstructured textual data sources, such as resumes, to provide more accurate and comprehensive job recommendations. In contrast to previous approaches that primarily focus on job recommendations based on a fixed set of concrete job advertisements, our approach involves the creation of a corpus that combines data from the European Skills, Competences, and Occupations (ESCO) taxonomy and EURopean Employment Services (EURES) job advertisements, ensuring an up-to-date and well-defined representation of general job titles in the labor market. Our two-step evaluation approach, consisting of an application-grounded evaluation using EURES job advertisements and a human-grounded evaluation using real-world resumes and Human Resources (HR) expert feedback, provides a comprehensive assessment of CareerBERT’s performance. Our experimental results demonstrate that CareerBERT outperforms both traditional and state-of-the-art embedding approaches while showing robust effectiveness in human expert evaluations. These results confirm the effectiveness of CareerBERT in supporting career consultants by generating relevant job recommendations based on resumes, ultimately enhancing the efficiency of job consultations and expanding the perspectives of job seekers. This research contributes to the field of NLP and job recommendation systems, offering valuable insights for both researchers and practitioners in the domain of career consulting and job matching.}
}

@article{LIU2025113217,
title = {Semantic relation-aware graph attention network with noise augmented layer-wise contrastive learning for recommendation},
journal = {Knowledge-Based Systems},
volume = {314},
pages = {113217},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113217},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125002643},
author = {Jianfang Liu and Wei Wang and Baolin Yi and Huanyu Zhang and Xiaoxuan Shen},
keywords = {Contrastive learning, Semantic relation-aware, Knowledge graph, Noise augmented, Graph attention network, Recommendation},
abstract = {Recommender systems based on knowledge graphs enhance the explainability of recommendations by incorporating external knowledge. Nevertheless, the accuracy of recommendations heavily depends on dense interaction data and high-quality knowledge graphs, both of which commonly suffer from data sparsity. Introducing graph contrastive learning to enhance representation quality can effectively improve recommendation performance. Existing graph contrastive learning methods that use graph augmentation can alleviate the data sparsity problem. However, they often neglect the semantic modeling of relation embeddings and lack sufficient contrastive information, leading to insufficient utilization of the embedding space for relations and nodes. To address this, we propose a semantic relation-aware graph attention network with a noise augmented layer-wise contrastive learning model for recommendation, named SRGAN. Specifically, we design a semantic relation-aware graph attention network that updates the semantics of relations during multi-layer iterations to better capture user preferences. Additionally, we construct a noise-augmented layer-wise contrastive learning model, employing simple yet effective noise perturbations to generate contrastive views for entities and relations. By maximizing the consistency of the representations in each layer, the model achieves alignment with the lower-level features of the intermediate layers. Extensive experiments on three public benchmark datasets demonstrate that our proposed method significantly outperforms current approaches. To ensure reproducibility, we make the code and data from our experiments publicly available on https://github.com/liujianfang2021/SRGAN.}
}

@article{LAI2025105888,
title = {Advanced graph embedding for intelligent heating, ventilation, and air conditioning optimization: An ensemble learning-based recommender system},
journal = {Case Studies in Thermal Engineering},
volume = {68},
pages = {105888},
year = {2025},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2025.105888},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X25001480},
author = {Shouliang Lai and Xiyu Yi and Peiling Zhou and Lu Peng and Wentao Liu and Shi Sun and Binrong Huang},
keywords = {Graph embedding, HVAC optimization, Ensemble learning, Recommender systems, Smart buildings},
abstract = {This study introduces a robust and scalable software architecture designed for real-time data ingestion, processing, and user interaction within a smart building setting. Utilizing advanced graph embedding techniques combined with ensemble learning models, we developed a recommender system tailored for Heating, Ventilation, and Air Conditioning (HVAC) optimization in Shenzhen Qianhai Smart Community. We employed a mixed-methods approach, including the generation of synthetic multivariate time series data, data preprocessing, statistical correlation analysis, and the implementation of GraphSAGE, Graph Attention Networks (GAT), and Node2Vec for graph embedding. The ensemble learning framework integrated Decision Trees, Random Forests, Gradient Boosting Machines (XGBoost), and Neural Networks to enhance prediction accuracy. Our findings demonstrate that the proposed architecture maintains high performance under increased loads, with key sensor correlations effectively managed to optimize HVAC operations. The recommender system achieved a 51 % reduction in energy consumption of chilled water pumps and a 15 % increase in occupant satisfaction by providing personalized HVAC settings. These results highlight the significance of integrated system designs and data-driven strategies in developing intelligent building management solutions. The study contributes actionable insights into system scalability and user-centric environmental controls, paving the way for future research in real-world implementations and advanced analytical techniques.}
}

@article{WU2025129780,
title = {Cross-modal feature symbiosis for personalized meta-path generation in heterogeneous networks},
journal = {Neurocomputing},
volume = {633},
pages = {129780},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129780},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225004527},
author = {Xiaotong Wu and Liqing Qiu and Weidong Zhao},
keywords = {Heterogeneous graph neural networks, Meta-path generation, Reinforcement learning, Cross-modal information processing},
abstract = {In heterogeneous graph neural networks (HGNNs), the capture of intricate relationships among various types of entities is essential to achieve advanced machine learning applications. Heterogeneous Information Networks (HINs), composed of interconnected multi-type nodes and edges, face significant challenges in managing semantic diversity and inherent heterogeneity. Traditional methods, which rely on manually designed meta-paths, struggle to adapt dynamically to personalized needs and often neglect the integration of structural and attribute features. To address these limitations, this paper introduces the Cross-Modal Symbiotic Meta-Path Generator (CSMPG) framework. CSMPG integrates two key modules: a Cross-Modal State Generation Module that encodes node structure and attribute information into task-aware state vectors and a Personalized Meta-Path Generation Module that dynamically generates and refines meta-paths using reinforcement learning. By leveraging downstream task feedback, CSMPG optimizes path selection to maximize performance. The framework effectively balances cross-modal feature integration and semantic diversity, uncovering impactful meta-paths that are often overlooked by traditional approaches. Experimental results demonstrate that CSMPG consistently enhances recommendation quality and significantly outperforms structure-only and predefined-path-based models.}
}

@article{AI2025129692,
title = {An explainable recommendation algorithm based on content summarization and linear attention},
journal = {Neurocomputing},
volume = {630},
pages = {129692},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129692},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003649},
author = {Jun Ai and Haolin Li and Zhan Su and Fengyu Zhao},
keywords = {Content summary, Linear attention, Explainable recommendation algorithm, Vivaldi synthetic coordinate algorithm, Kolmogorov–Arnold neural network},
abstract = {Recommendation algorithms can alleviate the problem of information explosion and cater to the needs of users to quickly lock in preferred items, promote business development, and have important theoretical significance and broad theoretical value. Explainable recommendation algorithms can not only complete recommendation tasks, but also generate recommendation explanations, so that users can more easily accept preferences. Research related to natural language text generation has promoted the progress of explainable text generation technology for recommendation systems. This paper proposes an explainable recommendation algorithm based on content summarization and linear attention mechanism. The model uses the keyword extraction algorithm to extract key information from user comment text as an important feature of subsequent text generation tasks, and further introduces linear Transformer to improve the training speed of the model and enhance its scalability. In addition, the model also uses the Vivaldi synthetic coordinate algorithm to deeply mine user and item features and uses the Kolmogorov–Arnold neural network model to reduce the error of predicted ratings. Compared with existing leading algorithms, the algorithm in this paper has achieved significant improvements in text generation and recommendation rating prediction. This paper reveals that applying the linear attention mechanism to the explainable recommendation algorithm can greatly reduce the training cost and improve scalability, and the fusion of synthetic coordinates and attention can further mine the hidden information of the recommendation system, effectively improving the performance of the recommendation algorithm.}
}

@inproceedings{10.1145/3269206.3271739,
author = {Wang, Hongwei and Zhang, Fuzheng and Wang, Jialin and Zhao, Miao and Li, Wenjie and Xie, Xing and Guo, Minyi},
title = {RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems},
year = {2018},
isbn = {9781450360142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3269206.3271739},
doi = {10.1145/3269206.3271739},
abstract = {To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple "ripples" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.},
booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
pages = {417–426},
numpages = {10},
keywords = {knowledge graph, preference propagation, recommender systems},
location = {Torino, Italy},
series = {CIKM '18}
}

@inproceedings{10.1145/3357384.3357925,
author = {Song, Weiping and Shi, Chence and Xiao, Zhiping and Duan, Zhijian and Xu, Yewen and Zhang, Ming and Tang, Jian},
title = {AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357925},
doi = {10.1145/3357384.3357925},
abstract = {Click-through rate (CTR) prediction, which aims to predict the probability of a user clicking on an ad or an item, is critical to many online applications such as online advertising and recommender systems. The problem is very challenging since (1) the input features (e.g., the user id, user age, item id, item category) are usually sparse and high-dimensional, and (2) an effective prediction relies on high-order combinatorial features (a.k.a. cross features), which are very time-consuming to hand-craft by domain experts and are impossible to be enumerated. Therefore, there have been efforts in finding low-dimensional representations of the sparse and high-dimensional raw features and their meaningful combinations. In this paper, we propose an effective and efficient method called the AutoInt to automatically learn the high-order feature interactions of input features. Our proposed algorithm is very general, which can be applied to both numerical and categorical input features. Specifically, we map both the numerical and categorical features into the same low-dimensional space. Afterwards, a multi-head self-attentive neural network with residual connections is proposed to explicitly model the feature interactions in the low-dimensional space. With different layers of the multi-head self-attentive neural networks, different orders of feature combinations of input features can be modeled. The whole model can be efficiently fit on large-scale raw data in an end-to-end fashion. Experimental results on four real-world datasets show that our proposed approach not only outperforms existing state-of-the-art approaches for prediction but also offers good explainability. Code is available at: urlhttps://github.com/DeepGraphLearning/RecommenderSystems.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1161–1170},
numpages = {10},
keywords = {ctr prediction, explainable recommendation, high-order feature interactions, self attention},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1145/3219819.3219965,
author = {Hu, Binbin and Shi, Chuan and Zhao, Wayne Xin and Yu, Philip S.},
title = {Leveraging Meta-path based Context for Top- N Recommendation with A Neural Co-Attention Model},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219965},
doi = {10.1145/3219819.3219965},
abstract = {Heterogeneous information network (HIN) has been widely adopted in recommender systems due to its excellence in modeling complex context information. Although existing HIN based recommendation methods have achieved performance improvement to some extent, they have two major shortcomings. First, these models seldom learn an explicit representation for path or meta-path in the recommendation task. Second, they do not consider the mutual effect between the meta-path and the involved user-item pair in an interaction. To address these issues, we develop a novel deep neural network with the co-attention mechanism for leveraging rich meta-path based context for top-N recommendation. We elaborately design a three-way neural interaction model by explicitly incorporating meta-path based context. To construct the meta-path based context, we propose to use a priority based sampling technique to select high-quality path instances. Our model is able to learn effective representations for users, items and meta-path based context for implementing a powerful interaction function. The co-attention mechanism improves the representations for meta-path based con- text, users and items in a mutual enhancement way. Extensive experiments on three real-world datasets have demonstrated the effectiveness of the proposed model. In particular, the proposed model performs well in the cold-start scenario and has potentially good interpretability for the recommendation results.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
pages = {1531–1540},
numpages = {10},
keywords = {attention mechanism, deep learning, heterogeneous information network, recommender system},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3178876.3186070,
author = {Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
title = {Neural Attentional Rating Regression with Review-level Explanations},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186070},
doi = {10.1145/3178876.3186070},
abstract = {Reviews information is dominant for users to make online purchasing decisions in e-commerces. However, the usefulness of reviews is varied. We argue that less-useful reviews hurt model's performance, and are also less meaningful for user's reference. While some existing models utilize reviews for improving the performance of recommender systems, few of them consider the usefulness of reviews for recommendation quality. In this paper, we introduce a novel attention mechanism to explore the usefulness of reviews, and propose a Neural Attentional Regression model with Review-level Explanations (NARRE) for recommendation. Specifically, NARRE can not only predict precise ratings, but also learn the usefulness of each review simultaneously. Therefore, the highly-useful reviews are obtained which provide review-level explanations to help users make better and faster decisions. Extensive experiments on benchmark datasets of Amazon and Yelp on different domains show that the proposed NARRE model consistently outperforms the state-of-the-art recommendation approaches, including PMF, NMF, SVD++, HFT, and DeepCoNN in terms of rating prediction, by the proposed attention model that takes review usefulness into consideration. Furthermore, the selected reviews are shown to be effective when taking existing review-usefulness ratings in the system as ground truth. Besides, crowd-sourcing based evaluations reveal that in most cases, NARRE achieves equal or even better performances than system's usefulness rating method in selecting reviews. And it is flexible to offer great help on the dominant cases in real e-commerce scenarios when the ratings on review-usefulness are not available in the system.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1583–1592},
numpages = {10},
keywords = {explainable recommendation, neural attention network, recommender systems, review usefulness},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3308558.3313705,
author = {Cao, Yixin and Wang, Xiang and He, Xiangnan and Hu, Zikun and Chua, Tat-Seng},
title = {Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313705},
doi = {10.1145/3308558.3313705},
abstract = {Incorporating knowledge graph (KG) into recommender system is promising in improving the recommendation accuracy and explainability. However, existing methods largely assume that a KG is complete and simply transfer the ”knowledge” in KG at the shallow level of entity raw data or embeddings. This may lead to suboptimal performance, since a practical KG can hardly be complete, and it is common that a KG has missing facts, relations, and entities. Thus, we argue that it is crucial to consider the incomplete nature of KG when incorporating it into recommender system. In this paper, we jointly learn the model of recommendation and knowledge graph completion. Distinct from previous KG-based recommendation methods, we transfer the relation information in KG, so as to understand the reasons that a user likes an item. As an example, if a user has watched several movies directed by (relation) the same person (entity), we can infer that the director relation plays a critical role when the user makes the decision, thus help to understand the user's preference at a finer granularity. Technically, we contribute a new translation-based recommendation model, which specially accounts for various preferences in translating a user to an item, and then jointly train it with a KG completion model by combining several transfer schemes. Extensive experiments on two benchmark datasets show that our method outperforms state-of-the-art KG-based recommendation methods. Further analysis verifies the positive effect of joint training on both tasks of recommendation and KG completion, and the advantage of our model in understanding user preference. We publish our project at https://github.com/TaoMiner/joint-kg-recommender.},
booktitle = {The World Wide Web Conference},
pages = {151–161},
numpages = {11},
keywords = {Embedding, Item Recommendation, Joint Model, Knowledge Graph},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3397271.3401137,
author = {Wang, Xiang and Jin, Hongye and Zhang, An and He, Xiangnan and Xu, Tong and Chua, Tat-Seng},
title = {Disentangled Graph Collaborative Filtering},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401137},
doi = {10.1145/3397271.3401137},
abstract = {Learning informative representations of users and items from the interaction data is of crucial importance to collaborative filtering (CF). Present embedding functions exploit user-item relationships to enrich the representations, evolving from a single user-item instance to the holistic interaction graph. Nevertheless, they largely model the relationships in a uniform manner, while neglecting the diversity of user intents on adopting the items, which could be to pass time, for interest, or shopping for others like families. Such uniform approach to model user interests easily results in suboptimal representations, failing to model diverse relationships and disentangle user intents in representations.In this work, we pay special attention to user-item relationships at the finer granularity of user intents. We hence devise a new model, Disentangled Graph Collaborative Filtering (DGCF), to disentangle these factors and yield disentangled representations. Specifically, by modeling a distribution over intents for each user-item interaction, we iteratively refine the intent-aware interaction graphs and representations. Meanwhile, we encourage independence of different intents. This leads to disentangled representations, effectively distilling information pertinent to each intent. We conduct extensive experiments on three benchmark datasets, and DGCF achieves significant improvements over several state-of-the-art models like NGCF, DisenGCN, and MacridVAE. Further analyses offer insights into the advantages of DGCF on the disentanglement of user intents and interpretability of representations. Our codes are available in https://github.com/ xiangwang1223/disentangled_graph_collaborative_filtering.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1001–1010},
numpages = {10},
keywords = {collaborative filtering, disentangled representation learning, explainable recommendation, graph neural networks},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inproceedings{10.1145/3343031.3351034,
author = {Wei, Yinwei and Wang, Xiang and Nie, Liqiang and He, Xiangnan and Hong, Richang and Chua, Tat-Seng},
title = {MMGCN: Multi-modal Graph Convolution Network for Personalized Recommendation of Micro-video},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343031.3351034},
doi = {10.1145/3343031.3351034},
abstract = {Personalized recommendation plays a central role in many online content sharing platforms. To provide quality micro-video recommendation service, it is of crucial importance to consider the interactions between users and items (i.e. micro-videos) as well as the item contents from various modalities (e.g. visual, acoustic, and textual). Existing works on multimedia recommendation largely exploit multi-modal contents to enrich item representations, while less effort is made to leverage information interchange between users and items to enhance user representations and further capture user's fine-grained preferences on different modalities. In this paper, we propose to exploit user-item interactions to guide the representation learning in each modality, and further personalized micro-video recommendation. We design a Multi-modal Graph Convolution Network (MMGCN) framework built upon the message-passing idea of graph neural networks, which can yield modal-specific representations of users and micro-videos to better capture user preferences. Specifically, we construct a user-item bipartite graph in each modality, and enrich the representation of each node with the topological structure and features of its neighbors. Through extensive experiments on three publicly available datasets, Tiktok, Kwai, and MovieLens, we demonstrate that our proposed model is able to significantly outperform state-of-the-art multi-modal recommendation methods.},
booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
pages = {1437–1445},
numpages = {9},
keywords = {graph convolution network, micro-video understanding, multi-modal recommendation},
location = {Nice, France},
series = {MM '19}
}

@inproceedings{10.1145/2806416.2806504,
author = {He, Xiangnan and Chen, Tao and Kan, Min-Yen and Chen, Xiao},
title = {TriRank: Review-aware Explainable Recommendation by Modeling Aspects},
year = {2015},
isbn = {9781450337946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806416.2806504},
doi = {10.1145/2806416.2806504},
abstract = {Most existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions.},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
pages = {1661–1670},
numpages = {10},
keywords = {aspects, comments, explanable recommendation, reviews, top-n recommendation, tripartite graph ranking},
location = {Melbourne, Australia},
series = {CIKM '15}
}

@inproceedings{10.1145/3159652.3159668,
author = {Chen, Xu and Xu, Hongteng and Zhang, Yongfeng and Tang, Jiaxi and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
title = {Sequential Recommendation with User Memory Networks},
year = {2018},
isbn = {9781450355810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159652.3159668},
doi = {10.1145/3159652.3159668},
abstract = {User preferences are usually dynamic in real-world recommender systems, and a user»s historical behavior records may not be equally important when predicting his/her future interests. Existing recommendation algorithms -- including both shallow and deep approaches -- usually embed a user»s historical records into a single latent vector/representation, which may have lost the per item- or feature-level correlations between a user»s historical records and future interests. In this paper, we aim to express, store, and manipulate users» historical records in a more explicit, dynamic, and effective manner. To do so, we introduce the memory mechanism to recommender systems. Specifically, we design a memory-augmented neural network (MANN) integrated with the insights of collaborative filtering for recommendation. By leveraging the external memory matrix in MANN, we store and update users» historical records explicitly, which enhances the expressiveness of the model. We further adapt our framework to both item- and feature-level versions, and design the corresponding memory reading/writing operations according to the nature of personalized recommendation scenarios. Compared with state-of-the-art methods that consider users» sequential behavior for recommendation, e.g., sequential recommenders with recurrent neural networks (RNN) or Markov chains, our method achieves significantly and consistently better performance on four real-world datasets. Moreover, experimental analyses show that our method is able to extract the intuitive patterns of how users» future actions are affected by previous behaviors.},
booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
pages = {108–116},
numpages = {9},
keywords = {collaborative filtering, memory networks, sequential recommendation},
location = {Marina Del Rey, CA, USA},
series = {WSDM '18}
}

@inproceedings{10.1145/3109859.3109890,
author = {Seo, Sungyong and Huang, Jing and Yang, Hao and Liu, Yan},
title = {Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction},
year = {2017},
isbn = {9781450346528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109859.3109890},
doi = {10.1145/3109859.3109890},
abstract = {Recently, many e-commerce websites have encouraged their users to rate shopping items and write review texts. This review information has been very useful for understanding user preferences and item properties, as well as enhancing the capability to make personalized recommendations of these websites. In this paper, we propose to model user preferences and item properties using convolutional neural networks (CNNs) with dual local and global attention, motivated by the superiority of CNNs to extract complex features. By using aggregated review texts from a user and aggregated review text for an item, our model can learn the unique features (embedding) of each user and each item. These features are then used to predict ratings. We train these user and item networks jointly which enable the interaction between users and items in a similar way as matrix factorization. The local attention provides us insight on a user's preferences or an item's properties. The global attention helps CNNs focus on the semantic meaning of the whole review text. Thus, the combined local and global attentions enable an interpretable and better-learned representation of users and items. We validate the proposed models by testing on popular review datasets in Yelp and Amazon and compare the results with matrix factorization (MF), the hidden factor and topical (HFT) model, and the recently proposed convolutional matrix factorization (ConvMF+). Our proposed CNNs with dual attention model outperforms HFT and ConvMF+ in terms of mean square errors (MSE). In addition, we compare the user/item embeddings learned from these models for classification and recommendation. These results also confirm the superior quality of user/item embeddings learned from our model.},
booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
pages = {297–305},
numpages = {9},
keywords = {attention model, convolutional neural network, deep learning for recommender systems},
location = {Como, Italy},
series = {RecSys '17}
}

@inproceedings{10.1145/3331184.3331203,
author = {Xian, Yikun and Fu, Zuohui and Muthukrishnan, S. and de Melo, Gerard and Zhang, Yongfeng},
title = {Reinforcement Knowledge Graph Reasoning for Explainable Recommendation},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331203},
doi = {10.1145/3331184.3331203},
abstract = {Recent advances in personalized recommendation have sparked great interest in the exploitation of rich structured information provided by knowledge graphs. Unlike most existing approaches that only focus on leveraging knowledge graphs for more accurate recommendation, we aim to conduct explicit reasoning with knowledge for decision making so that the recommendations are generated and supported by an interpretable causal inference procedure. To this end, we propose a method called Policy-Guided Path Reasoning (PGPR), which couples recommendation and interpretability by providing actual paths in a knowledge graph. Our contributions include four aspects. We first highlight the significance of incorporating knowledge graphs into recommendation to formally define and interpret the reasoning process. Second, we propose a reinforcement learning (RL) approach featured by an innovative soft reward strategy, user-conditional action pruning and a multi-hop scoring function. Third, we design a policy-guided graph search algorithm to efficiently and effectively sample reasoning paths for recommendation. Finally, we extensively evaluate our method on several large-scale real-world benchmark datasets, obtaining favorable results compared with state-of-the-art methods.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {285–294},
numpages = {10},
keywords = {explainability, knowledge graphs, recommendation system, reinforcement learning},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3442381.3450133,
author = {Wang, Xiang and Huang, Tinglin and Wang, Dingxian and Yuan, Yancheng and Liu, Zhenguang and He, Xiangnan and Chua, Tat-Seng},
title = {Learning Intents behind Interactions with Knowledge Graph for Recommendation},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450133},
doi = {10.1145/3442381.3450133},
abstract = {Knowledge graph (KG) plays an increasingly important role in recommender systems. A recent technical trend is to develop end-to-end models founded on graph neural networks (GNNs). However, existing GNN-based models are coarse-grained in relational modeling, failing to (1) identify user-item relation at a fine-grained level of intents, and (2) exploit relation dependencies to preserve the semantics of long-range connectivity. In this study, we explore intents behind a user-item interaction by using auxiliary item knowledge, and propose a new model, Knowledge Graph-based Intent Network (KGIN). Technically, we model each intent as an attentive combination of KG relations, encouraging the independence of different intents for better model capability and interpretability. Furthermore, we devise a new information aggregation scheme for GNN, which recursively integrates the relation sequences of long-range connectivity (i.e., relational paths). This scheme allows us to distill useful information about user intents and encode them into the representations of users and items. Experimental results on three benchmark datasets show that, KGIN achieves significant improvements over the state-of-the-art methods like KGAT&nbsp;[41], KGNN-LS&nbsp;[38], and CKAN&nbsp;[47]. Further analyses show that KGIN offers interpretable explanations for predictions by identifying influential intents and relational paths. The implementations are available at https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {878–887},
numpages = {10},
keywords = {Graph Neural Networks, Knowledge Graph, Recommendation},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3178876.3186145,
author = {Cheng, Zhiyong and Ding, Ying and Zhu, Lei and Kankanhalli, Mohan},
title = {Aspect-Aware Latent Factor Model: Rating Prediction with Ratings and Reviews},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186145},
doi = {10.1145/3178876.3186145},
abstract = {Although latent factor models (e.g., matrix factorization) achieve good accuracy in rating prediction, they suffer from several problems including cold-start, non-transparency, and suboptimal recommendation for local users or items. In this paper, we employ textual review information with ratings to tackle these limitations. Firstly, we apply a proposed aspect-aware topic model (ATM) on the review text to model user preferences and item features from different aspects, and estimate the aspect importance of a user towards an item. The aspect importance is then integrated into a novel aspect-aware latent factor model (ALFM), which learns user's and item's latent factors based on ratings. In particular, ALFM introduces a weighted matrix to associate those latent factors with the same set of aspects discovered by ATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, an aspect rating is weighted by an aspect importance, which is dependent on the targeted user's preferences and targeted item's features. Therefore, it is expected that the proposed method can model a user's preferences on an item more accurately for each user-item pair locally. Comprehensive experimental studies have been conducted on 19 datasets from Amazon and Yelp 2017 Challenge dataset. Results show that our method achieves significant improvement compared with strong baseline methods, especially for users with only few ratings. Moreover, our model could interpret the recommendation results in depth.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {639–648},
numpages = {10},
keywords = {aspect-aware, matrix factorization, recommendation, review-aware, topic model},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3178876.3186154,
author = {Tay, Yi and Anh Tuan, Luu and Hui, Siu Cheung},
title = {Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186154},
doi = {10.1145/3178876.3186154},
abstract = {This paper proposes a new neural architecture for collaborative ranking with implicit feedback. Our model, LRML (Latent Relational Metric Learning) is a novel metric learning approach for recommendation. More specifically, instead of simple push-pull mechanisms between user and item pairs, we propose to learn latent relations that describe each user item interaction. This helps to alleviate the potential geometric inflexibility of existing metric learning approaches. This enables not only better performance but also a greater extent of modeling capability, allowing our model to scale to a larger number of interactions. In order to do so, we employ a augmented memory module and learn to attend over these memory blocks to construct latent relations. The memory-based attention module is controlled by the user-item interaction, making the learned relation vector specific to each user-item pair. Hence, this can be interpreted as learning an exclusive and optimal relational translation for each user-item interaction. The proposed architecture demonstrates the state-of-the-art performance across multiple recommendation benchmarks. LRML outperforms other metric learning models by 6\%-7.5\% in terms of Hits@10 and nDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover, qualitative studies also demonstrate evidence that our proposed model is able to infer and encode explicit sentiment, temporal and attribute information despite being only trained on implicit feedback. As such, this ascertains the ability of LRML to uncover hidden relational structure within implicit datasets.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {729–739},
numpages = {11},
keywords = {attention mechanism, collaborative filtering, collaborative ranking, deep learning, implicit feedback, information retrieval, neural networks, recommender system},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3442381.3449788,
author = {Zheng, Yu and Gao, Chen and Li, Xiang and He, Xiangnan and Li, Yong and Jin, Depeng},
title = {Disentangling User Interest and Conformity for Recommendation with Causal Embedding},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449788},
doi = {10.1145/3442381.3449788},
abstract = {Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users’ conformity towards popular items, which entangles users’ real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {2980–2991},
numpages = {12},
keywords = {Recommender systems, causal embedding, popularity bias},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3631700.3665226,
author = {Afreen, Neda and Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Malloci, Francesca Maridina and Marras, Mirko and Martis, Andrea Giovanni},
title = {Learner-centered Ontology for Explainable Educational Recommendation},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665226},
doi = {10.1145/3631700.3665226},
abstract = {Ontologies form the core of knowledge graphs, which act as faithful, semantic-rich sources for training models in delivering explainable recommendations. These models learn to extract logical paths between learners and resources to be recommended within the knowledge graph, according to behavior- and content-based patterns. Extracted paths are then used not only to provide recommendations, but also to generate accompanying textual explanations. Despite the potential of this approach, current ontologies derived from the traditional learner-resource interaction data fall short in terms of richness from an educational perspective. Conversely, general-purpose ontologies, while comprehensive in educational aspects, are overly complex for recommendation tasks. Unfortunately, a suboptimal ontology might prevent to articulate reasoning paths, and thus explanations, relevant for learners within the knowledge graph. To counter this limitation, in this paper, we propose LOXER, a novel ontology designed to unlock learner-centered logical paths for explainable educational recommendation. Our design integrates insights from diverse sources, including feedback from a local co-design group of learners, observations from specialized traditional large-scale educational recommendation datasets, and connections with well-known vocabularies of other existing ontologies. To validate our ontology, we conducted an evaluation of the explanation types it enables, involving university and lifelong learners and assessing explanation properties like effectiveness, decision-making speed, motivation, satisfaction, and confidence. Results show our ontology’s ability to foster diverse considerations during the learners’ decision-making process and to establish a semantic structure for knowledge graphs for explainable recommendation.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {567–575},
numpages = {9},
keywords = {Explainability., Ontology, Recommendation},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3637528.3671781,
author = {Zhang, Jingsen and Tang, Jiakai and Chen, Xu and Yu, Wenhui and Hu, Lantao and Jiang, Peng and Li, Han},
title = {Natural Language Explainable Recommendation with Robustness Enhancement},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671781},
doi = {10.1145/3637528.3671781},
abstract = {Natural language explainable recommendation has become a promising direction to facilitate more efficient and informed user decisions. Previous models mostly focus on how to enhance the explanation accuracy. However, the robustness problem has been largely ignored, which requires the explanations generated for similar user-item pairs should not be too much different. Different from traditional classification problems, improving the robustness of natural languages has two unique characteristics: (1) Different token importances, that is, different tokens play various roles in representing the complete sentence, and the robustness requirements for predicting them should also be different. (2) Continuous token semantics, that is, the similarity of the output should be judged based on semantics, and the sequences without any token-level overlap may also be highly similar. Based on these characteristics, we formulate and solve a novel problem in the recommendation domain, that is, robust natural language explainable recommendation. To the best of our knowledge, it is the first time in this field. Specifically, we base our modeling on adversarial robust optimization and design four types of heuristic methods to modify the adversarial outputs with weighted token probabilities and synonym replacements. Furthermore, to consider the mutual influence between the above characteristics, we regard language generation as a decision-making problem and design a dual-policy reinforcement learning framework to improve the robustness of the generated languages. We conduct extensive experiments to demonstrate the effectiveness of our framework.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4203–4212},
numpages = {10},
keywords = {adversarial learning, explainable recommendation, natural language explanations},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3640457.3688069,
author = {Ariza-Casabona, Alejandro and Boratto, Ludovico and Salam\'{o}, Maria},
title = {A Comparative Analysis of Text-Based Explainable Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688069},
doi = {10.1145/3640457.3688069},
abstract = {One way to increase trust among users towards recommender systems is to provide the recommendation along with a textual explanation. In the literature, extraction-based, generation-based, and, more recently, hybrid solutions based on retrieval-augmented generation have been proposed to tackle the problem of text-based explainable recommendation. However, the use of different datasets, preprocessing steps, target explanations, baselines, and evaluation metrics complicates the reproducibility and state-of-the-art assessment of previous work among different model categories for successful advancements in the field. Our aim is to provide a comprehensive analysis of text-based explainable recommender systems by setting up a well-defined benchmark that accommodates generation-based, extraction-based, and hybrid approaches. Also, we enrich the existing evaluation of explainability and text quality of the explanations with a novel definition of feature hallucination. Our experiments on three real-world datasets unveil hidden behaviors and confirm several claims about model patterns. Our source code and preprocessed datasets are available at https://github.com/alarca94/text-exp-recsys24.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {105–115},
numpages = {11},
keywords = {Explainable Recommendation, Feature Hallucination, Natural Language Explanations, Reproducibility},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3543507.3583260,
author = {Zhang, Jingsen and Chen, Xu and Tang, Jiakai and Shao, Weiqi and Dai, Quanyu and Dong, Zhenhua and Zhang, Rui},
title = {Recommendation with Causality enhanced Natural Language Explanations},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583260},
doi = {10.1145/3543507.3583260},
abstract = {Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {876–886},
numpages = {11},
keywords = {Explainable Recommendation, Natural Language Explanations},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3624918.3625331,
author = {Yu, Yi and Sugiyama, Kazunari and Jatowt, Adam},
title = {AdaReX: Cross-Domain, Adaptive, and Explainable Recommender System},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625331},
doi = {10.1145/3624918.3625331},
abstract = {Explainability is an inherent issue of recommender systems and has received a lot of attention recently. Generative explainable recommendation, which provides personalized explanations by generating textual rationales, is emerging as an effective solution. Despite promising, current methods face limitations in their reliance on dense training data, which hinders the generalizability of explainable recommender systems. Our work tackles a novel problem of cross-domain explainable recommendation aiming to extend the generalizability of explainable recommender systems. To solve this, we propose a novel approach that models aspects extracted from past reviews, to empower the explainable recommender systems by leveraging knowledge from other domains. Specifically, we propose AdaReX (Adaptive eXplainable Recommendation), to model auxiliary and target domains simultaneously. By performing specific tasks in respective domains and their interconnection via a discriminator model, AdaReX allows the aspect sequences to learn common knowledge across different domains and tasks. Furthermore, through our proposed optimization objective, the learning of aspect sequence is deeply cross-interacted with in-domain users and items’ latent factors, enabling the enhanced sharing of knowledge between domains. Our extensive experiments on real datasets demonstrate that our approach not only generates better explanations and recommendations for sparse users but also improves performance for general users.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {272–281},
numpages = {10},
keywords = {Explainable Recommender System, Natural Language Generation},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.1145/3485447.3511937,
author = {Geng, Shijie and Fu, Zuohui and Tan, Juntao and Ge, Yingqiang and de Melo, Gerard and Zhang, Yongfeng},
title = {Path Language Modeling over Knowledge Graphsfor Explainable Recommendation},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3511937},
doi = {10.1145/3485447.3511937},
abstract = {To facilitate human decisions with credible suggestions, personalized recommender systems should have the ability to generate corresponding explanations while making recommendations. Knowledge graphs (KG), which contain comprehensive information about users and products, are widely used to enable this. By reasoning over a KG in a node-by-node manner, existing explainable models provide a KG-grounded path for each user-recommended item. Such paths serve as an explanation and reflect the historical behavior pattern of the user. However, not all items can be reached following the connections within the constructed KG under finite hops. Hence, previous approaches are constrained by a recall bias in terms of existing connectivity of KG structures. To overcome this, we propose a novel Path Language Modeling Recommendation (PLM-Rec) framework, learning a language model over KG paths consisting of entities and edges. Through path sequence decoding, PLM-Rec unifies recommendation and explanation in a single step and fulfills them simultaneously. As a result, PLM-Rec not only captures the user behaviors but also eliminates the restriction to pre-existing KG connections, thereby alleviating the aforementioned recall bias. Moreover, the proposed technique makes it possible to conduct explainable recommendation even when the KG is sparse or possesses a large number of relations. Experiments and extensive ablation studies on three Amazon e-commerce datasets demonstrate the effectiveness and explainability of the PLM-Rec framework.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {946–955},
numpages = {10},
keywords = {Explainable Recommendation, Knowledge Graph, Path Language Model, Recall Bias, Recommender Systems},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3640457.3688075,
author = {Zhang, Xiaoyu and Li, Yishan and Wang, Jiayin and Sun, Bowen and Ma, Weizhi and Sun, Peijie and Zhang, Min},
title = {Large Language Models as Evaluators for Recommendation Explanations},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688075},
doi = {10.1145/3640457.3688075},
abstract = {The explainability of recommender systems has attracted significant attention in academia and industry. Many efforts have been made for explainable recommendations, yet evaluating the quality of the explanations remains a challenging and unresolved issue. In recent years, leveraging LLMs as evaluators presents a promising avenue in Natural Language Processing tasks (e.g., sentiment classification, information extraction), as they perform strong capabilities in instruction following and common-sense reasoning. However, evaluating recommendation explanatory texts is different from these NLG tasks, as its criteria are related to human perceptions and are usually subjective. In this paper, we investigate whether LLMs can serve as evaluators of recommendation explanations. To answer the question, we utilize real user feedback on explanations given from previous work and additionally collect third-party annotations and LLM evaluations. We design and apply a 3-level meta-evaluation strategy to measure the correlation between evaluator labels and the ground truth provided by users. Our experiments reveal that LLMs, such as GPT4, can provide comparable evaluations with appropriate prompts and settings. We also provide further insights into combining human labels with the LLM evaluation process and utilizing ensembles of multiple heterogeneous LLM evaluators to enhance the accuracy and stability of evaluations. Our study verifies that utilizing LLMs as evaluators can be an accurate, reproducible and cost-effective solution for evaluating recommendation explanation texts. Our code is available here1.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {33–42},
numpages = {10},
keywords = {Evaluation, Explainable Recommendation, Large Language Model},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3485447.3512029,
author = {Pan, Sicheng and Li, Dongsheng and Gu, Hansu and Lu, Tun and Luo, Xufang and Gu, Ning},
title = {Accurate and Explainable Recommendation via Review Rationalization},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512029},
doi = {10.1145/3485447.3512029},
abstract = {Auxiliary information, such as reviews, have been widely adopted to improve collaborative filtering (CF) algorithms, e.g., to boost the accuracy and provide explanations. However, most of the existing methods cannot distinguish between co-appearance and causality when learning from the reviews, so that they may rely on spurious correlations rather than causal relations in the recommendation — leading to poor generalization performance and unconvincing explanations. In this paper, we propose a Recommendation via Review Rationalization (R3) method including 1) a rationale generator to extract rationales from reviews to alleviate the effects of spurious correlations; 2) a rationale predictor to predict user ratings on items only from generated rationales; and 3) a correlation predictor upon both rationales and correlational features to ensure conditional independence between spurious correlations and rating predictions given causal rationales. Extensive experiments on real-world datasets show that the proposed method can achieve better generalization performance than state-of-the-art CF methods and provide causal-aware explanations even when the test data distribution changes.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3092–3101},
numpages = {10},
keywords = {explainability, rationalization, recommendation},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3604915.3609491,
author = {B\"{o}lz, Felix and Nurbakova, Diana and Calabretto, Sylvie and Gerl, Armin and Brunie, Lionel and Kosch, Harald},
title = {HUMMUS: A Linked, Healthiness-Aware, User-centered and Argument-Enabling Recipe Data Set for Recommendation},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3609491},
doi = {10.1145/3604915.3609491},
abstract = {The overweight and obesity rate is increasing for decades worldwide. Healthy nutrition is, besides education and physical activity, one of the various keys to tackle this issue. In an effort to increase the availability of digital, healthy recommendations, the scientific area of food recommendation extends its focus from the accuracy of the recommendations to beyond-accuracy goals like transparency and healthiness. To address this issue a data basis is required, which in the ideal case encompasses user-item interactions like ratings and reviews, food-related information such as recipe details, nutritional data, and in the best case additional data which describes the food items and their relations semantically. Though several recipe recommendation data sets exist, to the best of our knowledge, a holistic large-scale healthiness-aware and connected data sets have not been made available yet. The lack of such data could partially explain the poor popularity of the topic of healthy food recommendation when compared to the domain of movie recommendation. In this paper, we show that taking into account only user-item interactions is not sufficient for a recommendation. To close this gap, we propose a connected data set called HUMMUS (Health-aware User-centered recoMMendation and argUment-enabling data Set) collected from Food.com containing multiple features including rich nutrient information, text reviews, and ratings, enriched by the authors with extra features such as Nutri-scores and connections to semantic data like the FoodKG and the FoodOn ontology. We hope that these data will contribute to the healthy food recommendation domain.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {1–11},
numpages = {11},
keywords = {Explainable recommendation, Healthiness-aware recommendation, Knowledge graph, Nutrition scores, Recipe data set},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3539618.3591884,
author = {Guo, Shuyu and Zhang, Shuo and Sun, Weiwei and Ren, Pengjie and Chen, Zhumin and Ren, Zhaochun},
title = {Towards Explainable Conversational Recommender Systems},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591884},
doi = {10.1145/3539618.3591884},
abstract = {Explanations in conventional recommender systems have demonstrated benefits in helping the user understand the rationality of the recommendations and improving the system's efficiency, transparency, and trustworthiness. In the conversational environment, multiple contextualized explanations need to be generated, which poses further challenges for explanations. To better measure explainability in CRS, we propose ten evaluation perspectives based on the concepts from conventional recommender systems together with the characteristics of CRS. We assess five existing CRS benchmark datasets using these metrics and observe the necessity of improving the explanation quality of CRS. To achieve this, we conduct manual and automatic approaches to extend these dialogues and construct a new CRS dataset, namely Explainable Recommendation Dialogues (E-ReDial). It includes 756 dialogues with over 2,000 high-quality rewritten explanations. We compare two baseline approaches to perform explanation generation based on E-ReDial. Experimental results suggest that models trained on E-ReDial can significantly improve explainability while introducing knowledge into the models can further improve the performance. GPT-3 in the in-context learning setting can generate more realistic and diverse movie descriptions. In contrast, T5 training on E-Redial can better generate clear reasons for recommendations based on user preferences. E-ReDial is available at https://github.com/Superbooming/E-ReDial.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2786–2795},
numpages = {10},
keywords = {conversational information access, conversational recommendation, explainable recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3636555.3636898,
author = {Frej, Jibril and Shah, Neel and Knezevic, Marta and Nazaretsky, Tanya and K\"{a}ser, Tanja},
title = {Finding Paths for Explainable MOOC Recommendation: A Learner Perspective},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636898},
doi = {10.1145/3636555.3636898},
abstract = {The increasing availability of Massive Open Online Courses (MOOCs) has created a necessity for personalized course recommendation systems. These systems often combine neural networks with Knowledge Graphs (KGs) to achieve richer representations of learners and courses. While these enriched representations allow more accurate and personalized recommendations, explainability remains a significant challenge which is especially problematic for certain domains with significant impact such as education and online learning. Recently, a novel class of recommender systems that uses reinforcement learning and graph reasoning over KGs has been proposed to generate explainable recommendations in the form of paths over a KG. Despite their accuracy and interpretability on e-commerce datasets, these approaches have scarcely been applied to the educational domain and their use in practice has not been studied. In this work, we propose an explainable recommendation system for MOOCs that uses graph reasoning. To validate the practical implications of our approach, we conducted a user study examining user perceptions of our new explainable recommendations. We demonstrate the generalizability of our approach by conducting experiments on two educational datasets: COCO and Xuetang.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {426–437},
numpages = {12},
keywords = {Explainable AI, MOOCs, Recommendation, User study},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3616855.3635855,
author = {Liu, Xu and Yu, Tong and Xie, Kaige and Wu, Junda and Li, Shuai},
title = {Interact with the Explanations: Causal Debiased Explainable Recommendation System},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635855},
doi = {10.1145/3616855.3635855},
abstract = {In recent years, the field of recommendation systems has witnessed significant advancements, with explainable recommendation systems gaining prominence as a crucial area of research. These systems aim to enhance user experience by providing transparent and compelling recommendations, accompanied by explanations. However, a persistent challenge lies in addressing biases that can influence the recommendations and explanations offered by these systems. Such biases often stem from a tendency to favor popular items and generate explanations that highlight their common attributes, thereby deviating from the objective of delivering personalized recommendations and explanations. While existing debiasing methods have been applied in explainable recommendation systems, they often overlook the model-generated explanations in tackling biases. Consequently, biases in model-generated explanations may persist, potentially compromising system performance and user satisfaction.To address biases in both model-generated explanations and recommended items, we discern the impact of model-generated explanations in recommendation through a formulated causal graph. Inspired by this causal perspective, we propose a novel approach termed Causal Explainable Recommendation System (CERS), which incorporates model-generated explanations into the debiasing process and enacts causal interventions based on user feedback on the explanations. By utilizing model-generated explanations as intermediaries between user-item interactions and recommendation results, we adeptly mitigate the biases via targeted causal interventions. Experimental results demonstrate the efficacy of CERS in reducing popularity bias while simultaneously improving recommendation performance, leading to more personalized and tailored recommendations. Human evaluation further affirms that CERS generates explanations tailored to individual users, thereby enhancing the persuasiveness of the system.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {472–481},
numpages = {10},
keywords = {causal reasoning, debiased recommendation, explainable recommendation system},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3477495.3531873,
author = {Radlinski, Filip and Balog, Krisztian and Diaz, Fernando and Dixon, Lucas and Wedin, Ben},
title = {On Natural Language User Profiles for Transparent and Scrutable Recommendation},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531873},
doi = {10.1145/3477495.3531873},
abstract = {Natural interaction with recommendation and personalized search systems has received tremendous attention in recent years. We focus on the challenge of supporting people's understanding and control of these systems and explore a fundamentally new way of thinking about representation of knowledge in recommendation and personalization systems. Specifically, we argue that it may be both desirable and possible for algorithms that use natural language representations of users' preferences to be developed. We make the case that this could provide significantly greater transparency, as well as affordances for practical actionable interrogation of, and control over, recommendations. Moreover, we argue that such an approach, if successfully applied, may enable a major step towards systems that rely less on noisy implicit observations while increasing portability of knowledge of one's interests.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2863–2874},
numpages = {12},
keywords = {natural language, recommendation, scrutability, transparency},
location = {Madrid, Spain},
series = {SIGIR '22}
}

@inproceedings{10.1145/3539618.3591776,
author = {Shuai, Jie and Wu, Le and Zhang, Kun and Sun, Peijie and Hong, Richang and Wang, Meng},
title = {Topic-enhanced Graph Neural Networks for Extraction-based Explainable Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591776},
doi = {10.1145/3539618.3591776},
abstract = {Review information has been demonstrated beneficial for the explainable recommendation. It can be treated as training corpora for generation-based methods or knowledge bases for extraction-based models. However, for generation-based methods, the sparsity of user-generated reviews and the high complexity of generative language models lead to a lack of personalization and adaptability. For extraction-based methods, focusing only on relevant attributes makes them invalid in situations where explicit attribute words are absent, limiting the potential of extraction-based models.To this end, in this paper, we focus on the explicit and implicit analysis of review information simultaneously and propose novel a Topic-enhanced Graph Neural Networks (TGNN) to fully explore review information for better explainable recommendations. To be specific, we first use a pre-trained topic model to analyze reviews at the topic level, and design a sentence-enhanced topic graph to model user preference explicitly, where topics are intermediate nodes between users and items. Corresponding sentences serve as edge features. Thus, the requirement of explicit attribute words can be mitigated. Meanwhile, we leverage a review-enhanced rating graph to model user preference implicitly, where reviews are also considered as edge features for fine-grained user-item interaction modeling. Next, user and item representations from two graphs are used for final rating prediction and explanation extraction. Extensive experiments on three real-world datasets demonstrate the superiority of our proposed TGNN with both recommendation accuracy and explanation quality.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1188–1197},
numpages = {10},
keywords = {explainable recommendation, graph neural network, review-based recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3617023.3617052,
author = {Suarez Mariscal, Claudia and de Lima, Bruno Santana Massena and Galante, Renata and Cordeiro, Weverton},
title = {Assessing Explainable Recommendations from Knowledge Graph-based in an International Streaming Platform},
year = {2023},
isbn = {9798400709081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617023.3617052},
doi = {10.1145/3617023.3617052},
abstract = {Explainable recommendations can increase users’ confidence in the results provided by recommendation systems by providing justifications of why a certain item is recommended. In this way, the use of the Knowledge Graph (KG) guarantees an optimal organization of the data enabling one to trace the relationships between entities (users, recommended items, item attributes and features, and so on). Current proposals use different approaches such as embedding, connection, and propagation to deal with common problems that persist when generating recommendations, such as cold start or data lake. However, the complexity of recommendation models seems to increase when there is a large amount of data. In this work, we propose an analysis of the applicability of different frameworks based on knowledge graphs to obtain explanatory recommendations using a large dataset from an international streaming platform, with the idea of knowing the advantages and limitations of each approach to validate if complex models should really be used to obtain the best results. Through the experimentation of RippleNet, KGCN, KGAT, ECFKG, and DSKE, we focus on dataset structure, category-based, and refinement type of each framework. To conclude, we provide details on some general points of the evaluation of all frameworks using our dataset.},
booktitle = {Proceedings of the 29th Brazilian Symposium on Multimedia and the Web},
pages = {213–220},
numpages = {8},
keywords = {Connection-based model, Embedding-based model, Explainable recommendation, Knowledge Graph, Propagation-based model},
location = {Ribeir\~{a}o Preto, Brazil},
series = {WebMedia '23}
}

@Comment{jabref-meta: databaseType:bibtex;}
