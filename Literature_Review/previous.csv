BibliographyType,ISBN,Identifier,Author,Title,Journal,Volume,Number,Month,Pages,Year,Address,Note,URL,Booktitle,Chapter,Edition,Series,Editor,Publisher,ReportType,Howpublished,Institution,Organizations,School,Annote,Custom1,Custom2,Custom3,Custom4,Custom5,Journal_Book
7,,takami_flanagan_dai_ogata_2023,"Takami, Kyosuke; Flanagan, Brendan; Dai, Yiling; Ogata, Hiroaki",Personality-based tailored explainable recommendation for trustworthy smart learning system in the age of artificial intelligence,Smart Learning Environments,10.0,1.0,,,2023,,,,,,,,,Smart Learning Environments,,,,,,,,,,,,Smart Learning Environments
7,,lin_zhang_lin_zeng_zhou_wu_2024,"Lin, Yuanguo; Zhang, Wei; Lin, Fan; Zeng, Wenhua; Zhou, Xiuze; Wu, Pengcheng",Knowledge-aware reasoning with self-supervised reinforcement learning for explainable recommendation in MOOCs,Neural Computing and Applications,36.0,8.0,,4115–4132,2024,,,,,,,,,Neural Computing and Applications,,,,,,,,,,,,Neural Computing and Applications
5,,zanon_da_rocha_manzato_2024,"Zanon, André Levi; Da Rocha, Leonardo Chaves Dutra; Manzato, Marcelo Garcia",Model-Agnostic Knowledge Graph Embedding Explanations for Recommender Systems,,,,,3–27,2024,,,,Communications in Computer and Information Science,,,,,Communications in Computer and Information Science,,,,,,,,,,,,Communications in Computer and Information Science
5,,samih_ghadi_fennan_2023,"Samih, Amina; Ghadi, Abderrahim; Fennan, Abdelhadi",Knowledge Embeddings for Explainable Recommendation,,,,,116–126,2023,,,,Lecture Notes in Networks and Systems,,,,,Lecture Notes in Networks and Systems,,,,,,,,,,,,Lecture Notes in Networks and Systems
5,,li_liu_zhang_kou_liu_qu_2025,"Li, Dong; Liu, Zhicong; Zhang, Qingyu; Kou, Yue; Liu, Tingting; Qu, Haoran",Integrating User Sentiment and Behavior for Explainable Recommendation,,,,,135–148,2025,,,,Communications in Computer and Information Science,,,,,Communications in Computer and Information Science,,,,,,,,,,,,Communications in Computer and Information Science
7,,wen_liu_jing_yu_2024,"Wen, Jingxuan; Liu, Huafeng; Jing, Liping; Yu, Jian",Learning-based counterfactual explanations for recommendation,Science China Information Sciences,67.0,8.0,,,2024,,,,,,,,,Science China Information Sciences,,,,,,,,,,,,Science China Information Sciences
5,,long_jin_2024,"Long, Xiuhua; Jin, Ting",Prompt Tuning Models on Sentiment-Aware for Explainable Recommendation,,,,,116–132,2024,,,,Lecture Notes in Computer Science,,,,,Lecture Notes in Computer Science,,,,,,,,,,,,Lecture Notes in Computer Science
5,,jendal_le_lauw_lissandrini_dolog_hose_2024,"Jendal, Theis E.; Le, Trung-Hoang; Lauw, Hady W.; Lissandrini, Matteo; Dolog, Peter; Hose, Katja",Hypergraphs with Attention on Reviews for Explainable Recommendation,,,,,230–246,2024,,,,Lecture Notes in Computer Science,,,,,Lecture Notes in Computer Science,,,,,,,,,,,,Lecture Notes in Computer Science
5,,zhong_negre_2022,"Zhong, Jinfeng; Negre, Elsa",Context-Aware Explanations in Recommender Systems,,,,,76–85,2022,,,,Lecture Notes in Networks and Systems,,,,,Lecture Notes in Networks and Systems,,,,,,,,,,,,Lecture Notes in Networks and Systems
7,,alizadeh_noughabi_behkamal_zarrinkalam_kahani_2024,"Alizadeh Noughabi, Havva; Behkamal, Behshid; Zarrinkalam, Fattane; Kahani, Mohsen",Persuasive explanations for path reasoning recommendations,Journal of Intelligent Information Systems,,,,,2024,,,,,,,,,Journal of Intelligent Information Systems,,,,,,,,,,,,Journal of Intelligent Information Systems
5,,zhang_zhu_wang_2023,"Zhang, Tingxuan; Zhu, Li; Wang, Jie",Neighborhood Constraints Based Bayesian Personalized Ranking for Explainable Recommendation,,,,,166–173,2023,,,,Lecture Notes in Computer Science,,,,,Lecture Notes in Computer Science,,,,,,,,,,,,Lecture Notes in Computer Science
7,,zheng_chen_cao_peng_huang_2024,"Zheng, Jianxing; Chen, Sen; Cao, Feng; Peng, Furong; Huang, Mingqing",Explainable recommendation based on fusion representation of multi-type feature embedding,The Journal of Supercomputing,80.0,8.0,,10370–10393,2024,,,,,,,,,The Journal of Supercomputing,,,,,,,,,,,,The Journal of Supercomputing
7,,wang_xie_ding_chen_xiang_2025,"Wang, Shirui; Xie, Bohan; Ding, Ling; Chen, Jianting; Xiang, Yang",Reinforced logical reasoning over KGs for interpretable recommendation system,Machine Learning,114.0,4.0,,,2025,,,,,,,,,Machine Learning,,,,,,,,,,,,Machine Learning
7,,sang_yang_zhang_liao_2025,"Sang, Chun-Yan; Yang, Yang; Zhang, Yi-Bo; Liao, Shi-Gen",A user preference knowledge graph incorporating spatio-temporal transfer features for next POI recommendation,Applied Intelligence,55.0,6.0,,,2025,,,,,,,,,Applied Intelligence,,,,,,,,,,,,Applied Intelligence
6,,9811151,"Zarzour, Hafed; Alsmirat, Mohammad; Jararweh, Yaser",Using Deep Learning for Positive Reviews Prediction in Explainable Recommendation Systems,,,,June,358-362,2022,,,,International Conference on Information and Communication Systems (ICICS),,,,,,,,,,,,"In the recent years, recommender systems have begun to attract the attention of many online-based companies. While these systems are being developed to provide users with better recommendations, they suffer from the lack of explain-ability. The explainable recommendation systems are developed to solve the problem of why certain products or services are recommended to a particular user. However, less attention has been attracted for predicting positive reviews from the whole data in the context of explainable recommendation. Therefore, in this paper, we focus on developing a model that uses deep learning for predicting positive reviews in explainable recommendation systems. It enables users to get not only intuitive explanations for the recommended items, but also to get more transparency by investigating whether the explanations are positive ones. To evaluate the proposed model, we conduct experiments on a benchmark dataset from Amazon. Experimental results demonstrate the efficacy of the proposed model against the baselines.",,Deep learning;Communication systems;Companies;Predictive models;Benchmark testing;Recommender systems;Deep learning;Deep neural network;Recommender system;Explainable recommendation;Machine learning;Prediction model,,,International Conference on Information and Communication Systems (ICICS)
6,,8622439,"Suzuki, Takafumi; Oyama, Satoshi; Kurihara, Masahito",Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data,,,,Dec,3549-3551,2018,,,,IEEE International Conference on Big Data (Big Data),,,,,,,,,,,,"Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as ""customers who purchased this item also purchased...."". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.",,Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems,,,IEEE International Conference on Big Data (Big Data)
6,,10741116,"Tohidi, Nasim; Beheshti, Maedeh",Enhanced Explanations in Recommendation Systems,,,,Oct,1-5,2024,,,,IEEE International Symposium on Systems Engineering (ISSE),,,,,,,,,,,,"Recommendation Systems (RSs) play a crucial role in assisting users in making decisions and finding their desired items in various domains, such as movies, music, and hotels. However, their complex algorithms often raise concerns about transparency, fairness, and user trust. To address these challenges, we tried to propose a theoretical approach that combines SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) techniques to enhance the transparency and interpretability of RSs. We present a methodology for applying this approach in the context of movie recommendation, where SHAP values quantify global feature importance, and LIME explanations provide localized insights. This work can contribute to the advancement of transparent and user-centric RSs, with implications for a wide range of applications.",,Additives;Filtering;Motion pictures;Modeling;Recommender systems;recommendation system;explainability;interpretability;collaborative filtering,,,IEEE International Symposium on Systems Engineering (ISSE)
6,,9607106,"Vultureanu-Albişi, Alexandra; Bădică, Costin",Explainable Collaborative Filtering Recommendations Enriched with Contextual Information,,,,Oct,701-706,2021,,,,"International Conference on System Theory, Control and Computing (ICSTCC)",,,,,,,,,,,,"Today, the most important requirement of intelligent systems is to be able to explain their decisions to the end-user. Fulfilling this requirement is the goal of explainable AI (XAI) that proposes to produce explainable models that enable end-users to understand and trust the models. This research addresses the explainability of the recommendations. This paper presents an explainable recommender system for point of interest recommendations taking into account the context of the user. In our experiments we have used the STS (South Tyrol Suggests) dataset. The following major steps are part of our methodology: i) presenting the dataset, ii) using Restricted Boltzmann Machine based collaborative filtering recommendations, iii) using contextual information, and iv) extracting and presenting explanations for recommendations based on contextual information. The novelty that we propose in explainable recommender systems is a new explainable recommendation technique, which is quantitative and qualitative, providing both the list of top-n recommendations and the explanations of the recommendations based on context. This paper also provides an overview of research on this topic.",,Collaborative filtering;Computational modeling;Neural networks;Information filters;Control systems;Data mining;Usability;recommender systems;collaborative filtering;Restricted Boltzmann Machine;contextual information,,,"International Conference on System Theory, Control and Computing (ICSTCC)"
6,,9260076,"Lonjarret, Corentin; Robardet, Céline; Plantevit, Marc; Auburtin, Roch; Atzmueller, Martin",Why Should I Trust This Item? Explaining the Recommendations of any Model,,,,Oct,526-535,2020,,,,IEEE International Conference on Data Science and Advanced Analytics (DSAA),,,,,,,,,,,,"Explainable AI has received a lot of attention over the past decade, with the proposal of many methods explaining black box classifiers such as neural networks. Despite the ubiquity of recommender systems in the digital world, only few researchers have attempted to explain their functioning, whereas it raises e.g., ethical issues. Indeed, recommender systems direct user choices to a large extent and their impact is important as they give access to only a small part of the range of items (e.g., products and/or services), as the submerged part of the iceberg. Consequently, they limit access to other resources. The potentially negative effects of these systems have been pointed out as phenomena like echo chambers and winner-take-all effects, because the internal logic of these systems is to likely enclose the consumer in a ""dej́ a vu"" loop. Therefore, it is crucial to provide explanations' of such recommender systems and to identify the user data that led the system to make a specific recommendation. This makes it possible to evaluate recommender systems not only regarding their efficiency (i.e., their capability to recommend an item that was actually chosen by the user), but also w.r.t. the diversity, relevance and timeliness of the active data used to make the recommendation. In this paper, we propose a deep analysis of 7 state-of-the-art models learnt on 6 datasets based on the identification of the items or the sequences of items actively used by the models. The proposed method, which is based on subgroup discovery with different pattern languages (i.e., itemsets and sequences), provides interpretable explanations of the recommendations - useful to compare different models and explain the reasons behind the recommendation to the user.",,Recommender systems;History;Data science;Analytical models;Perturbation methods;Numerical models;Machine learning;Recommender systems;Explainable AI;Subgroup discovery,,,IEEE International Conference on Data Science and Advanced Analytics (DSAA)
6,,10776491,"Praseptiawan, Mugi; Muchtarom, M. Fikri Damar; Putri, Nabila Muthia; Pee, Ahmad Naim Che; Zakaria, Mohd Hafiz; Untoro, Meida Cahyo",Mooc Course Recommendation System Model with Explainable AI (XAI) Using Content Based Filtering Method,,,,Sep.,144-147,2024,,,,"International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)",,,,,,,,,,,,"Massive Open Online Course (MOOC) is a type of online course that has been designed and can be accessed by all individuals via the internet. The problem that is often found in MOOCs is the lack of a recommendation system provided by the algorithm of the MOOC. This research is conducted to analyze a recommendation system that applies the Content Based Filtering approach in order to solve the problems that occur. The recommendation system analyzed will function as a media that provides recommendations to users based on their preferences. By utilizing content-based methods, the recommendations given are expected to be exactly what the user wants. The level of explainability of the recommendation system is further emphasized by XAI using ELI5. By getting a concise explanation when a recommendation is given, the system will gain more trust from users for providing an appropriate recommendation. The assessment of the accuracy of the recommendation system model is measured using MAE. By researching this recommendation system using XAI, it is hoped that it can help future systems to improve the quality of the course recommendation system.",,Electrical engineering;Computer science;Computer aided instruction;Electronic learning;Filtering;Explainable AI;Media;Data models;Informatics;Recommender systems;MODC;content-based filtering;XAI;recommender system,,,"International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)"
6,,9005590,"Suzuki, Takafumi; Oyama, Satoshi; Kurihara, Masahito",Explainable Recommendation Using Review Text and a Knowledge Graph,,,,Dec,4638-4643,2019,,,,IEEE International Conference on Big Data (Big Data),,,,,,,,,,,,"Recommender systems using a knowledge graph can comprehensively organize users and items and their attributes and thereby improve recommendation performance. In addition, the relationship between users and items can be easily interpreted on the basis of entities and relations, thus giving explanations to recommendations. The algorithms and knowledge graphs used for generating explanations have not utilized review text. We have developed a recommendation method for predicting interactions between users and items using a knowledge graph and review text. The underlying user-item relationships are reflected and explanations are generated by predicting user-item interactions from the paths between a user and an item. The modeling is done using a recurrent neural network or a factorization machine. Items' aspects that interest users are extracted from review text and leveraged using an attention-like mechanism. Since the path between a user and an item can be easily interpreted, and the important aspects between a user and an item can be interpreted by observing the attention weight, the proposed model can generate a reasonable recommendation explanation. Testing using a real-world dataset demonstrated that the proposed model can explain the recommendations.",,Big Data;Machine-to-machine communications;Conferences;Recommendation;Knowledge Graph;Explainability;Review text;Recurent Neural Network,,,IEEE International Conference on Big Data (Big Data)
6,,10260804,"Rani, Neha; Qian, Yadi; Chu, Sharon Lynn",Explanation for User Trust in Context-Aware Recommender Systems for Search-As-Learning,,,,July,47-49,2023,,,,IEEE International Conference on Advanced Learning Technologies (ICALT),,,,,,,,,,,,"Learning through web browsing, often termed Search-as-Learning (SaL), can create information overload, due to thousands of search results. SaL can be made more efficient by developing context-aware tools that recommend items to the user and minimize information overload. However, to use context-aware recommender systems (CARS) users need to trust it. Literature has proposed explanations as a feature that helps to build trust. We investigate the impact of explanation on user trust and user experience for using CARS for SaL. Our study results show that people trust a CARS without explanation more during the first use, but for a CARS with explanations, user trust is significant only after multiple uses. Through interviews, we also uncovered the interesting paradox that even though users do not perceive that explanations add to their learning outcomes, they still prefer to use a CARS with explanations over one without.",,User experience;Automobiles;Interviews;Recommender systems;Explanation;Trust;User Experience;Context-Aware Recommender System,,,IEEE International Conference on Advanced Learning Technologies (ICALT)
6,,10683822,"Vultureanu-Albişi, Alexandra; Murareţu, Ionuţ; Bădică, Costin",A Trustworthy and Explainable AI Recommender System: Job Domain Case Study,,,,Sep.,1-7,2024,,,,International Conference on INnovations in Intelligent SysTems and Applications (INISTA),,,,,,,,,,,,"Finding a job these days is challenging because of the size, diversity, and goals of the market in a society impacted by pandemics, economic crises, or military hostilities. Trust is the most crucial factor in the job domain after performance expectations. It is particularly significant for women, less active job seekers, and people who did not experience job recommendations. Since recommender systems (RS) are one of the most frequently encountered human-centered and online applications in our daily lives, it is important to note that sound principles of trusting the environment of Artificial Intelligence (AI) systems are also required to characterize the trustworthiness of recommender systems. Otherwise, inadequate advice, high expectations and bad interpretations could lead to making bad choices or to demotivating job seekers. This paper expands on previous research, highlighting the point of view of trustworthiness in job recommender systems (JRS) and providing an overview of the dimensions of AI trustworthiness for the job domain. The purpose of this study is to investigate how trustworthy and suggestive outputs can improve the communication between a job mediator and a job seeker by enhancing the credibility of the information provided to job applicants and increasing customer satisfaction.",,Economics;Technological innovation;Pandemics;Explainable AI;Customer satisfaction;Cultural differences;Intelligent systems;job recommender system;trustworthiness;explainability;fairness,,,International Conference on INnovations in Intelligent SysTems and Applications (INISTA)
6,,9079084,"Zarzour, Hafed; Jararweh, Yaser; Hammad, Mahmoud M.; Al-Smadi, Mohammed",A long short-term memory deep learning framework for explainable recommendation,,,,April,233-237,2020,,,,International Conference on Information and Communication Systems (ICICS),,,,,,,,,,,,"Due to the growing quantity of information available on the Web, recommender systems have become crucial component for the success of online shopping stores. However, most of the existing recommender systems were only designed to improve the recommendation results and ignore the explainable recommendation aspect. Therefore, in this paper we propose a long short-term memory deep learning framework for explainable recommendation, that is able to generate an efficient explanation for any rating made by users for a recommended item. Such a framework would help users to choose a product with confident after reading the automatically generated explanation by our framework. The generated explanation is a concise sentence that shows the reason behind a recommendation, i.e., why a user should select that product. Extensive experiments on a real-world dataset from Amazon are conducted with the goal to evaluate the effectiveness of the proposed method in terms of loss and accuracy metrics. The experimental results demonstrate the effectiveness of our method according to the diversity in generating explainable recommendation.",,Deep learning;Measurement;Communication systems;Memory management;Electronic commerce;Recommender systems;long short-term memory (LSTM);deep learning;explainable recommendation;recommender system;machine learning,,,International Conference on Information and Communication Systems (ICICS)
6,,9836983,"Walek, Bogdan; Fajmon, Petr",A Recommender System for Recommending Suitable Products in E-shop Using Explanations,,,,May,16-20,2022,,,,"International Conference on Artificial Intelligence, Robotics and Control (AIRC)",,,,,,,,,,,,"This article proposes a recommender system for recommending relevant products in e-shop using explanations. The proposed system consists of three recommender modules called VIEW, RATING, and PURCHASE. The recommender modules use a content-based filtering approach and a collaborative filtering approach. The proposed recommender system works with explanations that contain arguments why the system recommended the specific product. Based on these explanations the user sees why specific products are recommended by the system. The proposed system was experimentally verified and the results of the experimental verification are discussed.",,Filtering;Collaborative filtering;Control systems;Artificial intelligence;Recommender systems;Robots;Testing;recommender system;e-shop recommender system;hybrid recommender system;explanations;content-based filtering;collaborative filtering,,,"International Conference on Artificial Intelligence, Robotics and Control (AIRC)"
6,,10873804,"Xiaolong, Zhou; Shijiao, Han; Zhenze, Li",Explainable Recommendation System Based on Aspect-Based Sentiment Analysis,,,,Dec,1-4,2024,,,,International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP),,,,,,,,,,,,"At information age, the rapid increase of information caused Information Overload problem, which made recommendation system (RS) come into being and push forward the quick development. Nowadays RS has been widely used in human society. Meanwhile, RS also faces challenges like data sparsity and poor explainability. An effective way to address data sparsity challenge is to exploit content information (like review data) for modeling users and items. By further mining content information, deep relationship between user-item interactions can be uncovered and therefore the explanation for recommendation results can be provided. In order to fully mine the information in review data and make precise recommendation with corresponding explanation, a recommendation model for rating prediction task is proposed in this paper. It exploits aspect-based sentiment analysis related theory to mine review features, incorporates the modeling of user preference and item properties with fine-grained sentiment information, which solves problems that previous model has poor context feature extraction ability and the sentiment analysis results are lack of reliability. Extensive experiments show that this model outperforms baseline models in rating prediction task and can provide explanations for the rating prediction results in view of sentiment.",,Analytical models;Sentiment analysis;Reviews;Computational modeling;Predictive models;Feature extraction;Wavelet analysis;Data models;Recommender systems;Context modeling;Recommender system;Review-based recommendation;Aspect-based sentiment analysis;Explainable recommendation,,,International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)
6,,8594883,"Wang, Xiting; Chen, Yiru; Yang, Jie; Wu, Le; Wu, Zhengtao; Xie, Xing",A Reinforcement Learning Framework for Explainable Recommendation,,,,Nov,587-596,2018,,,,IEEE International Conference on Data Mining (ICDM),,,,,,,,,,,,"Explainable recommendation, which provides explanations about why an item is recommended, has attracted increasing attention due to its ability in helping users make better decisions and increasing users' trust in the system. Existing explainable recommendation methods either ignore the working mechanism of the recommendation model or are designed for a specific recommendation model. Moreover, it is difficult for existing methods to ensure the presentation quality of the explanations (e.g., consistency). To solve these problems, we design a reinforcement learning framework for explainable recommendation. Our framework can explain any recommendation model (model-agnostic) and can flexibly control the explanation quality based on the application scenario. To demonstrate the effectiveness of our framework, we show how it can be used for generating sentence-level explanations. Specifically, we instantiate the explanation generator in the framework with a personalized-attention-based neural network. Offline experiments demonstrate that our method can well explain both collaborative filtering methods and deep-learning-based models. Evaluation with human subjects shows that the explanations generated by our method are significantly more useful than the explanations generated by the baselines.",,"Reinforcement learning;Recommender systems;Quality control;Collaboration;Predictive models;Neural networks;Transforms;Explainable recommendation, reinforcement learning, personalized explanation, attention networks",,,IEEE International Conference on Data Mining (ICDM)
7,,10048787,"Yang, Zhe-Rui; He, Zhen-Yu; Wang, Chang-Dong; Lai, Jian-Huang; Tian, Zhihong",Collaborative Meta-Path Modeling for Explainable Recommendation,IEEE Transactions on Computational Social Systems,11.0,2.0,April,1805-1815,2024,,,,,,,,,,,,,,,,"Although recommender systems have achieved considerable success, sometimes it is difficult to convince users due to the failure to explain the recommendation results. For this reason, explainable recommender systems have drawn a lot of attention in recent years. Among explainable recommendation models, the meta-path-based model plays a significant role because it can reason over the path connecting a user–item pair to achieve explainability. However, it is difficult for the meta-path-based model to achieve such a common explanation in collaborative filtering as “a user similar to you has purchased item  $A$ ” because there is no such meta-path. In this article, we contribute a new model named collaborative meta-path modeling for explainable recommendation (COMPER). It models the similarity of user pairs and item pairs through rating information and constructs collaborative meta-paths for explainability. In addition, we design an attention mechanism to aggregate different paths connecting the target user and the target item. Moreover, the information of the subgraph composed of all paths connecting the target user and the target item is integrated for rating prediction. Extensive experiments on five real-world datasets demonstrate that COMPER achieves good performance in a variety of scenarios, achieving improvements over several baselines.",,Collaborative filtering;Recommender systems;Predictive models;Computational modeling;Deep learning;Correlation coefficient;Recommender systems;Collaborative filtering;explainable recommendation;meta-path,,,IEEE Transactions on Computational Social Systems
6,,10446052,"Zhang, Jingsen; Bo, Xiaohe; Wang, Chenxi; Dai, Quanyu; Dong, Zhenhua; Tang, Ruiming; Chen, Xu",Active Explainable Recommendation with Limited Labeling Budgets,,,,April,5375-5379,2024,,,,"ICASSP - IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",,,,,,,,,,,,"Explainable recommendation has gained significant attention due to its potential to enhance user trust and system transparency. Previous studies primarily focus on refining model architectures to generate more informative explanations, assuming that the explanation data is sufficient and easy to acquire. However, in practice, obtaining the ground truth for explanations can be costly since individuals may not be inclined to put additional efforts to provide behavior explanations. In this paper, we study a novel problem in the field of explainable recommendation, that is, “given a limited budget to incentivize users to provide behavior explanations, how to effectively collect data such that the downstream models can be better optimized?” To solve this problem, we propose an active learning framework for recommender system, which consists of an acquisition function for sample collection and an explainable recommendation model to provide the final results. We consider both uncertainty and influence based strategies to design the acquisition function, which can determine the sample effectiveness from complementary perspectives. To demonstrate the effectiveness of our framework, we conduct extensive experiments based on real-world datasets.",,Uncertainty;Refining;Self-supervised learning;Signal processing;Data models;Speech processing;Recommender systems;Explainable Recommendation;Recommender System;Active learning;Influence Function,,,"ICASSP - IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
6,,10827288,"Bhatti, Uzair Aslam; Yu, Yang Ke; Mamyrbayev, O. Zh.; Aitkazina, A. A.; Hao, Tang; Zhumazhan, N. O.",Recommendations for Healthcare: An Interpretable Approach Using Deep Learning,,,,Aug,529-535,2024,,,,International Conference on Pattern Recognition and Artificial Intelligence (PRAI),,,,,,,,,,,,"This study introduces a novel approach to patient interpretation and diagnosis, utilizing Graph Neural Networks (GNNs) within a collaborative recommendation framework. Our proposed system employs GNN-based collaborative filtering to model complex patient-patient and patient-symptom relationships in a comprehensive graph structure. The system is designed to offer interpretable recommendations, explaining the reasoning behind diagnostic suggestions. The study focused on common chronic conditions in older adults, including high blood pressure, coronary heart disease, diabetes and stroke, as well as fractures, osteoporosis and arthritis. We used a graphical hybrid recommender system (GHRS) and a cooperative graph neural network (GCFNA and GCFYA) to predict hospital disease diagnosis. Encouragingly, both the GCFNA and GCFYA models achieved prediction accuracy rates of over 90%, highlighting the model's excellent performance in accurate predictions. The ultimate goal is to provide precise disease predictions for elderly patients, offer medical guidance, and enhance patient care in hospitals, particularly in managing chronic diseases.",,Heart;Osteoporosis;Accuracy;Hospitals;Predictive models;Graph neural networks;Pattern recognition;Older adults;Recommender systems;Medical diagnostic imaging;Hypertension;Coronary heart disease;diabetes mellitus;chronic obstructive pulmonary disease;graph convolutional neural network,,,International Conference on Pattern Recognition and Artificial Intelligence (PRAI)
6,,9482221,"Song, Wei; Wang, Chenglong; Ning, Keqing",Generate Personalized Explanations for Recommendation based on Keywords,,4.0,,June,51-57,2021,,,,"IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)",,,,,,,,,,,,"Explainable recommendation refers to providing users with recommended products and explaining to users the reasons for recommending the products. Recommendation explanations can greatly increase users’ trust and satisfaction with the recommender system, and to a certain extent can assist users make decisions efficiently. The current recommendation explanation is mainly templated sentences although this method is simple and easy to understand, it is relatively rigid, lacks flexibility, insufficient service, and requires a lot of manpower and material resources. Inspired by the above questions, by mining user comment information, we propose a method to generate multiple recommendations based on keywords. First, the keywords in the comment information are extracted through STF-IDF, and then the recommendation explanation is generated through the classic network GRU generated by natural language. Experiments show that our proposed method not only has better recommendation accuracy but is also has a higher quality of recommended interpretation compared to classic methods",,Automation;Conferences;Natural languages;Information management;Data mining;Recommender systems;recommender systems;explainable recommendation;natural language generation;keyword extraction,,,"IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)"
6,,10658914,"Chun, Hong Wei; Ong, Rongqing Kenneth; Khong, Andy W. H.",Reasonable Sense of Direction: Making Course Recommendations Understandable with LLMs,,,,Aug,1408-1412,2024,,,,IEEE International Midwest Symposium on Circuits and Systems (MWSCAS),,,,,,,,,,,,"Course recommendation systems play an essential role in academic institutions for students to find courses that align with their interests and graduation requirements. However, due to their “black-box” nature, recommendation systems often lack transparency and interpretability, leading to challenges in trust and usability. Our proposed framework leverages Large Language Models (LLMs) to generate clear, human-readable explanations based on course content by drawing connections between the existing courses taken by the student and recommended courses.",,Circuits and systems;Large language models;Closed box;Cognition;Usability;Integrated circuit modeling;Recommender systems;Course Recommendation Systems;Educational Technology;Large Language Models,,,IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)
6,,10334552,"Chen, Zhanghui; Ai, Xinbo; Guo, Yanjun; Huang, Yitian; Yang, Jing",Explainable Recommendation for Hazard Inspection Reasoning Through Knowledge Graph,,,,Oct,37-42,2023,,,,IEEE International Conference on Computer Science and Network Technology (ICCSNT),,,,,,,,,,,,"In the process of hazards inspecting in safety production, the number and types of hazard entities are often vast and varied. Introducing of existing recommendation algorithms may lead to low recommendation quality and lack of explain ability. To address these challenges, achieving dual improvement in accuracy and reliability of hazard inspection recommendations. We propose three metrics that represent the explanation quality of recommendation results: Inspection Recency of Hazard, Risk Level of Entity and Utilization Rate of Graph. And then we propose two optimization methods on model inner-training and post-training: Pruning-Strategy Optimization and Re-Rank Optimization. In hazards inspection dataset of safety production, hazard inspection recommendation NDCG@10 reaches 0.433(5.1 % higher than baseline) and overall path explanation metric scores reaches 1.928(74.8% higher than baseline). Compared with previous algorithms, our methods achieve higher recommendation performance and explainability quality.",,Measurement;Computer science;Law enforcement;Optimization methods;Production;Knowledge graphs;Inspection;recommendation system;hazard inspection;ex- plainability,,,IEEE International Conference on Computer Science and Network Technology (ICCSNT)
6,,10825771,"Turgut, Özlem; Kök, İbrahim; Özdemir, Suat",AgroXAI: Explainable AI-Driven Crop Recommendation System for Agriculture 4.0,,,,Dec,7208-7217,2024,,,,IEEE International Conference on Big Data (BigData),,,,,,,,,,,,"Today, crop diversification in agriculture is a critical issue to meet the increasing demand for food and to improve food safety and quality. This issue is considered to be the most important challenge for the next generation of agriculture due to diminishing natural resources, limited arable land and unpredictable climatic conditions caused by climate change. In this paper, we employ emerging technologies such as the Internet of Things (IoT), machine learning (ML) and explainable artificial intelligence (XAI) to improve operational efficiency and productivity in the agricultural sector. Specifically, we propose an edge computing-based explainable crop recommendation system, AgroXAI, which suggests suitable crops for a region based on weather and soil conditions. In this system, we provide local and global explanations of ML model decisions with methods such as ELI5, LIME, SHAP, which we integrate into ML models. More importantly, we provide regional alternative crop recommendations with the Counterfactual explainability method. In this way, we envision that our proposed AgroXAI system will be a platform that provides regional crop diversity in the next generation agriculture.",,Productivity;Explainable AI;Computational modeling;Crops;Soil;Agriculture;Internet of Things;Sustainable development;Recommender systems;Next generation networking;Explainable Artificial Intelligence (XAI);Agriculture 4.0;Internet of Things;edge computing;crop recommendation,,,IEEE International Conference on Big Data (Big Data)
6,,10308154,"Das, Samiran; Chatterjee, Sujoy",Explainable Machine Learning for Crop Recommendation from Agriculture Sensor Data- a New Paradigm,,,,July,1-7,2023,,,,International Conference on Computing Communication and Networking Technologies (ICCCNT),,,,,,,,,,,,"The dwindling agricultural earnings and decrease in crop yield in recent years due to improper crop selection and fluctuation/ uncertainty in weather necessitate proper machine learning-based analysis. Machine learning methods can potentially alleviate the predicament caused by the lack of appropriate soil testing, consultation, and bias in manual suggestion. This work attempted to comprehend the agricultural sensor data and weather conditions and formulated the task in terms of supervised classification. The work obtained accurate suggestions in the presence of missing data, noise, etc. by using advanced machine learning methods. But recommendation alone is insufficient to convince farmers and other stakeholders to adopt this approach. Hence, this paper introduced explainable machine learning to completely comprehend the decision-making process. This work quantified the importance of features, explained individual prediction outcomes, and uncovered the rationale for decisions. The work employed state-of-the-art local interpretable model-agnostic, post-hoc explanation methods to provide in-depth insights. The insights obtained from the explanations can help the farmers develop a knowledge base and assist the farmers in choosing the appropriate sensors for the task. The human interpretable analysis enables the farmers to obtain satisfactory yields in these ever-changing and extreme weather conditions and environmental degradation.",,Uncertainty;Pollution control;Machine learning;Soil;Pollution measurement;Stakeholders;Resource management;Agricultural data analytics;Sensor data;Crop recommendation;Explainable machine learning,,,International Conference on Computing Communication and Networking Technologies (ICCCNT)
7,,10742303,"Cao, Yang; Shang, Shuo; Wang, Jun; Zhang, Wei",Explainable Session-Based Recommendation via Path Reasoning,IEEE Transactions on Knowledge and Data Engineering,37.0,1.0,Jan,278-290,2025,,,,,,,,,,,,,,,,"This paper explores explaining session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting nodes for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR and introduce path midpoint reward to enhance the exploration efficiency and accuracy in knowledge graphs. To improve the knowledge graph’s completeness and diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.",,Cognition;Knowledge graphs;Accuracy;Reinforcement learning;Feature extraction;Matrix decomposition;Data mining;Attention mechanisms;Predictive models;Correlation;Explainable recommendation;hierarchical reinforcement learning;knowledge graph;session-based recommendation (SR),,,IEEE Transactions on Knowledge and Data Engineering
7,,10623784,"Guo, Feipeng; Wang, Zifan",KEMB-Rec: Knowledge-Enhanced Explainable Multibehavior Recommendation With Graph Contrastive Learning,IEEE Internet of Things Journal,12.0,4.0,Feb,3563-3576,2025,,,,,,,,,,,,,,,,"In the era of Internet of Things (IoT), intelligent recommendation systems are crucial components for users to locate the items they require. Existing recommendation systems overlook the diversity of user behaviors and rely solely on utilizing a singular form of user-item interaction data. Multibehavior recommendation (MBR) works to solve this problem by utilizing multityped user behaviors to mine the heterogeneous relations between users and items to improve recommendation accuracy. Nevertheless, there are still challenges to be overcome, including capture of differences and commonalities between different types of behaviors, learning of users’ personalized behavioral patterns, consideration of semantic knowledge, and building of users’ trust in algorithms. In light of the aforementioned considerations, we propose a knowledge-enhanced explainable MBR model (KEMB-Rec) with graph contrastive learning, comprising two modules. The first is the user behavior-aware module, which mines user’s behavior pattern using the user behavior hyper meta-graphs and captures the differences and commonalities between different behaviors through graph contrastive learning. The second is the semantic knowledge-aware module, which is based on single behavior interaction graphs to mine the semantic relational knowledge, and makes full use of it to represent users and items. Then, we design contrastive learning task and recommendation task, and the two tasks are optimized jointly. At the same time, effective recommendation explanations are provided by mining paths and semantics between users and items as a way to enhance user trust and satisfaction. The proposed KEMB-Rec is evaluated in real-world data sets, with results indicating that KEMB-Rec outperforms various baselines.",,Contrastive learning;Semantics;Task analysis;Internet of Things;Data mining;Recommender systems;Accuracy;Explanation;graph contrastive learning;graph neural network (GNN);multibehavior recommendation (MBR);semantic knowledge,,,IEEE Internet of Things Journal
6,,10884422,"Batmani, Sahar; Moradi, Parham; Heidari, Narges; Jalili, Mahdi",An Explainable Recommender System by Integrating Graph Neural Networks and User Reviews,,,,Dec,669-674,2024,,,,IEEE International Conference on Data Mining (ICDM),,,,,,,,,,,,"This paper introduces an explainable Graph Neural Network (GNN)-based recommender system that integrates user-item interactions and user reviews to enhance recommendation accuracy and interpretability. The proposed method leverages Temporal Convolutional Networks (TCNs) as a language model to encode user reviews into vector representations, capturing temporal dynamics and contextual information. Additionally, it extracts opinion-aspect pairs from reviews, enabling the system to understand specific product features and user sentiments. Bipartite graphs are constructed to represent interactions between users/items and opinion aspects, facilitating the integration of user reviews into the GNN framework. A contrastive learning approach is employed to combine these graphs with TCN-generated review embeddings, enhancing the system's ability to capture complex relationships. Finally, a recommendation strategy is proposed which considers relevant opinion-aspects as explanations for recommendations. The experiments conducted on several benchmarks reveal that our method outperforms its competitors.",,Reviews;Convolution;Contrastive learning;Feature extraction;Graph neural networks;Vectors;Bipartite graph;Data mining;Convolutional neural networks;Recommender systems;Recommender System;Explainability;Graph Neural Networks;Temporal Convolution Networks;User Reviews,,,IEEE International Conference on Data Mining (ICDM)
7,,SHIMIZU2022107970,"Shimizu, Ryotaro; Matsutani, Megumi; Goto, Masayuki",An explainable recommendation framework based on an improved knowledge graph attention network with massive volumes of side information,Knowledge-Based Systems,239.0,,,107970,2022,,,https://www.sciencedirect.com/science/article/pii/S0950705121010959,,,,,,,,,,,,,"In recent years, explainable recommendation has been a topic of active study. This is because the branch of the machine learning field related to methodologies is enabling human understanding of the reasons for the outputs of recommender systems. The realization of explainable recommendation is widely expected to increase both user satisfaction and the demand for explainable recommendation systems. Explainable recommendation utilizes a wealth of side information (such as sellers, brands, user ages and genders, and bookmark information, among others) to expound the decision-making reasoning applied by recommendation models. In explainable recommendation, although learning side information containing numerous variables leads to rich interpretability, learning too many variables presents a challenge because decreases the amount of learning that a given computational resource can perform, and the accuracy of the recommendation model may be degraded. However, numerous and diverse variables are included in the side information stored by the actual companies operating massive real-world services. Hence, to realize practical applications of this valuable information, it is necessary to resolve problems such as computational cost. In this study, we propose a new framework for explainable recommendation based on an improved knowledge graph attention network model, which utilizes the side information of items and realizes high recommendation accuracy. The proposed framework enables direct interpretation by visualizing the reasons for the recommendations provided. Experimental results show that the proposed framework reduced computational time requirements by approximately 80%, while maintaining recommendation accuracy by enabling the model to learn the probabilistically given edges included in the graph structure. Moreover, the results show that the proposed framework exhibited richer interpretability than the conventional model. Finally, a multifaceted analysis suggests that the proposed framework is not only effective as an explainable recommendation model but also provides a powerful tool for planning various marketing strategies.",,"Explainable artificial intelligence, Explainable recommendation, Model-intrinsic approach, Knowledge graph attention network, Knowledge graph embedding, Knowledge graph enabled recommendation",,,Knowledge-Based Systems
7,,BRUNOT2022102021,"Brunot, Léo; Canovas, Nicolas; Chanson, Alexandre; Labroche, Nicolas; Verdeaux, Willème",Preference-based and local post-hoc explanations for recommender systems,Information Systems,108.0,,,102021,2022,,,https://www.sciencedirect.com/science/article/pii/S0306437922000254,,,,,,,,,,,,,"Post-hoc explanation aims at defining a simple local surrogate model to shed light on a prediction produced by a complex, generally black-box, model. In the general context of classification, it has been shown that local surrogates may not always be able to capture a local explanation, i.e. for a specific instance prediction, but rather depict more of a general behavior of the black-box. This problem is even more complex in a recommendation scenario where classes and decision boundaries are not explicitly defined and where data are very sparse by nature. We show in this paper that it is possible to tackle these problems with an efficient sampling around the recommendation instance to explain, to finally learn a proper local surrogate model. To this aim, this paper introduces several new approaches to capture efficiently local explanation models in the context of recommendation, all defined around a locality sample. Noticeably, and novel to this work, we show that it is possible to achieve a simple, yet better quality explanation model by not directly considering ratings, but rather implicit preferences as expressed by comparisons of pairs of ratings. We introduce to this extent a novel explainable model based on a pairwise loss RankNet architecture. Extensive experiments show that our methods can be better than state-of-the-art methods depending on the locality of the black-box model, and are much more efficient to retrieve meaningful explainable features locally.",,"Post-hoc explanation, Recommender systems, Locality, Pairwise preference",,,Information Systems
7,,TAO2022109300,"Tao, Shaohua; Qiu, Runhe; Xu, Bo; Ping, Yuan",Micro-behaviour with Reinforcement Knowledge-aware Reasoning for Explainable Recommendation,Knowledge-Based Systems,251.0,,,109300,2022,,,https://www.sciencedirect.com/science/article/pii/S0950705122006529,,,,,,,,,,,,,"Existing practical recommendation scenarios involve multiple micro-behaviour user–item interactions, such as clicks, page views, add-to-favourites, and purchases, which provide fine-grained and a better in-depth understanding of the user’s preference. Furthermore, some recommendation methods have incorporated item knowledge into the micro-behaviour of user–item interaction. Although some have proved effective, two insights are often neglected. First, they fail to combine micro-behaviour with the relation of the knowledge graph (KG), and the semantic relationship between micro-behaviour and relation is not captured. Second, they do not provide explicit reasoning for micro-behaviour from user–item interaction data. These insights motivated us to propose a novel model of Micro-behaviour with Reinforcement Knowledge-aware Reasoning for Explainable Recommendation (MBKR), which incorporates micro-behaviour and the KG into reinforcement learning for explainable recommendation. Specifically, the model learns the behaviour by user–item propagation and the relation from the KG and combines the two to calculate the behavioural strength to mine user’s interests. In addition, we designed a Shawo-relational path that combines recommendation and interpretability by providing rational paths; these paths capture the semantics of behaviours and relations. Finally, we extensively evaluated our method on several large-scale benchmark datasets, and the results indicate that the proposed method is more effective in providing recommendations than state-of-the-art methods.",,"Micro-behaviour, Knowledge graph, Deep reinforcement learning, Recommendation, Explanation",,,Knowledge-Based Systems
7,,TAO2021107217,"Tao, Shaohua; Qiu, Runhe; Ping, Yuan; Ma, Hui",Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation,Knowledge-Based Systems,227.0,,,107217,2021,,,https://www.sciencedirect.com/science/article/pii/S0950705121004792,,,,,,,,,,,,,"Knowledge graphs (KGs) can provide rich, structured information for recommendation systems as well as increase accuracy and perform explicit reasoning. Deep reinforcement learning (RL) has also sparked great interest in personalized recommendations. The combination of the two holds promise in carrying out interpretable causal inference procedures and improving the performance of graph-structured recommendation. However, most KG-based recommendation focus on rich semantic relationships between entities in a heterogeneous knowledge graph, and thus fail to fully make use of the image information corresponding to an entity. In order to address these issues, we proposed a novel Multi-modal Knowledge-aware Reinforcement Learning Network (MKRLN), which couples recommendation and interpretability by providing actual paths in multi-modal KG (MKG). The MKRLN can generate path representation by composing the structural and visual information of entities, and infers the underlying rational of agent-MKG interactions by leveraging the sequential dependencies within a path from the MKG. In addition, as KGs have too many attributes and entities, their combination with RL leads to too many action spaces and states in the reinforcement learning space, which complicates the search of action spaces. Furthermore, in order to solve this problem, we proposed a new hierarchical attention-path, which makes users focus their attention on the items they are interested in. This reduces the relations and entities in the KGs, which in turn reduces the action space and state in RL, shortens the path to the target entity, and improves the accuracy of recommendation. Our model has explicit explanation ability in knowledge and images. Finally, we extensively evaluated our model on several large-scale real-world benchmark datasets, and it yielded favorable results compared with state-of-the-art methods.",,"Multi-modal knowledge graph, Knowledge graph, Image, Deep reinforcement learning, Recommendation",,,Knowledge-Based Systems
7,,YANG2021106687,"Yang, Chao; Zhou, Weixin; Wang, Zhiyu; Jiang, Bin; Li, Dongsheng; Shen, Huawei",Accurate and Explainable Recommendation via Hierarchical Attention Network Oriented Towards Crowd Intelligence,Knowledge-Based Systems,213.0,,,106687,2021,,,https://www.sciencedirect.com/science/article/pii/S0950705120308169,,,,,,,,,,,,,"Review-based recommendation algorithms can alleviate the data sparsity issue in collaborative filtering by combining user ratings and reviews in model learning. However, most existing methods simplify the feature extraction process from reviews by assuming that different granularities of information (e.g., word, review, and feature) are equally important, which cannot optimally leverage the most important information and thus achieves suboptimal recommendation accuracy. Besides, many existing works directly regard text features as users or items representations, which may not be enough to make precise representations due to the large amount of redundant information in reviews. To tackle the two problems mentioned above, we propose a deep learning-based method named Hierarchical Attention Network Oriented Towards Crowd Intelligence (HANCI). First, HANCI replaces the commonly-used topic models or CNN text processor with an RNN text processor in review feature extraction, which can fully exploit the advantages of the sequential dependencies of reviews by using the whole hidden layers of the bidirectional LSTM as outputs. Second, HANCI weighs the importance of features guided by crowd intelligence to more accurately represent each user on each item, and vice versa. Third, HANCI utilizes a hierarchical attention network based on multi-level review text analysis to extract more precise user preferences and item latent features, so that HANCI can explore the importance of words, the usefulness of reviews and the importance of features to achieve more accurate recommendation. Extensive experiments on three public datasets show that HANCI outperforms the state-of-the-art review-based recommendation algorithms in accuracy and meanwhile provides insightful explanations.",,"Crowd intelligence, Explainable recommendation, Hierarchical attention, Review representation, Recommender system",,,Knowledge-Based Systems
7,,LIU2020102099,"Liu, Peng; Zhang, Lemei; Gulla, Jon Atle",Dynamic attention-based explainable recommendation with textual and visual fusion,Information Processing & Management,57.0,6.0,,102099,2020,,,https://www.sciencedirect.com/science/article/pii/S0306457319301761,,,,,,,,,,,,,"Explainable recommendation, which provides explanations about why an item is recommended, has attracted growing attention in both research and industry communities. However, most existing explainable recommendation methods cannot provide multi-model explanations consisting of both textual and visual modalities or adaptive explanations tailored for the user’s dynamic preference, potentially leading to the degradation of customers’ satisfaction, confidence and trust for the recommender system. On the technical side, Recurrent Neural Network (RNN) has become the most prevalent technique to model dynamic user preferences. Benefit from the natural characteristics of RNN, the hidden state is a combination of long-term dependency and short-term interest to some degrees. But it works like a black-box and the monotonic temporal dependency of RNN is not sufficient to capture the user’s short-term interest. In this paper, to deal with the above issues, we propose a novel Attentive Recurrent Neural Network (Ante-RNN) with textual and visual fusion for the dynamic explainable recommendation. Specifically, our model jointly learns image representations with textual alignment and text representations with topical attention mechanism in a parallel way. Then a novel dynamic contextual attention mechanism is incorporated into Ante-RNN for modelling the complicated correlations among recent items and strengthening the user’s short-term interests. By combining the full latent visual-semantic alignments and a hybrid attention mechanism including topical and contextual attentions, Ante-RNN makes the recommendation process more transparent and explainable. Extensive experimental results on two real world datasets demonstrate the superior performance and explainability of our model.",,"Dynamic explainable recommendation, Recurrent neural network, Attention mechanism, Semantic alignment, Multi-model fusion, User interests",,,Information Processing & Management
7,,LIANG202194,"Liang, Qianqiao; Zheng, Xiaolin; Wang, Yan; Zhu, Mengying","O3ERS: An explainable recommendation system with online learning, online recommendation, and online explanation",Information Sciences,562.0,,,94-115,2021,,,https://www.sciencedirect.com/science/article/pii/S0020025520312366,,,,,,,,,,,,,"Explainable recommendation systems (ERSs) have attracted increasing attention from researchers, which generate high-quality recommendations with intuitive explanations to help users make appropriate decisions. However, most of the existing ERSs are designed with an offline setting, which can hardly adjust their models using the online feedback instantly for improved performance. To overcome the limitations of ERSs with the offline setting, we propose a novel online setting for ERSs and devise an effective model called O3ERS in this online setting, which can perform online learning with good scalability and rigorous theoretical guides for better online recommendations and online explanations. O3ERS also addresses two challenging problems in real scenarios, namely, the sparsity and delay of online explanations’ feedback as well as the partialness and insufficiency of online recommendations’ feedback. Specifically, O3ERS not only instantly leverages the knowledge learned from the recommendations’ feedback to adjust the sparse and delayed explanations’ feedback for better explanations but also utilizes a novel exploitation–exploration strategy that incorporates the explanations’ feedback to adjust the partial and insufficient recommendations’ feedback for better recommendations. Our theoretical analysis and empirical studies on one simulated and two real-world datasets show that our model outperforms the state-of-the-art models in online scenarios remarkably.",,"Explainable recommendation systems, Online learning, Factorization bandit",,,Information Sciences
7,,ZANON2022109333,"Zanon, André Levi; da Rocha, Leonardo Chaves Dutra; Manzato, Marcelo Garcia",Balancing the trade-off between accuracy and diversity in recommender systems with personalized explanations based on Linked Open Data,Knowledge-Based Systems,252.0,,,109333,2022,,,https://www.sciencedirect.com/science/article/pii/S0950705122006682,,,,,,,,,,,,,"Collaborative filtering recommendation algorithms generate suggestions based on similar interactions between users. Although it provides accurate recommendations, the approach has two limitations: the popularity bias, which frequently suggests a small set of the most interacted items, and the systems’ black box functioning, as they are grounded on complex mathematical models. To improve such aspects in collaborative filtering algorithms, this paper introduces a multi-domain item reordering system based on the best explanation for an item, which are the best ranked paths extracted from a Linked Open Data knowledge graph connecting recommended and interacted items. To order paths, the algorithm assigns a value to the node attributes connecting two items by calculating the popularity of the property between interacted items that are rare in the full set of items. Results from two datasets of the movie and music domains comparing the proposed reordering system with six baselines of different collaborative filtering families showed that our easy-to-explain approach improved diversity and/or accuracy metrics.",,"Recommender systems, Collaborative filtering, Linked open data, Explainable AI",,,Knowledge-Based Systems
7,,PAZRUZA2024102497,"Paz-Ruza, Jorge; Alonso-Betanzos, Amparo; Guijarro-Berdiñas, Bertha; Cancela, Brais; Eiras-Franco, Carlos",Sustainable transparency on recommender systems: Bayesian ranking of images for explainability,Information Fusion,111.0,,,102497,2024,,,https://www.sciencedirect.com/science/article/pii/S1566253524002756,,,,,,,,,,,,,"Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using existing visual content created by users is a promising option to maximize transparency and user trust. State-of-the-art models that follow this approach, despite leveraging highly optimized architectures, employ surrogate learning tasks that do not efficiently model the objective of ranking images as explanations for a given recommendation; this leads to a suboptimal training process with high computational costs that may not be reduced without affecting model performance. This work presents BRIE, a novel model where we leverage Bayesian Pairwise Ranking to enhance the training process, allowing us to consistently outperform state-of-the-art models in six real-world datasets while reducing its model size by up to 64 times and its CO2 emissions by up to 75% in training and inference.",,"Machine Learning, Explainable Artificial Intelligence, Frugal AI, Dyadic data, Explainable recommendations, Recommender systems",,,Information Fusion
7,,AI2025129692,"Ai, Jun; Li, Haolin; Su, Zhan; Zhao, Fengyu",An explainable recommendation algorithm based on content summarization and linear attention,Neurocomputing,630.0,,,129692,2025,,,https://www.sciencedirect.com/science/article/pii/S0925231225003649,,,,,,,,,,,,,"Recommendation algorithms can alleviate the problem of information explosion and cater to the needs of users to quickly lock in preferred items, promote business development, and have important theoretical significance and broad theoretical value. Explainable recommendation algorithms can not only complete recommendation tasks, but also generate recommendation explanations, so that users can more easily accept preferences. Research related to natural language text generation has promoted the progress of explainable text generation technology for recommendation systems. This paper proposes an explainable recommendation algorithm based on content summarization and linear attention mechanism. The model uses the keyword extraction algorithm to extract key information from user comment text as an important feature of subsequent text generation tasks, and further introduces linear Transformer to improve the training speed of the model and enhance its scalability. In addition, the model also uses the Vivaldi synthetic coordinate algorithm to deeply mine user and item features and uses the Kolmogorov–Arnold neural network model to reduce the error of predicted ratings. Compared with existing leading algorithms, the algorithm in this paper has achieved significant improvements in text generation and recommendation rating prediction. This paper reveals that applying the linear attention mechanism to the explainable recommendation algorithm can greatly reduce the training cost and improve scalability, and the fusion of synthetic coordinates and attention can further mine the hidden information of the recommendation system, effectively improving the performance of the recommendation algorithm.",,"Content summary, Linear attention, Explainable recommendation algorithm, Vivaldi synthetic coordinate algorithm, Kolmogorov–Arnold neural network",,,Neurocomputing
7,,WEI2023202,"Wei, Tianjun; Chow, Tommy W. S.; Ma, Jianghong; Zhao, Mingbo",ExpGCN: Review-aware Graph Convolution Network for explainable recommendation,Neural Networks,157.0,,,202-215,2023,,,https://www.sciencedirect.com/science/article/pii/S0893608022004087,,,,,,,,,,,,,"Existing works in recommender system have widely explored extracting reviews as explanations beyond user–item interactions, and formulated the explanation generation as a ranking task to enhance item recommendation performance. To associate explanations with users and items, graph neural networks (GNN) are usually employed to learn node representations on the heterogeneous user–item–explanation interaction graph. However, modeling heterogeneous graph convolution poses limitations in both message passing styles and computational efficiency, resulting in sub-optimal recommendation performance. To address the limitations, we propose an Explanation-aware Graph Convolution Network (ExpGCN). In particular, the heterogeneous interaction graph is divided to subgraphs regard to the edge types in ExpGCN. By aggregating information from distinct subgraphs, ExpGCN is capable of generating node representations for explanation ranking task and item recommendation task respectively. Task-oriented graph convolution can not only reduce the complexity of heterogeneous node aggregation, but also alleviate the performance degeneration caused by the conflicts between task learning objectives, which has been neglected in current studies. Extensive experiments on four public datasets show that ExpGCN significantly outperforms state-of-the-art baselines with high efficiency, demonstrating the effectiveness of ExpGCN in explainable recommendations.",,"Explainable recommendation, Recommender system, Graph Neural Network, Multi-task learning, Collaborative filtering",,,Neural Networks
7,,KAUR2023100507,"Kaur, Gurinder; Liu, Fei; Chen, Yi-Ping Phoebe",A deep learning knowledge graph neural network for recommender systems,Machine Learning with Applications,14.0,,,100507,2023,,,https://www.sciencedirect.com/science/article/pii/S2666827023000609,,,,,,,,,,,,,"Knowledge graphs are becoming the new state-of-the-art for recommender systems. This paper is based on knowledge graphs to alleviate the problem of data sparsity. Various methods have been recently deployed to solve this problem which largely attempts to study user-item representation and then recommend items to users based on these representations. Although these methods are effective, they lack explainability for recommendations and do not mine side information. In this paper, we propose the use of knowledge graphs which includes additional information about users and items in addition to the use of a user/item interaction matrix. The vital element of our model is neighbourhood aggregation for collaborative filtering. Every user and item are associated with an ID embedding, which is circulated on the interaction graph for users, items, and their attributes. We obtain the final embeddings by combining the embeddings learned at various hidden layers with a biased sum. Our model is easier to train and achieves better performance compared to graph neural network-based collaborative filtering (GCF) and other state-of-the-art recommender methods. We provide evidence for our argument by analytically comparing the knowledge graph convolution network (KGCN) with GCF and eight other state-of-the-art methods, using similar experimental settings and the same datasets.",,"Collaborative filtering, Graph neural network, Recommender system, Knowledge graph",,,Machine Learning with Applications
7,,YANG2020106194,"Yang, Zuoxi; Dong, Shoubin",HAGERec: Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation,Knowledge-Based Systems,204.0,,,106194,2020,,,https://www.sciencedirect.com/science/article/pii/S0950705120304196,,,,,,,,,,,,,"Knowledge graph (KG) can provide auxiliary information for recommender system to alleviate the sparsity and cold start problems, while graph convolutional networks (GCN) has recently been established as the state-of-the-art representation learning method. The combination of them is a promising perspective to improve the performance of graph-structured recommendation. However, most of GCN-based recommendations focus on homogeneous graph or user/item-similarity graph, fail to fully make use of the complex and rich semantics between entities in heterogeneous knowledge graph. In this paper, we develop Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation (HAGERec) to explore users’ potential preferences from the high-order connectivity structure of heterogeneous knowledge graph. To exploit semantic information, HAGERec simultaneously learn the representations of users and items via a bi-directional information propagation strategy. Specifically, the entity’s representation can be aggregated through messages passing from its local proximity structure, and a hierarchical attention mechanism is developed to adaptively characterize and adjust collaborative signals. With the help of the attention mechanism, an attentive entity sampling strategy is proposed to select relevant neighbor entities, and the explainability is endowed to the model by building knowledge-aware connectivity. Experiments conducted on four real-world public datasets demonstrate the state-of-the-art performance and the strong explainability of HAGERec.",,"Recommender system, Graph convolutional network, Hierarchical attention, Knowledge graph",,,Knowledge-Based Systems
7,,LI2024112042,"Li, Weisheng; Zhong, Hao; Zhou, Junming; Chang, Chao; Lin, Ronghua; Tang, Yong",An attention mechanism and residual network based knowledge graph-enhanced recommender system,Knowledge-Based Systems,299.0,,,112042,2024,,,https://www.sciencedirect.com/science/article/pii/S0950705124006762,,,,,,,,,,,,,"Recommender systems enhanced by a knowledge graph (KG) have attained widespread popularity and attention in recent years. However, traditional KG-based recommender systems encounter the challenge of gradient explosion as the network depth increases. Additionally, the abundance of unreliable paths in a KG has a detrimental impact on feature representation learning. In this article, we propose a KG-enhanced recommender system based on residual network and attention mechanism, which can capture high-order connectivity and long-range dependencies of the KG. Specifically, a resource allocation approach is employed to calculate the resource amount, which is subsequently utilized to evaluate the path reliability of the KG. After completing path extraction, we employ an attention mechanism to capture semantic correlations and structural information. To leverage the KG for enhancing recommender systems, we design a deep residual network with shortcut connections, effectively amalgamating advanced and abstract features using deep neural networks. The introduction of shortcut connections not only facilitates the fitting of residual mappings but also mitigates potential issues such as gradient explosion and convergence difficulties due to excessive network depth. Extensive experiments conducted on three standard datasets over baseline methods have demonstrated the superiority of our proposed recommender system.",,"Knowledge graph, Recommender system, Residual network, Attention mechanism",,,Knowledge-Based Systems
7,,WANG2020436,"Wang, Tongxuan; Zheng, Xiaolong; He, Saike; Zhang, Zhu; Wu, Desheng Dash",Learning user-item paths for explainable recommendation,IFAC-PapersOnLine,53.0,5.0,,436-440,2020,,3rd IFAC Workshop on Cyber-Physical & Human Systems CPHS 2020,https://www.sciencedirect.com/science/article/pii/S2405896321002305,,,,,,,,,,,,,"Knowledge graph based explainable recommendation system is a kind of personalized recommendation which uses side information to solve the reason why recommending an item. Previous study has not fully explored the connection between users and items in knowledge graph, especially the problem of overall semantic representation, and can not capture the high level semantic representation of the path, it is difficult for existing path-based methods to clarify the overall semantics of paths. Especially when the path contains similar entities but different relationship. In this paper, we propose a model named Meta-Path-based Explainable Recommendation System (MPERS) to represent the paths in the knowledge graph through the semantic information of entities and relationships, and distinguish the different contributions that different paths make to conduct users’ preference. The experimental study demonstrates the superiority of our method compared with the state-of-the-art ones",,"explainable recommendation, knowledge graph, deep neural networks",,,IFAC-PapersOnLine
7,,GUO2021185,"Guo, Siyuan; Wang, Ying; Yuan, Hao; Huang, Zeyu; Chen, Jianwei; Wang, Xin",TAERT: Triple-Attentional Explainable Recommendation with Temporal Convolutional Network,Information Sciences,567.0,,,185-200,2021,,,https://www.sciencedirect.com/science/article/pii/S0020025521002772,,,,,,,,,,,,,"Explainable Recommendation aims at not only providing the recommended items to users, but also enabling users to be aware of why these items are recommended. To better understand the recommended results, textual reviews have been playing an increasingly important role in the recommender systems. However, how to learn the latent representation of user preferences and item features, and how to model the interactions between them effectively via specific aspects in the reviews are two crucial problems in the explainable recommendation. To this end, we propose a novel Triple-Attentional Explainable Recommendation with Temporal Convolutional Network, named TAERT, which is to jointly generate recommendation results and explanations. Specifically, we first explore a feature learning method based on Temporal Convolutional Network (TCN) to derive word-aware and review-aware vector representations. Then, we introduce three levels of attention networks to model word contribution, review usefulness and importance of latent factors, respectively. Finally, the predicted rating is inferred by the factor-level attention based prediction layer. Furthermore, the attention mechanism is also conducive to identifying the representative item reviews and highlighting the informative words to generate explanations. Compared with the state-of-the-art methods, comprehensive experiments on six real-world datasets are conducted to verify the effectiveness on both recommendation and explanation.",,"Recommender system, Explainable recommendation, Triple attention networks, Temporal Convolutional Network, Rating prediction",,,Information Sciences
7,,MARKCHOM2023110258,"Markchom, Thanet; Liang, Huizhi; Ferryman, James",Scalable and explainable visually-aware recommender systems,Knowledge-Based Systems,263.0,,,110258,2023,,,https://www.sciencedirect.com/science/article/pii/S0950705123000084,,,,,,,,,,,,,"Recommender systems are popularly used to deal with an information overload issue. Existing systems mainly focus on user–item interactions and semantic information derived from metadata of users and items to improve recommendation accuracy. Item images provide useful information to infer users’ individual preferences, especially for those domains where visual factors are influential such as fashion items. However, this type of information has been ignored by most previous work. To bridge this gap and meet the requirements of performance from the aspects of Accuracy, Scalability, and Explainability evaluation metrics, this paper proposes a scalable and explainable visually-aware recommender system framework called SEV-RS. This framework contains a visually-augmented heterogeneous information network, a scalable meta-path feature extraction method for multi-hop relations, and a shallow explainable meta-path based Collaborative Filtering recommendation approach. We compared SEV-RS with the state-of-the-art models such as the deep learning model using Graph Attention Network on two real-world datasets and one synthetic dataset. The results show that SEV-RS produced more accurate and more explainable recommendations. Also, SEV-RS has substantially less computational time than the compared deep learning models.",,"Recommender system, Heterogeneous information network, Meta-path, Visual information, Scalability, Explainability",,,Knowledge-Based Systems
7,,HAO2025113113,"Hao, Qingbo; Wang, Chundong; Xiao, Yingyuan; Zheng, Wenguang",IReGNN: Implicit review-enhanced graph neural network for explainable recommendation,Knowledge-Based Systems,311.0,,,113113,2025,,,https://www.sciencedirect.com/science/article/pii/S0950705125001601,,,,,,,,,,,,,"Explainable recommendations can not only recommend items to users but also provide corresponding explanations, which is crucial for enhancing the transparency, credibility, and security of the system. Reviews, as an important information source for explainable recommendations, have received considerable attention. However, existing review-based explainable recommendations focus primarily on exploring user preferences and item features, as well as generating explanations from reviews, overlooking the limitations imposed by review sparsity on model performance. To address this issue, we propose an Implicit Review-enhanced Graph Neural Network (IReGNN) for explainable recommendations. Specifically, we construct a review network and a rating network, respectively. For the review network, we adopt an unsupervised approach to mine different topics of users and items, thereby enhancing node attribute representations. On the other hand, for the rating network, we extract implicit relationships between individuals and generate virtual reviews under the constraint of topics, which can effectively alleviate the data sparsity issue. Finally, we leverage a spatial graph neural network to learn node representations, generating accurate recommendations and high-quality explanations. Through a series of experiments on three publicly available datasets, results demonstrate that IReGNN outperforms eight baseline models in terms of rating prediction and explanation quality. Moreover, our model also has certain advantages in sparse data scenarios. The model and datasets are released at: https://github.com/SamuelZack/IReGNN.git.",,"Explainable recommendations, Graph neural network, Implicit reviews, Topic extraction",,,Knowledge-Based Systems
7,,LIU2025113217,"Liu, Jianfang; Wang, Wei; Yi, Baolin; Zhang, Huanyu; Shen, Xiaoxuan",Semantic relation-aware graph attention network with noise augmented layer-wise contrastive learning for recommendation,Knowledge-Based Systems,314.0,,,113217,2025,,,https://www.sciencedirect.com/science/article/pii/S0950705125002643,,,,,,,,,,,,,"Recommender systems based on knowledge graphs enhance the explainability of recommendations by incorporating external knowledge. Nevertheless, the accuracy of recommendations heavily depends on dense interaction data and high-quality knowledge graphs, both of which commonly suffer from data sparsity. Introducing graph contrastive learning to enhance representation quality can effectively improve recommendation performance. Existing graph contrastive learning methods that use graph augmentation can alleviate the data sparsity problem. However, they often neglect the semantic modeling of relation embeddings and lack sufficient contrastive information, leading to insufficient utilization of the embedding space for relations and nodes. To address this, we propose a semantic relation-aware graph attention network with a noise augmented layer-wise contrastive learning model for recommendation, named SRGAN. Specifically, we design a semantic relation-aware graph attention network that updates the semantics of relations during multi-layer iterations to better capture user preferences. Additionally, we construct a noise-augmented layer-wise contrastive learning model, employing simple yet effective noise perturbations to generate contrastive views for entities and relations. By maximizing the consistency of the representations in each layer, the model achieves alignment with the lower-level features of the intermediate layers. Extensive experiments on three public benchmark datasets demonstrate that our proposed method significantly outperforms current approaches. To ensure reproducibility, we make the code and data from our experiments publicly available on https://github.com/liujianfang2021/SRGAN.",,"Contrastive learning, Semantic relation-aware, Knowledge graph, Noise augmented, Graph attention network, Recommendation",,,Knowledge-Based Systems
7,,WU2025129780,"Wu, Xiaotong; Qiu, Liqing; Zhao, Weidong",Cross-modal feature symbiosis for personalized meta-path generation in heterogeneous networks,Neurocomputing,633.0,,,129780,2025,,,https://www.sciencedirect.com/science/article/pii/S0925231225004527,,,,,,,,,,,,,"In heterogeneous graph neural networks (HGNNs), the capture of intricate relationships among various types of entities is essential to achieve advanced machine learning applications. Heterogeneous Information Networks (HINs), composed of interconnected multi-type nodes and edges, face significant challenges in managing semantic diversity and inherent heterogeneity. Traditional methods, which rely on manually designed meta-paths, struggle to adapt dynamically to personalized needs and often neglect the integration of structural and attribute features. To address these limitations, this paper introduces the Cross-Modal Symbiotic Meta-Path Generator (CSMPG) framework. CSMPG integrates two key modules: a Cross-Modal State Generation Module that encodes node structure and attribute information into task-aware state vectors and a Personalized Meta-Path Generation Module that dynamically generates and refines meta-paths using reinforcement learning. By leveraging downstream task feedback, CSMPG optimizes path selection to maximize performance. The framework effectively balances cross-modal feature integration and semantic diversity, uncovering impactful meta-paths that are often overlooked by traditional approaches. Experimental results demonstrate that CSMPG consistently enhances recommendation quality and significantly outperforms structure-only and predefined-path-based models.",,"Heterogeneous graph neural networks, Meta-path generation, Reinforcement learning, Cross-modal information processing",,,Neurocomputing
6,9781450360142.0,10.1145/3269206.3271739,"Wang, Hongwei; Zhang, Fuzheng; Wang, Jialin; Zhao, Miao; Li, Wenjie; Xie, Xing; Guo, Minyi",RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems,,,,,417–426,2018,"New York, NY, USA",,https://doi.org/10.1145/3269206.3271739,Proceedings of the ACM International Conference on Information and Knowledge Management,,,CIKM '18,,Association for Computing Machinery,,,,,,,"To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple ""ripples"" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.",,"knowledge graph, preference propagation, recommender systems",,,ACM International Conference on Information and Knowledge Management
6,9781450369763.0,10.1145/3357384.3357925,"Song, Weiping; Shi, Chence; Xiao, Zhiping; Duan, Zhijian; Xu, Yewen; Zhang, Ming; Tang, Jian",AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks,,,,,1161–1170,2019,"New York, NY, USA",,https://doi.org/10.1145/3357384.3357925,Proceedings of the ACM International Conference on Information and Knowledge Management,,,CIKM '19,,Association for Computing Machinery,,,,,,,"Click-through rate (CTR) prediction, which aims to predict the probability of a user clicking on an ad or an item, is critical to many online applications such as online advertising and recommender systems. The problem is very challenging since (1) the input features (e.g., the user id, user age, item id, item category) are usually sparse and high-dimensional, and (2) an effective prediction relies on high-order combinatorial features (a.k.a. cross features), which are very time-consuming to hand-craft by domain experts and are impossible to be enumerated. Therefore, there have been efforts in finding low-dimensional representations of the sparse and high-dimensional raw features and their meaningful combinations. In this paper, we propose an effective and efficient method called the AutoInt to automatically learn the high-order feature interactions of input features. Our proposed algorithm is very general, which can be applied to both numerical and categorical input features. Specifically, we map both the numerical and categorical features into the same low-dimensional space. Afterwards, a multi-head self-attentive neural network with residual connections is proposed to explicitly model the feature interactions in the low-dimensional space. With different layers of the multi-head self-attentive neural networks, different orders of feature combinations of input features can be modeled. The whole model can be efficiently fit on large-scale raw data in an end-to-end fashion. Experimental results on four real-world datasets show that our proposed approach not only outperforms existing state-of-the-art approaches for prediction but also offers good explainability. Code is available at: urlhttps://github.com/DeepGraphLearning/RecommenderSystems.",,"ctr prediction, explainable recommendation, high-order feature interactions, self attention",,,ACM International Conference on Information and Knowledge Management
6,9781450355520.0,10.1145/3219819.3219965,"Hu, Binbin; Shi, Chuan; Zhao, Wayne Xin; Yu, Philip S.",Leveraging Meta-path based Context for Top- N Recommendation with A Neural Co-Attention Model,,,,,1531–1540,2018,"New York, NY, USA",,https://doi.org/10.1145/3219819.3219965,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining,,,KDD '18,,Association for Computing Machinery,,,,,,,"Heterogeneous information network (HIN) has been widely adopted in recommender systems due to its excellence in modeling complex context information. Although existing HIN based recommendation methods have achieved performance improvement to some extent, they have two major shortcomings. First, these models seldom learn an explicit representation for path or meta-path in the recommendation task. Second, they do not consider the mutual effect between the meta-path and the involved user-item pair in an interaction. To address these issues, we develop a novel deep neural network with the co-attention mechanism for leveraging rich meta-path based context for top-N recommendation. We elaborately design a three-way neural interaction model by explicitly incorporating meta-path based context. To construct the meta-path based context, we propose to use a priority based sampling technique to select high-quality path instances. Our model is able to learn effective representations for users, items and meta-path based context for implementing a powerful interaction function. The co-attention mechanism improves the representations for meta-path based con- text, users and items in a mutual enhancement way. Extensive experiments on three real-world datasets have demonstrated the effectiveness of the proposed model. In particular, the proposed model performs well in the cold-start scenario and has potentially good interpretability for the recommendation results.",,"attention mechanism, deep learning, heterogeneous information network, recommender system",,,ACM SIGKDD Conference on Knowledge Discovery and Data Mining
6,9781450356398.0,10.1145/3178876.3186070,"Chen, Chong; Zhang, Min; Liu, Yiqun; Ma, Shaoping",Neural Attentional Rating Regression with Review-level Explanations,,,,,1583–1592,2018,"Republic and Canton of Geneva, CHE",,https://doi.org/10.1145/3178876.3186070,Proceedings of the World Wide Web Conference,,,WWW '18,,International World Wide Web Conferences Steering Committee,,,,,,,"Reviews information is dominant for users to make online purchasing decisions in e-commerces. However, the usefulness of reviews is varied. We argue that less-useful reviews hurt model's performance, and are also less meaningful for user's reference. While some existing models utilize reviews for improving the performance of recommender systems, few of them consider the usefulness of reviews for recommendation quality. In this paper, we introduce a novel attention mechanism to explore the usefulness of reviews, and propose a Neural Attentional Regression model with Review-level Explanations (NARRE) for recommendation. Specifically, NARRE can not only predict precise ratings, but also learn the usefulness of each review simultaneously. Therefore, the highly-useful reviews are obtained which provide review-level explanations to help users make better and faster decisions. Extensive experiments on benchmark datasets of Amazon and Yelp on different domains show that the proposed NARRE model consistently outperforms the state-of-the-art recommendation approaches, including PMF, NMF, SVD++, HFT, and DeepCoNN in terms of rating prediction, by the proposed attention model that takes review usefulness into consideration. Furthermore, the selected reviews are shown to be effective when taking existing review-usefulness ratings in the system as ground truth. Besides, crowd-sourcing based evaluations reveal that in most cases, NARRE achieves equal or even better performances than system's usefulness rating method in selecting reviews. And it is flexible to offer great help on the dominant cases in real e-commerce scenarios when the ratings on review-usefulness are not available in the system.",,"explainable recommendation, neural attention network, recommender systems, review usefulness",,,ACM Web Conference
6,9781450366748.0,10.1145/3308558.3313705,"Cao, Yixin; Wang, Xiang; He, Xiangnan; Hu, Zikun; Chua, Tat-Seng",Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences,,,,,151–161,2019,"New York, NY, USA",,https://doi.org/10.1145/3308558.3313705,The World Wide Web Conference,,,WWW '19,,Association for Computing Machinery,,,,,,,"Incorporating knowledge graph (KG) into recommender system is promising in improving the recommendation accuracy and explainability. However, existing methods largely assume that a KG is complete and simply transfer the ”knowledge” in KG at the shallow level of entity raw data or embeddings. This may lead to suboptimal performance, since a practical KG can hardly be complete, and it is common that a KG has missing facts, relations, and entities. Thus, we argue that it is crucial to consider the incomplete nature of KG when incorporating it into recommender system. In this paper, we jointly learn the model of recommendation and knowledge graph completion. Distinct from previous KG-based recommendation methods, we transfer the relation information in KG, so as to understand the reasons that a user likes an item. As an example, if a user has watched several movies directed by (relation) the same person (entity), we can infer that the director relation plays a critical role when the user makes the decision, thus help to understand the user's preference at a finer granularity. Technically, we contribute a new translation-based recommendation model, which specially accounts for various preferences in translating a user to an item, and then jointly train it with a KG completion model by combining several transfer schemes. Extensive experiments on two benchmark datasets show that our method outperforms state-of-the-art KG-based recommendation methods. Further analysis verifies the positive effect of joint training on both tasks of recommendation and KG completion, and the advantage of our model in understanding user preference. We publish our project at https://github.com/TaoMiner/joint-kg-recommender.",,"Embedding, Item Recommendation, Joint Model, Knowledge Graph",,,ACM Web Conference
6,9781450380164.0,10.1145/3397271.3401137,"Wang, Xiang; Jin, Hongye; Zhang, An; He, Xiangnan; Xu, Tong; Chua, Tat-Seng",Disentangled Graph Collaborative Filtering,,,,,1001–1010,2020,"New York, NY, USA",,https://doi.org/10.1145/3397271.3401137,Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval,,,SIGIR '20,,Association for Computing Machinery,,,,,,,"Learning informative representations of users and items from the interaction data is of crucial importance to collaborative filtering (CF). Present embedding functions exploit user-item relationships to enrich the representations, evolving from a single user-item instance to the holistic interaction graph. Nevertheless, they largely model the relationships in a uniform manner, while neglecting the diversity of user intents on adopting the items, which could be to pass time, for interest, or shopping for others like families. Such uniform approach to model user interests easily results in suboptimal representations, failing to model diverse relationships and disentangle user intents in representations.In this work, we pay special attention to user-item relationships at the finer granularity of user intents. We hence devise a new model, Disentangled Graph Collaborative Filtering (DGCF), to disentangle these factors and yield disentangled representations. Specifically, by modeling a distribution over intents for each user-item interaction, we iteratively refine the intent-aware interaction graphs and representations. Meanwhile, we encourage independence of different intents. This leads to disentangled representations, effectively distilling information pertinent to each intent. We conduct extensive experiments on three benchmark datasets, and DGCF achieves significant improvements over several state-of-the-art models like NGCF, DisenGCN, and MacridVAE. Further analyses offer insights into the advantages of DGCF on the disentanglement of user intents and interpretability of representations. Our codes are available in https://github.com/ xiangwang1223/disentangled_graph_collaborative_filtering.",,"collaborative filtering, disentangled representation learning, explainable recommendation, graph neural networks",,,International ACM SIGIR Conference on Research and Development in Information Retrieval
6,9781450368896.0,10.1145/3343031.3351034,"Wei, Yinwei; Wang, Xiang; Nie, Liqiang; He, Xiangnan; Hong, Richang; Chua, Tat-Seng",MMGCN: Multi-modal Graph Convolution Network for Personalized Recommendation of Micro-video,,,,,1437–1445,2019,"New York, NY, USA",,https://doi.org/10.1145/3343031.3351034,Proceedings of the ACM International Conference on Multimedia,,,MM '19,,Association for Computing Machinery,,,,,,,"Personalized recommendation plays a central role in many online content sharing platforms. To provide quality micro-video recommendation service, it is of crucial importance to consider the interactions between users and items (i.e. micro-videos) as well as the item contents from various modalities (e.g. visual, acoustic, and textual). Existing works on multimedia recommendation largely exploit multi-modal contents to enrich item representations, while less effort is made to leverage information interchange between users and items to enhance user representations and further capture user's fine-grained preferences on different modalities. In this paper, we propose to exploit user-item interactions to guide the representation learning in each modality, and further personalized micro-video recommendation. We design a Multi-modal Graph Convolution Network (MMGCN) framework built upon the message-passing idea of graph neural networks, which can yield modal-specific representations of users and micro-videos to better capture user preferences. Specifically, we construct a user-item bipartite graph in each modality, and enrich the representation of each node with the topological structure and features of its neighbors. Through extensive experiments on three publicly available datasets, Tiktok, Kwai, and MovieLens, we demonstrate that our proposed model is able to significantly outperform state-of-the-art multi-modal recommendation methods.",,"graph convolution network, micro-video understanding, multi-modal recommendation",,,ACM International Conference on Multimedia
6,9781450337946.0,10.1145/2806416.2806504,"He, Xiangnan; Chen, Tao; Kan, Min-Yen; Chen, Xiao",TriRank: Review-aware Explainable Recommendation by Modeling Aspects,,,,,1661–1670,2015,"New York, NY, USA",,https://doi.org/10.1145/2806416.2806504,ACM International Conference on Information and Knowledge Management,,,CIKM '15,,Association for Computing Machinery,,,,,,,"Most existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions.",,"aspects, comments, explanable recommendation, reviews, top-n recommendation, tripartite graph ranking",,,ACM International Conference on Information and Knowledge Management
6,9781450355810.0,10.1145/3159652.3159668,"Chen, Xu; Xu, Hongteng; Zhang, Yongfeng; Tang, Jiaxi; Cao, Yixin; Qin, Zheng; Zha, Hongyuan",Sequential Recommendation with User Memory Networks,,,,,108–116,2018,"New York, NY, USA",,https://doi.org/10.1145/3159652.3159668,Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,,,WSDM '18,,Association for Computing Machinery,,,,,,,"User preferences are usually dynamic in real-world recommender systems, and a user»s historical behavior records may not be equally important when predicting his/her future interests. Existing recommendation algorithms -- including both shallow and deep approaches -- usually embed a user»s historical records into a single latent vector/representation, which may have lost the per item- or feature-level correlations between a user»s historical records and future interests. In this paper, we aim to express, store, and manipulate users» historical records in a more explicit, dynamic, and effective manner. To do so, we introduce the memory mechanism to recommender systems. Specifically, we design a memory-augmented neural network (MANN) integrated with the insights of collaborative filtering for recommendation. By leveraging the external memory matrix in MANN, we store and update users» historical records explicitly, which enhances the expressiveness of the model. We further adapt our framework to both item- and feature-level versions, and design the corresponding memory reading/writing operations according to the nature of personalized recommendation scenarios. Compared with state-of-the-art methods that consider users» sequential behavior for recommendation, e.g., sequential recommenders with recurrent neural networks (RNN) or Markov chains, our method achieves significantly and consistently better performance on four real-world datasets. Moreover, experimental analyses show that our method is able to extract the intuitive patterns of how users» future actions are affected by previous behaviors.",,"collaborative filtering, memory networks, sequential recommendation",,,ACM International Conference on Web Search and Data Mining
6,9781450346528.0,10.1145/3109859.3109890,"Seo, Sungyong; Huang, Jing; Yang, Hao; Liu, Yan",Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction,,,,,297–305,2017,"New York, NY, USA",,https://doi.org/10.1145/3109859.3109890,Proceedings of the Eleventh ACM Conference on Recommender Systems,,,RecSys '17,,Association for Computing Machinery,,,,,,,"Recently, many e-commerce websites have encouraged their users to rate shopping items and write review texts. This review information has been very useful for understanding user preferences and item properties, as well as enhancing the capability to make personalized recommendations of these websites. In this paper, we propose to model user preferences and item properties using convolutional neural networks (CNNs) with dual local and global attention, motivated by the superiority of CNNs to extract complex features. By using aggregated review texts from a user and aggregated review text for an item, our model can learn the unique features (embedding) of each user and each item. These features are then used to predict ratings. We train these user and item networks jointly which enable the interaction between users and items in a similar way as matrix factorization. The local attention provides us insight on a user's preferences or an item's properties. The global attention helps CNNs focus on the semantic meaning of the whole review text. Thus, the combined local and global attentions enable an interpretable and better-learned representation of users and items. We validate the proposed models by testing on popular review datasets in Yelp and Amazon and compare the results with matrix factorization (MF), the hidden factor and topical (HFT) model, and the recently proposed convolutional matrix factorization (ConvMF+). Our proposed CNNs with dual attention model outperforms HFT and ConvMF+ in terms of mean square errors (MSE). In addition, we compare the user/item embeddings learned from these models for classification and recommendation. These results also confirm the superior quality of user/item embeddings learned from our model.",,"attention model, convolutional neural network, deep learning for recommender systems",,,ACM Conference on Recommender Systems
6,9781450361729.0,10.1145/3331184.3331203,"Xian, Yikun; Fu, Zuohui; Muthukrishnan, S.; de Melo, Gerard; Zhang, Yongfeng",Reinforcement Knowledge Graph Reasoning for Explainable Recommendation,,,,,285–294,2019,"New York, NY, USA",,https://doi.org/10.1145/3331184.3331203,Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval,,,SIGIR'19,,Association for Computing Machinery,,,,,,,"Recent advances in personalized recommendation have sparked great interest in the exploitation of rich structured information provided by knowledge graphs. Unlike most existing approaches that only focus on leveraging knowledge graphs for more accurate recommendation, we aim to conduct explicit reasoning with knowledge for decision making so that the recommendations are generated and supported by an interpretable causal inference procedure. To this end, we propose a method called Policy-Guided Path Reasoning (PGPR), which couples recommendation and interpretability by providing actual paths in a knowledge graph. Our contributions include four aspects. We first highlight the significance of incorporating knowledge graphs into recommendation to formally define and interpret the reasoning process. Second, we propose a reinforcement learning (RL) approach featured by an innovative soft reward strategy, user-conditional action pruning and a multi-hop scoring function. Third, we design a policy-guided graph search algorithm to efficiently and effectively sample reasoning paths for recommendation. Finally, we extensively evaluate our method on several large-scale real-world benchmark datasets, obtaining favorable results compared with state-of-the-art methods.",,"explainability, knowledge graphs, recommendation system, reinforcement learning",,,International ACM SIGIR Conference on Research and Development in Information Retrieval
6,9781450383127.0,10.1145/3442381.3450133,"Wang, Xiang; Huang, Tinglin; Wang, Dingxian; Yuan, Yancheng; Liu, Zhenguang; He, Xiangnan; Chua, Tat-Seng",Learning Intents behind Interactions with Knowledge Graph for Recommendation,,,,,878–887,2021,"New York, NY, USA",,https://doi.org/10.1145/3442381.3450133,Proceedings of the Web Conference,,,WWW '21,,Association for Computing Machinery,,,,,,,"Knowledge graph (KG) plays an increasingly important role in recommender systems. A recent technical trend is to develop end-to-end models founded on graph neural networks (GNNs). However, existing GNN-based models are coarse-grained in relational modeling, failing to (1) identify user-item relation at a fine-grained level of intents, and (2) exploit relation dependencies to preserve the semantics of long-range connectivity. In this study, we explore intents behind a user-item interaction by using auxiliary item knowledge, and propose a new model, Knowledge Graph-based Intent Network (KGIN). Technically, we model each intent as an attentive combination of KG relations, encouraging the independence of different intents for better model capability and interpretability. Furthermore, we devise a new information aggregation scheme for GNN, which recursively integrates the relation sequences of long-range connectivity (i.e., relational paths). This scheme allows us to distill useful information about user intents and encode them into the representations of users and items. Experimental results on three benchmark datasets show that, KGIN achieves significant improvements over the state-of-the-art methods like KGAT&nbsp;[41], KGNN-LS&nbsp;[38], and CKAN&nbsp;[47]. Further analyses show that KGIN offers interpretable explanations for predictions by identifying influential intents and relational paths. The implementations are available at https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network.",,"Graph Neural Networks, Knowledge Graph, Recommendation",,,ACM Web Conference
6,9781450356398.0,10.1145/3178876.3186145,"Cheng, Zhiyong; Ding, Ying; Zhu, Lei; Kankanhalli, Mohan",Aspect-Aware Latent Factor Model: Rating Prediction with Ratings and Reviews,,,,,639–648,2018,"Republic and Canton of Geneva, CHE",,https://doi.org/10.1145/3178876.3186145,Proceedings of the World Wide Web Conference,,,WWW '18,,International World Wide Web Conferences Steering Committee,,,,,,,"Although latent factor models (e.g., matrix factorization) achieve good accuracy in rating prediction, they suffer from several problems including cold-start, non-transparency, and suboptimal recommendation for local users or items. In this paper, we employ textual review information with ratings to tackle these limitations. Firstly, we apply a proposed aspect-aware topic model (ATM) on the review text to model user preferences and item features from different aspects, and estimate the aspect importance of a user towards an item. The aspect importance is then integrated into a novel aspect-aware latent factor model (ALFM), which learns user's and item's latent factors based on ratings. In particular, ALFM introduces a weighted matrix to associate those latent factors with the same set of aspects discovered by ATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, an aspect rating is weighted by an aspect importance, which is dependent on the targeted user's preferences and targeted item's features. Therefore, it is expected that the proposed method can model a user's preferences on an item more accurately for each user-item pair locally. Comprehensive experimental studies have been conducted on 19 datasets from Amazon and Yelp 2017 Challenge dataset. Results show that our method achieves significant improvement compared with strong baseline methods, especially for users with only few ratings. Moreover, our model could interpret the recommendation results in depth.",,"aspect-aware, matrix factorization, recommendation, review-aware, topic model",,,ACM Web Conference
6,9781450356398.0,10.1145/3178876.3186154,"Tay, Yi; Anh Tuan, Luu; Hui, Siu Cheung",Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking,,,,,729–739,2018,"Republic and Canton of Geneva, CHE",,https://doi.org/10.1145/3178876.3186154,Proceedings of the World Wide Web Conference,,,WWW '18,,International World Wide Web Conferences Steering Committee,,,,,,,"This paper proposes a new neural architecture for collaborative ranking with implicit feedback. Our model, LRML (Latent Relational Metric Learning) is a novel metric learning approach for recommendation. More specifically, instead of simple push-pull mechanisms between user and item pairs, we propose to learn latent relations that describe each user item interaction. This helps to alleviate the potential geometric inflexibility of existing metric learning approaches. This enables not only better performance but also a greater extent of modeling capability, allowing our model to scale to a larger number of interactions. In order to do so, we employ a augmented memory module and learn to attend over these memory blocks to construct latent relations. The memory-based attention module is controlled by the user-item interaction, making the learned relation vector specific to each user-item pair. Hence, this can be interpreted as learning an exclusive and optimal relational translation for each user-item interaction. The proposed architecture demonstrates the state-of-the-art performance across multiple recommendation benchmarks. LRML outperforms other metric learning models by 6\%-7.5\% in terms of Hits@10 and nDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover, qualitative studies also demonstrate evidence that our proposed model is able to infer and encode explicit sentiment, temporal and attribute information despite being only trained on implicit feedback. As such, this ascertains the ability of LRML to uncover hidden relational structure within implicit datasets.",,"attention mechanism, collaborative filtering, collaborative ranking, deep learning, implicit feedback, information retrieval, neural networks, recommender system",,,ACM Web Conference
6,9781450383127.0,10.1145/3442381.3449788,"Zheng, Yu; Gao, Chen; Li, Xiang; He, Xiangnan; Li, Yong; Jin, Depeng",Disentangling User Interest and Conformity for Recommendation with Causal Embedding,,,,,2980–2991,2021,"New York, NY, USA",,https://doi.org/10.1145/3442381.3449788,Proceedings of the Web Conference,,,WWW '21,,Association for Computing Machinery,,,,,,,"Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users’ conformity towards popular items, which entangles users’ real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation.",,"Recommender systems, causal embedding, popularity bias",,,ACM Web Conference
6,9798400704666.0,10.1145/3631700.3665226,"Afreen, Neda; Balloccu, Giacomo; Boratto, Ludovico; Fenu, Gianni; Malloci, Francesca Maridina; Marras, Mirko; Martis, Andrea Giovanni",Learner-centered Ontology for Explainable Educational Recommendation,,,,,567–575,2024,"New York, NY, USA",,https://doi.org/10.1145/3631700.3665226,"Adjunct Proceedings of the ACM Conference on User Modeling, Adaptation and Personalization",,,UMAP Adjunct '24,,Association for Computing Machinery,,,,,,,"Ontologies form the core of knowledge graphs, which act as faithful, semantic-rich sources for training models in delivering explainable recommendations. These models learn to extract logical paths between learners and resources to be recommended within the knowledge graph, according to behavior- and content-based patterns. Extracted paths are then used not only to provide recommendations, but also to generate accompanying textual explanations. Despite the potential of this approach, current ontologies derived from the traditional learner-resource interaction data fall short in terms of richness from an educational perspective. Conversely, general-purpose ontologies, while comprehensive in educational aspects, are overly complex for recommendation tasks. Unfortunately, a suboptimal ontology might prevent to articulate reasoning paths, and thus explanations, relevant for learners within the knowledge graph. To counter this limitation, in this paper, we propose LOXER, a novel ontology designed to unlock learner-centered logical paths for explainable educational recommendation. Our design integrates insights from diverse sources, including feedback from a local co-design group of learners, observations from specialized traditional large-scale educational recommendation datasets, and connections with well-known vocabularies of other existing ontologies. To validate our ontology, we conducted an evaluation of the explanation types it enables, involving university and lifelong learners and assessing explanation properties like effectiveness, decision-making speed, motivation, satisfaction, and confidence. Results show our ontology’s ability to foster diverse considerations during the learners’ decision-making process and to establish a semantic structure for knowledge graphs for explainable recommendation.",,"Explainability., Ontology, Recommendation",,,"Adjunct ACM Conference on User Modeling, Adaptation and Personalization"
6,9798400704901.0,10.1145/3637528.3671781,"Zhang, Jingsen; Tang, Jiakai; Chen, Xu; Yu, Wenhui; Hu, Lantao; Jiang, Peng; Li, Han",Natural Language Explainable Recommendation with Robustness Enhancement,,,,,4203–4212,2024,"New York, NY, USA",,https://doi.org/10.1145/3637528.3671781,Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,,,KDD '24,,Association for Computing Machinery,,,,,,,"Natural language explainable recommendation has become a promising direction to facilitate more efficient and informed user decisions. Previous models mostly focus on how to enhance the explanation accuracy. However, the robustness problem has been largely ignored, which requires the explanations generated for similar user-item pairs should not be too much different. Different from traditional classification problems, improving the robustness of natural languages has two unique characteristics: (1) Different token importances, that is, different tokens play various roles in representing the complete sentence, and the robustness requirements for predicting them should also be different. (2) Continuous token semantics, that is, the similarity of the output should be judged based on semantics, and the sequences without any token-level overlap may also be highly similar. Based on these characteristics, we formulate and solve a novel problem in the recommendation domain, that is, robust natural language explainable recommendation. To the best of our knowledge, it is the first time in this field. Specifically, we base our modeling on adversarial robust optimization and design four types of heuristic methods to modify the adversarial outputs with weighted token probabilities and synonym replacements. Furthermore, to consider the mutual influence between the above characteristics, we regard language generation as a decision-making problem and design a dual-policy reinforcement learning framework to improve the robustness of the generated languages. We conduct extensive experiments to demonstrate the effectiveness of our framework.",,"adversarial learning, explainable recommendation, natural language explanations",,,ACM SIGKDD Conference on Knowledge Discovery and Data Mining
6,9781450394161.0,10.1145/3543507.3583260,"Zhang, Jingsen; Chen, Xu; Tang, Jiakai; Shao, Weiqi; Dai, Quanyu; Dong, Zhenhua; Zhang, Rui",Recommendation with Causality enhanced Natural Language Explanations,,,,,876–886,2023,"New York, NY, USA",,https://doi.org/10.1145/3543507.3583260,Proceedings of the ACM Web Conference,,,WWW '23,,Association for Computing Machinery,,,,,,,"Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.",,"Explainable Recommendation, Natural Language Explanations",,,ACM Web Conference
6,9798400704086.0,10.1145/3624918.3625331,"Yu, Yi; Sugiyama, Kazunari; Jatowt, Adam","AdaReX: Cross-Domain, Adaptive, and Explainable Recommender System",,,,,272–281,2023,"New York, NY, USA",,https://doi.org/10.1145/3624918.3625331,Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region,,,SIGIR-AP '23,,Association for Computing Machinery,,,,,,,"Explainability is an inherent issue of recommender systems and has received a lot of attention recently. Generative explainable recommendation, which provides personalized explanations by generating textual rationales, is emerging as an effective solution. Despite promising, current methods face limitations in their reliance on dense training data, which hinders the generalizability of explainable recommender systems. Our work tackles a novel problem of cross-domain explainable recommendation aiming to extend the generalizability of explainable recommender systems. To solve this, we propose a novel approach that models aspects extracted from past reviews, to empower the explainable recommender systems by leveraging knowledge from other domains. Specifically, we propose AdaReX (Adaptive eXplainable Recommendation), to model auxiliary and target domains simultaneously. By performing specific tasks in respective domains and their interconnection via a discriminator model, AdaReX allows the aspect sequences to learn common knowledge across different domains and tasks. Furthermore, through our proposed optimization objective, the learning of aspect sequence is deeply cross-interacted with in-domain users and items’ latent factors, enabling the enhanced sharing of knowledge between domains. Our extensive experiments on real datasets demonstrate that our approach not only generates better explanations and recommendations for sparse users but also improves performance for general users.",,"Explainable Recommender System, Natural Language Generation",,,International ACM SIGIR Conference on Research and Development in Information Retrieval
6,9781450390965.0,10.1145/3485447.3511937,"Geng, Shijie; Fu, Zuohui; Tan, Juntao; Ge, Yingqiang; de Melo, Gerard; Zhang, Yongfeng",Path Language Modeling over Knowledge Graphsfor Explainable Recommendation,,,,,946–955,2022,"New York, NY, USA",,https://doi.org/10.1145/3485447.3511937,Proceedings of the ACM Web Conference,,,WWW '22,,Association for Computing Machinery,,,,,,,"To facilitate human decisions with credible suggestions, personalized recommender systems should have the ability to generate corresponding explanations while making recommendations. Knowledge graphs (KG), which contain comprehensive information about users and products, are widely used to enable this. By reasoning over a KG in a node-by-node manner, existing explainable models provide a KG-grounded path for each user-recommended item. Such paths serve as an explanation and reflect the historical behavior pattern of the user. However, not all items can be reached following the connections within the constructed KG under finite hops. Hence, previous approaches are constrained by a recall bias in terms of existing connectivity of KG structures. To overcome this, we propose a novel Path Language Modeling Recommendation (PLM-Rec) framework, learning a language model over KG paths consisting of entities and edges. Through path sequence decoding, PLM-Rec unifies recommendation and explanation in a single step and fulfills them simultaneously. As a result, PLM-Rec not only captures the user behaviors but also eliminates the restriction to pre-existing KG connections, thereby alleviating the aforementioned recall bias. Moreover, the proposed technique makes it possible to conduct explainable recommendation even when the KG is sparse or possesses a large number of relations. Experiments and extensive ablation studies on three Amazon e-commerce datasets demonstrate the effectiveness and explainability of the PLM-Rec framework.",,"Explainable Recommendation, Knowledge Graph, Path Language Model, Recall Bias, Recommender Systems",,,ACM Web Conference
6,9781450390965.0,10.1145/3485447.3512029,"Pan, Sicheng; Li, Dongsheng; Gu, Hansu; Lu, Tun; Luo, Xufang; Gu, Ning",Accurate and Explainable Recommendation via Review Rationalization,,,,,3092–3101,2022,"New York, NY, USA",,https://doi.org/10.1145/3485447.3512029,Proceedings of the ACM Web Conference,,,WWW '22,,Association for Computing Machinery,,,,,,,"Auxiliary information, such as reviews, have been widely adopted to improve collaborative filtering (CF) algorithms, e.g., to boost the accuracy and provide explanations. However, most of the existing methods cannot distinguish between co-appearance and causality when learning from the reviews, so that they may rely on spurious correlations rather than causal relations in the recommendation — leading to poor generalization performance and unconvincing explanations. In this paper, we propose a Recommendation via Review Rationalization (R3) method including 1) a rationale generator to extract rationales from reviews to alleviate the effects of spurious correlations; 2) a rationale predictor to predict user ratings on items only from generated rationales; and 3) a correlation predictor upon both rationales and correlational features to ensure conditional independence between spurious correlations and rating predictions given causal rationales. Extensive experiments on real-world datasets show that the proposed method can achieve better generalization performance than state-of-the-art CF methods and provide causal-aware explanations even when the test data distribution changes.",,"explainability, rationalization, recommendation",,,ACM Web Conference
6,9798400702419.0,10.1145/3604915.3609491,"Bolz, Felix; Nurbakova, Diana; Calabretto, Sylvie; Gerl, Armin; Brunie, Lionel; Kosch, Harald","HUMMUS: A Linked, Healthiness-Aware, User-centered and Argument-Enabling Recipe Data Set for Recommendation",,,,,1–11,2023,"New York, NY, USA",,https://doi.org/10.1145/3604915.3609491,Proceedings of the ACM Conference on Recommender Systems,,,RecSys '23,,Association for Computing Machinery,,,,,,,"The overweight and obesity rate is increasing for decades worldwide. Healthy nutrition is, besides education and physical activity, one of the various keys to tackle this issue. In an effort to increase the availability of digital, healthy recommendations, the scientific area of food recommendation extends its focus from the accuracy of the recommendations to beyond-accuracy goals like transparency and healthiness. To address this issue a data basis is required, which in the ideal case encompasses user-item interactions like ratings and reviews, food-related information such as recipe details, nutritional data, and in the best case additional data which describes the food items and their relations semantically. Though several recipe recommendation data sets exist, to the best of our knowledge, a holistic large-scale healthiness-aware and connected data sets have not been made available yet. The lack of such data could partially explain the poor popularity of the topic of healthy food recommendation when compared to the domain of movie recommendation. In this paper, we show that taking into account only user-item interactions is not sufficient for a recommendation. To close this gap, we propose a connected data set called HUMMUS (Health-aware User-centered recoMMendation and argUment-enabling data Set) collected from Food.com containing multiple features including rich nutrient information, text reviews, and ratings, enriched by the authors with extra features such as Nutri-scores and connections to semantic data like the FoodKG and the FoodOn ontology. We hope that these data will contribute to the healthy food recommendation domain.",,"Explainable recommendation, Healthiness-aware recommendation, Knowledge graph, Nutrition scores, Recipe data set",,,ACM Conference on Recommender Systems
6,9798400716188.0,10.1145/3636555.3636898,"Frej, Jibril; Shah, Neel; Knezevic, Marta; Nazaretsky, Tanya; Kaser, Tanja",Finding Paths for Explainable MOOC Recommendation: A Learner Perspective,,,,,426–437,2024,"New York, NY, USA",,https://doi.org/10.1145/3636555.3636898,Proceedings of the Learning Analytics and Knowledge Conference,,,LAK '24,,Association for Computing Machinery,,,,,,,"The increasing availability of Massive Open Online Courses (MOOCs) has created a necessity for personalized course recommendation systems. These systems often combine neural networks with Knowledge Graphs (KGs) to achieve richer representations of learners and courses. While these enriched representations allow more accurate and personalized recommendations, explainability remains a significant challenge which is especially problematic for certain domains with significant impact such as education and online learning. Recently, a novel class of recommender systems that uses reinforcement learning and graph reasoning over KGs has been proposed to generate explainable recommendations in the form of paths over a KG. Despite their accuracy and interpretability on e-commerce datasets, these approaches have scarcely been applied to the educational domain and their use in practice has not been studied. In this work, we propose an explainable recommendation system for MOOCs that uses graph reasoning. To validate the practical implications of our approach, we conducted a user study examining user perceptions of our new explainable recommendations. We demonstrate the generalizability of our approach by conducting experiments on two educational datasets: COCO and Xuetang.",,"Explainable AI, MOOCs, Recommendation, User study",,,Learning Analytics and Knowledge Conference
6,9798400703713.0,10.1145/3616855.3635855,"Liu, Xu; Yu, Tong; Xie, Kaige; Wu, Junda; Li, Shuai",Interact with the Explanations: Causal Debiased Explainable Recommendation System,,,,,472–481,2024,"New York, NY, USA",,https://doi.org/10.1145/3616855.3635855,Proceedings of the ACM International Conference on Web Search and Data Mining,,,WSDM '24,,Association for Computing Machinery,,,,,,,"In recent years, the field of recommendation systems has witnessed significant advancements, with explainable recommendation systems gaining prominence as a crucial area of research. These systems aim to enhance user experience by providing transparent and compelling recommendations, accompanied by explanations. However, a persistent challenge lies in addressing biases that can influence the recommendations and explanations offered by these systems. Such biases often stem from a tendency to favor popular items and generate explanations that highlight their common attributes, thereby deviating from the objective of delivering personalized recommendations and explanations. While existing debiasing methods have been applied in explainable recommendation systems, they often overlook the model-generated explanations in tackling biases. Consequently, biases in model-generated explanations may persist, potentially compromising system performance and user satisfaction.To address biases in both model-generated explanations and recommended items, we discern the impact of model-generated explanations in recommendation through a formulated causal graph. Inspired by this causal perspective, we propose a novel approach termed Causal Explainable Recommendation System (CERS), which incorporates model-generated explanations into the debiasing process and enacts causal interventions based on user feedback on the explanations. By utilizing model-generated explanations as intermediaries between user-item interactions and recommendation results, we adeptly mitigate the biases via targeted causal interventions. Experimental results demonstrate the efficacy of CERS in reducing popularity bias while simultaneously improving recommendation performance, leading to more personalized and tailored recommendations. Human evaluation further affirms that CERS generates explanations tailored to individual users, thereby enhancing the persuasiveness of the system.",,"causal reasoning, debiased recommendation, explainable recommendation system",,,ACM International Conference on Web Search and Data Mining
6,9781450394086.0,10.1145/3539618.3591776,"Shuai, Jie; Wu, Le; Zhang, Kun; Sun, Peijie; Hong, Richang; Wang, Meng",Topic-enhanced Graph Neural Networks for Extraction-based Explainable Recommendation,,,,,1188–1197,2023,"New York, NY, USA",,https://doi.org/10.1145/3539618.3591776,Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval,,,SIGIR '23,,Association for Computing Machinery,,,,,,,"Review information has been demonstrated beneficial for the explainable recommendation. It can be treated as training corpora for generation-based methods or knowledge bases for extraction-based models. However, for generation-based methods, the sparsity of user-generated reviews and the high complexity of generative language models lead to a lack of personalization and adaptability. For extraction-based methods, focusing only on relevant attributes makes them invalid in situations where explicit attribute words are absent, limiting the potential of extraction-based models.To this end, in this paper, we focus on the explicit and implicit analysis of review information simultaneously and propose novel a Topic-enhanced Graph Neural Networks (TGNN) to fully explore review information for better explainable recommendations. To be specific, we first use a pre-trained topic model to analyze reviews at the topic level, and design a sentence-enhanced topic graph to model user preference explicitly, where topics are intermediate nodes between users and items. Corresponding sentences serve as edge features. Thus, the requirement of explicit attribute words can be mitigated. Meanwhile, we leverage a review-enhanced rating graph to model user preference implicitly, where reviews are also considered as edge features for fine-grained user-item interaction modeling. Next, user and item representations from two graphs are used for final rating prediction and explanation extraction. Extensive experiments on three real-world datasets demonstrate the superiority of our proposed TGNN with both recommendation accuracy and explanation quality.",,"explainable recommendation, graph neural network, review-based recommendation",,,International ACM SIGIR Conference on Research and Development in Information Retrieval
7,,Rana2022,"Rana, Arpit; D’Addio, Rafael M.; Manzato, Marcelo G.; Bridge, Derek",Extended recommendation-by-explanation,User Modeling and User-Adapted Interaction,32.0,1-2,,91–131,2022,,,,,,,,,User Modeling and User-Adapted Interaction,,,,,,,,,,,,User Modeling and User-Adapted Interaction
7,,Haque2025,"Haque, Akm Bahalul; Islam, Najmul; Mikalef, Patrick",To Explain or Not To Explain: An Empirical Investigation of AI-based Recommendations on Social Media Platforms,Electronic Markets,35.0,1,,,2025,,,,,,,,,Electronic Markets,,,,,,,,,,,,Electronic Markets
7,,Ranjbar2024,"Ranjbar, Niloofar; Momtazi, Saeedeh; Homayoonpour, Mohammadmehdi",Explaining recommendation system using counterfactual textual explanations,Machine Learning,113.0,4,,1989–2012,2024,,,,,,,,,Machine Learning,,,,,,,,,,,,Machine Learning
5,,CaroMartinez2024,"Caro-Martínez, Marta; Jorro-Aragoneses, José L.; Díaz-Agudo, Belén; Recio-García, Juan A.",Graph-Based Interface for Explanations by Examples in Recommender Systems: A User Study,,,,,28–41,2024,,,,Communications in Computer and Information Science,,,,,Communications in Computer and Information Science,,,,,,,,,,,,Communications in Computer and Information Science
7,,DeCampos2024,"De Campos, Luis M.; Fernández-Luna, Juan M.; Huete, Juan F.",An explainable content-based approach for recommender systems: a case study in journal recommendation for paper submission,User Modeling and User-Adapted Interaction,34.0,4,,1431–1465,2024,,,,,,,,,User Modeling and User-Adapted Interaction,,,,,,,,,,,,User Modeling and User-Adapted Interaction
7,,xie_wang_xu_chen_zheng_tang_2024,"Xie, Fenfang; Wang, Yuansheng; Xu, Kun; Chen, Liang; Zheng, Zibin; Tang, Mingdong",A Review-Level Sentiment Information Enhanced Multitask Learning Approach for Explainable Recommendation,IEEE Transactions on Computational Social Systems,11.0,5,,5925–5934,2024,,,,,,,,,IEEE Transactions on Computational Social Systems,,,,,,,,,,,,IEEE Transactions on Computational Social Systems
6,,le_abel_gouspillou_2023,"Le, Ngoc Luyen; Abel, Marie-Hélène; Gouspillou, Philippe",Combining Embedding-Based and Semantic-Based Models for Post-Hoc Explanations in Recommender Systems,"IEEE International Conference on Systems, Man and Cybernetics",,,,4619–4624,2023,,,,,,,,,,,,,,,,,,,,,"IEEE International Conference on Systems, Man and Cybernetics"
6,,bastola_shakya_2024,"Bastola, Rama; Shakya, Subarna",Knowledge-Enriched Graph Convolution Network for Hybrid Explainable Recommendation from Review Texts and Reasoning Path,International Conference on Inventive Computation Technologies,,,,590–599,2024,,,,,,,,,,,,,,,,,,,,,International Conference on Inventive Computation Technologies
7,,hu_liu_miao_lin_miao_2022,"Hu, Yidan; Liu, Yong; Miao, Chunyan; Lin, Gongqi; Miao, Yuan",Aspect-guided Syntax Graph Learning for Explainable Recommendation,IEEE Transactions on Knowledge and Data Engineering,,,,1–14,2022,,,,,,,,,IEEE Transactions on Knowledge and Data Engineering,,,,,,,,,,,,IEEE Transactions on Knowledge and Data Engineering
6,,zhan_li_li_liu_gupta_kot_2023,"Zhan, Huijing; Li, Ling; Li, Shaohua; Liu, Weide; Gupta, Manas; Kot, Alex C.",Towards Explainable Recommendation Via Bert-Guided Explanation Generator,"International Conference on Acoustics, Speech, and Signal Processing",,,,1–5,2023,,,,,,,,,"International Conference on Acoustics, Speech, and Signal Processing",,,,,,,,,,,,"International Conference on Acoustics, Speech, and Signal Processing"
7,,LI2025110542,"Li, Ying; Li, Ming; Ding, Jin; Bai, Yixue",Two-layer knowledge graph transformer network-based question and answer explainable recommendation,Engineering Applications of Artificial Intelligence,149.0,,,110542,2025,,,https://www.sciencedirect.com/science/article/pii/S0952197625005421,,,,,,,,,,,,,"The question and answer (Q&A) recommendation in community question answering (CQA) helps users quickly and accurately find the desired Q&A. However, existing studies face the problems of sparse interaction data, cold starts, and a lack of explanations. This paper proposes a novel Q&A explainable recommendation approach based on a two-layer knowledge graph transformer network. It alleviates the sparse data and cold start problem by the novel two-layer knowledge graph. First, a two-layer knowledge graph in CQA is constructed. The interaction layer helps to enrich the associations between users and questions and answers (Q&As). The semantic layer provides semantic associations and reflects contextual domain knowledge. Second, a critical meta-path recognition module is constructed to learn the critical meta-paths between users and documents from the interaction layer. Then, a user and Q&A embedding method based on a two-layer knowledge graph is proposed to enhance the user and Q&A representations. Finally, a recommendation and explanation layer is established to obtain personalized Q&A recommendation results and corresponding explanations. Compared with the baselines, the proposed method shows superior performance. It achieves average improvements of 21.28%, 28.41% and 27.18% in precision, recall and F1-measure, respectively, in the top-K Q&A recommendation separately. It improves the area under the curve and F1-measure of the click-through rate prediction recommendation by 11.32% and 23.06%, respectively.",,"Question and answer recommendation, Knowledge graph-based recommendation, Two-layer knowledge graph, Explainable recommendation",,,Engineering Applications of Artificial Intelligence
7,,XIE2021235,"Xie, Jin; Zhu, Fuxi; Li, Xuefei; Huang, Sheng; Liu, Shichao",Attentive preference personalized recommendation with sentence-level explanations,Neurocomputing,426.0,,,235-247,2021,,,https://www.sciencedirect.com/science/article/pii/S0925231220315903,,,,,,,,,,,,,"Personalized recommendation mostly employs users’ historical data to improve their user profiles, and these profiles are then used as the bases for recommendations. Because reviews can contain a large amount of information regarding user preferences and item features, they can be naturally into recommender systems (RSs) as contextual information, thus solving the problem of data sparsity and helping to provide personalized recommendations. The existing technology mainly extracts latent representations of users or items in an independent and static manner. We argue that static embedding cannot fully capture a user's preferences. Indeed, a user will have different preferences corresponding to different items. This type of review-based recommendation model cannot provide a personalized, and complete semantic explanation of a candidate recommendation item to a user. In this paper, we introduce an attention mechanism to explore the importance of specific sentences in reviews for different users and propose a novel attentive preference personalized recommendation with sentence-level explanations (APSE). The APSE employs the latent features of users and items and the latent factors of their pairwise interactions to obtain review representations. Then, the APSE uses probability matrix factorization to model additional high-level feature interactions based on these user-item pairs for rating prediction. We implement review feature learning in the APSE to exploit review data in which an attentive mechanism is used to highlight the influences of words and sentences to achieve focused paragraph embedding. Finally, the APSE also employs an explanation sentence judgment mechanism that implements the user-item pair interaction method to extract comments or statements that pertain to user preferences as recommendation interpretations. Experiments are performed on real-world datasets for validation. Additionally, we show the important words and sentences highlighted by the attentive mechanism. At the end of the experiment, a specific item explanation for a user is produced and compared with the user's existing comments. The results show that the performance of the APSE can exceed that of various recommended models when the available ratings are limited.",,"Explainable recommendation, Review representation, Attentive mechanism",,,Neurocomputing
7,,balloccu_boratto_fenu_marras_2022,"Balloccu, Giacomo; Boratto, Ludovico; Fenu, Gianni; Marras, Mirko",XRecSys: A framework for path reasoning quality in explainable recommendation,Software Impacts,14.0,,,100404,2022,,,,,,,,,Software Impacts,,,,,,,,,,,,Software Impacts
7,,balloccu_boratto_fenu_marras_2023,"Balloccu, Giacomo; Boratto, Ludovico; Fenu, Gianni; Marras, Mirko",Reinforcement recommendation reasoning through knowledge graphs for explanation path quality,Knowledge-Based Systems,260.0,,,110098,2023,,,,,,,,,Knowledge-Based Systems,,,,,,,,,,,,Knowledge-Based Systems
7,,WU2024111133,"Wu, Huiqiong; Guo, Guibing; Yang, Enneng; Luo, Yudong; Chu, Yabo; Jiang, Linying; Wang, Xingwei",PESI: Personalized Explanation recommendation with Sentiment Inconsistency between ratings and reviews,Knowledge-Based Systems,283.0,,,111133,2024,,,https://www.sciencedirect.com/science/article/pii/S0950705123008833,,,,,,,,,,,,,"Explainable recommendations aim to generate personalized explanations for suggested items, which are provided based on the historical interactions (e.g., ratings) between users and items. Review contents are often taken as a proxy of explanations. However, most review-based models presume a sentiment consistency between user ratings and review contents, ignoring their inconsistency in real applications. By analyzing three real datasets, we observe that a user may share a positive (negative) opinion to an item in terms of rating value but a negative (positive) sentiment in terms of review content, and such contradicting scenario takes over 40% of all cases in general. To resolve this issue, in this paper we propose a novel explainable recommendation model called PESI, which can generate accurate Personalized Explanations recommendation with the involvement of Sentiment Inconsistency between ratings and reviews. Specifically, PESI consists of three modules: rating prediction, explanation generation, and a novel rating-review inconsistency extraction. The inconsistency extraction module disentangles ratings and reviews, effectively distinguishing both shared and private features, and ensuring accurate disentanglement through contrastive learning objectives. Then, the extracted inconsistent features are injected into the explanation generation module to provide more personalized and higher-quality explanations. The experimental results on the three datasets show that PESI consistently outperforms other competing methods in terms of explanation quality.",,"Recommendation system, Explanation generation, Sentiment analysis",,,Knowledge-Based Systems
6,9781450336215.0,10.1145/2766462.2767755,"McAuley, Julian; Targett, Christopher; Shi, Qinfeng; van den Hengel, Anton",Image-Based Recommendations on Styles and Substitutes,,,,,43–52,2015,"New York, NY, USA",,https://doi.org/10.1145/2766462.2767755,Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval,,,SIGIR '15,,Association for Computing Machinery,,,,,,,"Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being complementary (such as a pair of jeans and a matching shirt). This information guides many of the choices that people make, from buying clothes to their interactions with each other. We seek here to model this human sense of the relationships between objects based on their appearance. Our approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within. We cast this as a network inference problem defined on graphs of related images, and provide a large-scale dataset for the training and evaluation of the same. The system we develop is capable of recommending which clothes and accessories will go well together (and which will not), amongst a host of other applications.",,"visual features, recommender systems, metric learning",,,International ACM SIGIR Conference on Research and Development in Information Retrieval
6,9781450368599.0,10.1145/3340531.3411992,"Li, Lei; Zhang, Yongfeng; Chen, Li",Generate Neural Template Explanations for Recommendation,,,,,755–764,2020,"New York, NY, USA",,https://doi.org/10.1145/3340531.3411992,Proceedings of the ACM International Conference on Information \& Knowledge Management,,,CIKM '20,,Association for Computing Machinery,,,,,,,"Personalized recommender systems are important to assist user decision-making in the era of information overload. Meanwhile, explanations of the recommendations further help users to better understand the recommended items so as to make informed choices, which gives rise to the importance of explainable recommendation research. Textual sentence-based explanation has been an important form of explanations for recommender systems due to its advantage in communicating rich information to users. However, current approaches to generating sentence explanations are either limited to predefined sentence templates, which restricts the sentence expressiveness, or opt for free-style sentence generation, which makes it difficult for sentence quality control. In an attempt to benefit both sentence expressiveness and quality, we propose a Neural Template (NETE) explanation generation framework, which brings the best of both worlds by learning sentence templates from data and generating template-controlled sentences that comment about specific features. Experimental results on real-world datasets show that NETE consistently outperforms state-of-the-art explanation generation approaches in terms of sentence quality and expressiveness. Further analysis on case study also shows the advantages of NETE on generating diverse and controllable explanations.",,"explainable recommendation, natural language generation, neural template explanation, recommender systems",,,ACM International Conference on Information and Knowledge Management
6,9781450362016.0,10.1145/3292500.3330989,"Wang, Xiang; He, Xiangnan; Cao, Yixin; Liu, Meng; Chua, Tat-Seng",KGAT: Knowledge Graph Attention Network for Recommendation,,,,,950–958,2019,"New York, NY, USA",,https://doi.org/10.1145/3292500.3330989,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining,,,KDD '19,,Association for Computing Machinery,,,,,,,"To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism. We release the codes and datasets at https://github.com/xiangwang1223/knowledge_graph_attention_network.",,"recommendation, knowledge graph, higher-order connectivity, graph neural network, embedding propagation, collaborative filtering",,,ACM SIGKDD Conference on Knowledge Discovery and Data Mining
6,9781450369367.0,10.1145/3351095.3372852,"Zhang, Yunfeng; Liao, Q. Vera; Bellamy, Rachel K. E.",Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making,,,,,295–305,2020,"New York, NY, USA",,https://doi.org/10.1145/3351095.3372852,"Proceedings of the Conference on Fairness, Accountability, and Transparency",,,FAT* '20,,Association for Computing Machinery,,,,,,,"Today, AI is being increasingly used to help human experts make decisions in high-stakes scenarios. In these scenarios, full automation is often undesirable, not only due to the significance of the outcome, but also because human experts can draw on their domain knowledge complementary to the model's to ensure task success. We refer to these scenarios as AI-assisted decision making, where the individual strengths of the human and the AI come together to optimize the joint decision outcome. A key to their success is to appropriately calibrate human trust in the AI on a case-by-case basis; knowing when to trust or distrust the AI allows the human expert to appropriately apply their knowledge, improving decision outcomes in cases where the model is likely to perform poorly. This research conducts a case study of AI-assisted decision making in which humans and AI have comparable performance alone, and explores whether features that reveal case-specific model information can calibrate trust and improve the joint performance of the human and AI. Specifically, we study the effect of showing confidence score and local explanation for a particular prediction. Through two human experiments, we show that confidence score can help calibrate people's trust in an AI model, but trust calibration alone is not sufficient to improve AI-assisted decision making, which may also depend on whether the human can bring in enough unique knowledge to complement the AI's errors. We also highlight the problems in using local explanation for AI-assisted decision making scenarios and invite the research community to explore new approaches to explainability for calibrating human trust in AI.",,"confidence, decision support, explainable AI, trust",,,"Conference on Fairness, Accountability, and Transparency"
6,9781450390965.0,10.1145/3485447.3512031,"Yang, Aobo; Wang, Nan; Cai, Renqin; Deng, Hongbo; Wang, Hongning",Comparative Explanations of Recommendations,,,,,3113–3123,2022,"New York, NY, USA",,https://doi.org/10.1145/3485447.3512031,Proceedings of the ACM Web Conference,,,WWW '22,,Association for Computing Machinery,,,,,,,"As recommendation is essentially a comparative (or ranking) process, a good explanation should illustrate to users why an item is believed to be better than another, i.e., comparative explanations about the recommended items. Ideally, after reading the explanations, a user should reach the same ranking of items as the system’s. Unfortunately, little research attention has yet been paid on such comparative explanations. In this work, we develop an extract-and-refine architecture to explain the relative comparisons among a set of ranked items from a recommender system. For each recommended item, we first extract one sentence from its associated reviews that best suits the desired comparison against a set of reference items. Then this extracted sentence is further articulated with respect to the target user through a generative model to better explain why the item is recommended. We design a new explanation quality metric based on BLEU to guide the end-to-end training of the extraction and refinement components, which avoids generation of generic content. Extensive offline evaluations on two large recommendation benchmark datasets and serious user studies against an array of state-of-the-art explainable recommendation algorithms demonstrate the necessity of comparative explanations and the effectiveness of our solution.",,"comparative explanation, explainable recommendation, extract-and-refine, text generation",,,ACM Web Conference
