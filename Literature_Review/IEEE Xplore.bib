@INPROCEEDINGS{9811151,
  author={Zarzour, Hafed and Alsmirat, Mohammad and Jararweh, Yaser},
  booktitle={2022 13th International Conference on Information and Communication Systems (ICICS)}, 
  title={Using Deep Learning for Positive Reviews Prediction in Explainable Recommendation Systems}, 
  year={2022},
  volume={},
  number={},
  pages={358-362},
  abstract={In the recent years, recommender systems have begun to attract the attention of many online-based companies. While these systems are being developed to provide users with better recommendations, they suffer from the lack of explain-ability. The explainable recommendation systems are developed to solve the problem of why certain products or services are recommended to a particular user. However, less attention has been attracted for predicting positive reviews from the whole data in the context of explainable recommendation. Therefore, in this paper, we focus on developing a model that uses deep learning for predicting positive reviews in explainable recommendation systems. It enables users to get not only intuitive explanations for the recommended items, but also to get more transparency by investigating whether the explanations are positive ones. To evaluate the proposed model, we conduct experiments on a benchmark dataset from Amazon. Experimental results demonstrate the efficacy of the proposed model against the baselines.},
  keywords={Deep learning;Communication systems;Companies;Predictive models;Benchmark testing;Recommender systems;Deep learning;Deep neural network;Recommender system;Explainable recommendation;Machine learning;Prediction model},
  doi={10.1109/ICICS55353.2022.9811151},
  ISSN={2573-3346},
  month={June},}

@INPROCEEDINGS{8622439,
  author={Suzuki, Takafumi and Oyama, Satoshi and Kurihara, Masahito},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data}, 
  year={2018},
  volume={},
  number={},
  pages={3549-3551},
  abstract={Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as "customers who purchased this item also purchased....". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.},
  keywords={Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems},
  doi={10.1109/BigData.2018.8622439},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{10741116,
  author={Tohidi, Nasim and Beheshti, Maedeh},
  booktitle={2024 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Enhanced Explanations in Recommendation Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Recommendation Systems (RSs) play a crucial role in assisting users in making decisions and finding their desired items in various domains, such as movies, music, and hotels. However, their complex algorithms often raise concerns about transparency, fairness, and user trust. To address these challenges, we tried to propose a theoretical approach that combines SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) techniques to enhance the transparency and interpretability of RSs. We present a methodology for applying this approach in the context of movie recommendation, where SHAP values quantify global feature importance, and LIME explanations provide localized insights. This work can contribute to the advancement of transparent and user-centric RSs, with implications for a wide range of applications.},
  keywords={Additives;Filtering;Motion pictures;Modeling;Recommender systems;recommendation system;explainability;interpretability;collaborative filtering},
  doi={10.1109/ISSE63315.2024.10741116},
  ISSN={2687-8828},
  month={Oct},}

@INPROCEEDINGS{10004187,
  author={Xie, Lijie and Jin, Yaqing and Cui, Zhihua and Wang, Lifang},
  booktitle={2022 IEEE International Conference on Networking, Sensing and Control (ICNSC)}, 
  title={Research on Explainable Recommendation Model Based on Knowledge Graph}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to further obtain the best explanation paths and recommendation items that satisfy the preferences of users accurately and efficiently, a many-objective explainable recommendation model GrEA-ERS based on preferences of users is proposed, which designs pruning strategies to delete unsatisfied paths in knowledge graph based on on preferences of users, so as to reduce the search paths. Combined with the many-objective optimization algorithm GrEA, the paths in knowledge graph are used as decision variables, at which different explained paths correspond to different recommended items, and accuracy, diversity, novelty and explainability are optimized to obtain explained paths and their corresponding recommended items. Through extensive experiments, the model GrEA-ERS always outperforms other algorithms in terms of accuracy, novelty, diversity, and explainability.},
  keywords={Knowledge engineering;Semantics;Sensors;Optimization;knowledge graph;recommendation system;explainability;pruning algorithm},
  doi={10.1109/ICNSC55942.2022.10004187},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{9607106,
  author={Vultureanu-Albişi, Alexandra and Bădică, Costin},
  booktitle={2021 25th International Conference on System Theory, Control and Computing (ICSTCC)}, 
  title={Explainable Collaborative Filtering Recommendations Enriched with Contextual Information}, 
  year={2021},
  volume={},
  number={},
  pages={701-706},
  abstract={Today, the most important requirement of intelligent systems is to be able to explain their decisions to the end-user. Fulfilling this requirement is the goal of explainable AI (XAI) that proposes to produce explainable models that enable end-users to understand and trust the models. This research addresses the explainability of the recommendations. This paper presents an explainable recommender system for point of interest recommendations taking into account the context of the user. In our experiments we have used the STS (South Tyrol Suggests) dataset. The following major steps are part of our methodology: i) presenting the dataset, ii) using Restricted Boltzmann Machine based collaborative filtering recommendations, iii) using contextual information, and iv) extracting and presenting explanations for recommendations based on contextual information. The novelty that we propose in explainable recommender systems is a new explainable recommendation technique, which is quantitative and qualitative, providing both the list of top-n recommendations and the explanations of the recommendations based on context. This paper also provides an overview of research on this topic.},
  keywords={Collaborative filtering;Computational modeling;Neural networks;Information filters;Control systems;Data mining;Usability;recommender systems;collaborative filtering;Restricted Boltzmann Machine;contextual information},
  doi={10.1109/ICSTCC52150.2021.9607106},
  ISSN={2372-1618},
  month={Oct},}

@INPROCEEDINGS{9317519,
  author={Farooq Butt, Muhammad Hassan and Li, Jian Ping and Saboor, Tehreem},
  booktitle={2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, 
  title={A Tunable and Explainable Attributes (TEA) for Recommendation System}, 
  year={2020},
  volume={},
  number={},
  pages={39-43},
  abstract={Recommender system in information retrieval systems recommends relevant items to consumers by inspecting the consumer's preferences and objective behaviours. We received recommendations daily regarding what to take in as food, buy, and choices about the wear trends. However, we can understand our recommendations, and even less, we can tune our preferences efficiently. One main concern is those undesired or irrelevant recommendations, not only wasting our time, but they also cost media companies millions of dollars every year. Considering this issue, we proposed a tunable and explainable recommendation system where the attributes that determined the recommendations are explainable and tunable for every individual consumer. Irrelevant recommendations waste the consumer's time and the company's money, but if we put the power of the recommendations in the consumer's hands, we have a win-win situation. The suggested method addresses recommendation algorithms issues, which creates negative feedback loops and allows consumers to be aware of the profile they are building and tune it to see the content that interests them most.},
  keywords={Motion pictures;Measurement;Matrix decomposition;Training;Semantics;Recommender systems;Predictive models;Recommender System;Information Retrieval;Tunable Preferences;Explainable Recommendations},
  doi={10.1109/ICCWAMTIP51612.2020.9317519},
  ISSN={2576-8964},
  month={Dec},}

@INPROCEEDINGS{9260076,
  author={Lonjarret, Corentin and Robardet, Céline and Plantevit, Marc and Auburtin, Roch and Atzmueller, Martin},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Why Should I Trust This Item? Explaining the Recommendations of any Model}, 
  year={2020},
  volume={},
  number={},
  pages={526-535},
  abstract={Explainable AI has received a lot of attention over the past decade, with the proposal of many methods explaining black box classifiers such as neural networks. Despite the ubiquity of recommender systems in the digital world, only few researchers have attempted to explain their functioning, whereas it raises e.g., ethical issues. Indeed, recommender systems direct user choices to a large extent and their impact is important as they give access to only a small part of the range of items (e.g., products and/or services), as the submerged part of the iceberg. Consequently, they limit access to other resources. The potentially negative effects of these systems have been pointed out as phenomena like echo chambers and winner-take-all effects, because the internal logic of these systems is to likely enclose the consumer in a "dej́ a vu" loop. Therefore, it is crucial to provide explanations' of such recommender systems and to identify the user data that led the system to make a specific recommendation. This makes it possible to evaluate recommender systems not only regarding their efficiency (i.e., their capability to recommend an item that was actually chosen by the user), but also w.r.t. the diversity, relevance and timeliness of the active data used to make the recommendation. In this paper, we propose a deep analysis of 7 state-of-the-art models learnt on 6 datasets based on the identification of the items or the sequences of items actively used by the models. The proposed method, which is based on subgroup discovery with different pattern languages (i.e., itemsets and sequences), provides interpretable explanations of the recommendations - useful to compare different models and explain the reasons behind the recommendation to the user.},
  keywords={Recommender systems;History;Data science;Analytical models;Perturbation methods;Numerical models;Machine learning;Recommender systems;Explainable AI;Subgroup discovery},
  doi={10.1109/DSAA49011.2020.00067},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{10776491,
  author={Praseptiawan, Mugi and Muchtarom, M. Fikri Damar and Putri, Nabila Muthia and Pee, Ahmad Naim Che and Zakaria, Mohd Hafiz and Untoro, Meida Cahyo},
  booktitle={2024 11th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Mooc Course Recommendation System Model with Explainable AI (XAI) Using Content Based Filtering Method}, 
  year={2024},
  volume={},
  number={},
  pages={144-147},
  abstract={Massive Open Online Course (MOOC) is a type of online course that has been designed and can be accessed by all individuals via the internet. The problem that is often found in MOOCs is the lack of a recommendation system provided by the algorithm of the MOOC. This research is conducted to analyze a recommendation system that applies the Content Based Filtering approach in order to solve the problems that occur. The recommendation system analyzed will function as a media that provides recommendations to users based on their preferences. By utilizing content-based methods, the recommendations given are expected to be exactly what the user wants. The level of explainability of the recommendation system is further emphasized by XAI using ELI5. By getting a concise explanation when a recommendation is given, the system will gain more trust from users for providing an appropriate recommendation. The assessment of the accuracy of the recommendation system model is measured using MAE. By researching this recommendation system using XAI, it is hoped that it can help future systems to improve the quality of the course recommendation system.},
  keywords={Electrical engineering;Computer science;Computer aided instruction;Electronic learning;Filtering;Explainable AI;Media;Data models;Informatics;Recommender systems;MODC;content-based filtering;XAI;recommender system},
  doi={10.1109/EECSI63442.2024.10776491},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{9005590,
  author={Suzuki, Takafumi and Oyama, Satoshi and Kurihara, Masahito},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)}, 
  title={Explainable Recommendation Using Review Text and a Knowledge Graph}, 
  year={2019},
  volume={},
  number={},
  pages={4638-4643},
  abstract={Recommender systems using a knowledge graph can comprehensively organize users and items and their attributes and thereby improve recommendation performance. In addition, the relationship between users and items can be easily interpreted on the basis of entities and relations, thus giving explanations to recommendations. The algorithms and knowledge graphs used for generating explanations have not utilized review text. We have developed a recommendation method for predicting interactions between users and items using a knowledge graph and review text. The underlying user-item relationships are reflected and explanations are generated by predicting user-item interactions from the paths between a user and an item. The modeling is done using a recurrent neural network or a factorization machine. Items' aspects that interest users are extracted from review text and leveraged using an attention-like mechanism. Since the path between a user and an item can be easily interpreted, and the important aspects between a user and an item can be interpreted by observing the attention weight, the proposed model can generate a reasonable recommendation explanation. Testing using a real-world dataset demonstrated that the proposed model can explain the recommendations.},
  keywords={Big Data;Machine-to-machine communications;Conferences;Recommendation;Knowledge Graph;Explainability;Review text;Recurent Neural Network},
  doi={10.1109/BigData47090.2019.9005590},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{10260804,
  author={Rani, Neha and Qian, Yadi and Chu, Sharon Lynn},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Explanation for User Trust in Context-Aware Recommender Systems for Search-As-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={47-49},
  abstract={Learning through web browsing, often termed Search-as-Learning (SaL), can create information overload, due to thousands of search results. SaL can be made more efficient by developing context-aware tools that recommend items to the user and minimize information overload. However, to use context-aware recommender systems (CARS) users need to trust it. Literature has proposed explanations as a feature that helps to build trust. We investigate the impact of explanation on user trust and user experience for using CARS for SaL. Our study results show that people trust a CARS without explanation more during the first use, but for a CARS with explanations, user trust is significant only after multiple uses. Through interviews, we also uncovered the interesting paradox that even though users do not perceive that explanations add to their learning outcomes, they still prefer to use a CARS with explanations over one without.},
  keywords={User experience;Automobiles;Interviews;Recommender systems;Explanation;Trust;User Experience;Context-Aware Recommender System},
  doi={10.1109/ICALT58122.2023.00019},
  ISSN={2161-377X},
  month={July},}

@INPROCEEDINGS{10683822,
  author={Vultureanu-Albişi, Alexandra and Murareţu, Ionuţ and Bădică, Costin},
  booktitle={2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={A Trustworthy and Explainable AI Recommender System: Job Domain Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Finding a job these days is challenging because of the size, diversity, and goals of the market in a society impacted by pandemics, economic crises, or military hostilities. Trust is the most crucial factor in the job domain after performance expectations. It is particularly significant for women, less active job seekers, and people who did not experience job recommendations. Since recommender systems (RS) are one of the most frequently encountered human-centered and online applications in our daily lives, it is important to note that sound principles of trusting the environment of Artificial Intelligence (AI) systems are also required to characterize the trustworthiness of recommender systems. Otherwise, inadequate advice, high expectations and bad interpretations could lead to making bad choices or to demotivating job seekers. This paper expands on previous research, highlighting the point of view of trustworthiness in job recommender systems (JRS) and providing an overview of the dimensions of AI trustworthiness for the job domain. The purpose of this study is to investigate how trustworthy and suggestive outputs can improve the communication between a job mediator and a job seeker by enhancing the credibility of the information provided to job applicants and increasing customer satisfaction.},
  keywords={Economics;Technological innovation;Pandemics;Explainable AI;Customer satisfaction;Cultural differences;Intelligent systems;job recommender system;trustworthiness;explainability;fairness},
  doi={10.1109/INISTA62901.2024.10683822},
  ISSN={2768-7295},
  month={Sep.},}

@INPROCEEDINGS{9079084,
  author={Zarzour, Hafed and Jararweh, Yaser and Hammad, Mahmoud M. and Al-Smadi, Mohammed},
  booktitle={2020 11th International Conference on Information and Communication Systems (ICICS)}, 
  title={A long short-term memory deep learning framework for explainable recommendation}, 
  year={2020},
  volume={},
  number={},
  pages={233-237},
  abstract={Due to the growing quantity of information available on the Web, recommender systems have become crucial component for the success of online shopping stores. However, most of the existing recommender systems were only designed to improve the recommendation results and ignore the explainable recommendation aspect. Therefore, in this paper we propose a long short-term memory deep learning framework for explainable recommendation, that is able to generate an efficient explanation for any rating made by users for a recommended item. Such a framework would help users to choose a product with confident after reading the automatically generated explanation by our framework. The generated explanation is a concise sentence that shows the reason behind a recommendation, i.e., why a user should select that product. Extensive experiments on a real-world dataset from Amazon are conducted with the goal to evaluate the effectiveness of the proposed method in terms of loss and accuracy metrics. The experimental results demonstrate the effectiveness of our method according to the diversity in generating explainable recommendation.},
  keywords={Deep learning;Measurement;Communication systems;Memory management;Electronic commerce;Recommender systems;long short-term memory (LSTM);deep learning;explainable recommendation;recommender system;machine learning},
  doi={10.1109/ICICS49469.2020.239553},
  ISSN={2573-3346},
  month={April},}

@INPROCEEDINGS{9836983,
  author={Walek, Bogdan and Fajmon, Petr},
  booktitle={2022 3rd International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={A Recommender System for Recommending Suitable Products in E-shop Using Explanations}, 
  year={2022},
  volume={},
  number={},
  pages={16-20},
  abstract={This article proposes a recommender system for recommending relevant products in e-shop using explanations. The proposed system consists of three recommender modules called VIEW, RATING, and PURCHASE. The recommender modules use a content-based filtering approach and a collaborative filtering approach. The proposed recommender system works with explanations that contain arguments why the system recommended the specific product. Based on these explanations the user sees why specific products are recommended by the system. The proposed system was experimentally verified and the results of the experimental verification are discussed.},
  keywords={Filtering;Collaborative filtering;Control systems;Artificial intelligence;Recommender systems;Robots;Testing;recommender system;e-shop recommender system;hybrid recommender system;explanations;content-based filtering;collaborative filtering},
  doi={10.1109/AIRC56195.2022.9836983},
  ISSN={},
  month={May},}

@INPROCEEDINGS{10873804,
  author={Xiaolong, Zhou and Shijiao, Han and Zhenze, Li},
  booktitle={2024 21st International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, 
  title={Explainable Recommendation System Based on Aspect-Based Sentiment Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={At information age, the rapid increase of information caused Information Overload problem, which made recommendation system (RS) come into being and push forward the quick development. Nowadays RS has been widely used in human society. Meanwhile, RS also faces challenges like data sparsity and poor explainability. An effective way to address data sparsity challenge is to exploit content information (like review data) for modeling users and items. By further mining content information, deep relationship between user-item interactions can be uncovered and therefore the explanation for recommendation results can be provided. In order to fully mine the information in review data and make precise recommendation with corresponding explanation, a recommendation model for rating prediction task is proposed in this paper. It exploits aspect-based sentiment analysis related theory to mine review features, incorporates the modeling of user preference and item properties with fine-grained sentiment information, which solves problems that previous model has poor context feature extraction ability and the sentiment analysis results are lack of reliability. Extensive experiments show that this model outperforms baseline models in rating prediction task and can provide explanations for the rating prediction results in view of sentiment.},
  keywords={Analytical models;Sentiment analysis;Reviews;Computational modeling;Predictive models;Feature extraction;Wavelet analysis;Data models;Recommender systems;Context modeling;Recommender system;Review-based recommendation;Aspect-based sentiment analysis;Explainable recommendation},
  doi={10.1109/ICCWAMTIP64812.2024.10873804},
  ISSN={2576-8964},
  month={Dec},}

@INPROCEEDINGS{8594883,
  author={Wang, Xiting and Chen, Yiru and Yang, Jie and Wu, Le and Wu, Zhengtao and Xie, Xing},
  booktitle={2018 IEEE International Conference on Data Mining (ICDM)}, 
  title={A Reinforcement Learning Framework for Explainable Recommendation}, 
  year={2018},
  volume={},
  number={},
  pages={587-596},
  abstract={Explainable recommendation, which provides explanations about why an item is recommended, has attracted increasing attention due to its ability in helping users make better decisions and increasing users' trust in the system. Existing explainable recommendation methods either ignore the working mechanism of the recommendation model or are designed for a specific recommendation model. Moreover, it is difficult for existing methods to ensure the presentation quality of the explanations (e.g., consistency). To solve these problems, we design a reinforcement learning framework for explainable recommendation. Our framework can explain any recommendation model (model-agnostic) and can flexibly control the explanation quality based on the application scenario. To demonstrate the effectiveness of our framework, we show how it can be used for generating sentence-level explanations. Specifically, we instantiate the explanation generator in the framework with a personalized-attention-based neural network. Offline experiments demonstrate that our method can well explain both collaborative filtering methods and deep-learning-based models. Evaluation with human subjects shows that the explanations generated by our method are significantly more useful than the explanations generated by the baselines.},
  keywords={Reinforcement learning;Recommender systems;Quality control;Collaboration;Predictive models;Neural networks;Transforms;Explainable recommendation, reinforcement learning, personalized explanation, attention networks},
  doi={10.1109/ICDM.2018.00074},
  ISSN={2374-8486},
  month={Nov},}

@ARTICLE{10048787,
  author={Yang, Zhe-Rui and He, Zhen-Yu and Wang, Chang-Dong and Lai, Jian-Huang and Tian, Zhihong},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Collaborative Meta-Path Modeling for Explainable Recommendation}, 
  year={2024},
  volume={11},
  number={2},
  pages={1805-1815},
  abstract={Although recommender systems have achieved considerable success, sometimes it is difficult to convince users due to the failure to explain the recommendation results. For this reason, explainable recommender systems have drawn a lot of attention in recent years. Among explainable recommendation models, the meta-path-based model plays a significant role because it can reason over the path connecting a user–item pair to achieve explainability. However, it is difficult for the meta-path-based model to achieve such a common explanation in collaborative filtering as “a user similar to you has purchased item  $A$ ” because there is no such meta-path. In this article, we contribute a new model named collaborative meta-path modeling for explainable recommendation (COMPER). It models the similarity of user pairs and item pairs through rating information and constructs collaborative meta-paths for explainability. In addition, we design an attention mechanism to aggregate different paths connecting the target user and the target item. Moreover, the information of the subgraph composed of all paths connecting the target user and the target item is integrated for rating prediction. Extensive experiments on five real-world datasets demonstrate that COMPER achieves good performance in a variety of scenarios, achieving improvements over several baselines.},
  keywords={Collaborative filtering;Recommender systems;Predictive models;Computational modeling;Deep learning;Correlation coefficient;Recommender systems;Collaborative filtering;explainable recommendation;meta-path},
  doi={10.1109/TCSS.2023.3243939},
  ISSN={2329-924X},
  month={April},}

@INPROCEEDINGS{10446052,
  author={Zhang, Jingsen and Bo, Xiaohe and Wang, Chenxi and Dai, Quanyu and Dong, Zhenhua and Tang, Ruiming and Chen, Xu},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Active Explainable Recommendation with Limited Labeling Budgets}, 
  year={2024},
  volume={},
  number={},
  pages={5375-5379},
  abstract={Explainable recommendation has gained significant attention due to its potential to enhance user trust and system transparency. Previous studies primarily focus on refining model architectures to generate more informative explanations, assuming that the explanation data is sufficient and easy to acquire. However, in practice, obtaining the ground truth for explanations can be costly since individuals may not be inclined to put additional efforts to provide behavior explanations. In this paper, we study a novel problem in the field of explainable recommendation, that is, “given a limited budget to incentivize users to provide behavior explanations, how to effectively collect data such that the downstream models can be better optimized?” To solve this problem, we propose an active learning framework for recommender system, which consists of an acquisition function for sample collection and an explainable recommendation model to provide the final results. We consider both uncertainty and influence based strategies to design the acquisition function, which can determine the sample effectiveness from complementary perspectives. To demonstrate the effectiveness of our framework, we conduct extensive experiments based on real-world datasets.},
  keywords={Uncertainty;Refining;Self-supervised learning;Signal processing;Data models;Speech processing;Recommender systems;Explainable Recommendation;Recommender System;Active learning;Influence Function},
  doi={10.1109/ICASSP48485.2024.10446052},
  ISSN={2379-190X},
  month={April},}

@INPROCEEDINGS{10827288,
  author={Bhatti, Uzair Aslam and Yu, Yang Ke and Mamyrbayev, O.Zh. and Aitkazina, A.A. and Hao, Tang and Zhumazhan, N.O.},
  booktitle={2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Recommendations for Healthcare: An Interpretable Approach Using Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={529-535},
  abstract={This study introduces a novel approach to patient interpretation and diagnosis, utilizing Graph Neural Networks (GNNs) within a collaborative recommendation framework. Our proposed system employs GNN-based collaborative filtering to model complex patient-patient and patient-symptom relationships in a comprehensive graph structure. The system is designed to offer interpretable recommendations, explaining the reasoning behind diagnostic suggestions. The study focused on common chronic conditions in older adults, including high blood pressure, coronary heart disease, diabetes and stroke, as well as fractures, osteoporosis and arthritis. We used a graphical hybrid recommender system (GHRS) and a cooperative graph neural network (GCFNA and GCFYA) to predict hospital disease diagnosis. Encouragingly, both the GCFNA and GCFYA models achieved prediction accuracy rates of over 90%, highlighting the model's excellent performance in accurate predictions. The ultimate goal is to provide precise disease predictions for elderly patients, offer medical guidance, and enhance patient care in hospitals, particularly in managing chronic diseases.},
  keywords={Heart;Osteoporosis;Accuracy;Hospitals;Predictive models;Graph neural networks;Pattern recognition;Older adults;Recommender systems;Medical diagnostic imaging;Hypertension;Coronary heart disease;diabetes mellitus;chronic obstructive pulmonary disease;graph convolutional neural network},
  doi={10.1109/PRAI62207.2024.10827288},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{9482221,
  author={Song, Wei and Wang, Chenglong and Ning, Keqing},
  booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, 
  title={Generate Personalized Explanations for Recommendation based on Keywords}, 
  year={2021},
  volume={4},
  number={},
  pages={51-57},
  abstract={Explainable recommendation refers to providing users with recommended products and explaining to users the reasons for recommending the products. Recommendation explanations can greatly increase users’ trust and satisfaction with the recommender system, and to a certain extent can assist users make decisions efficiently. The current recommendation explanation is mainly templated sentences although this method is simple and easy to understand, it is relatively rigid, lacks flexibility, insufficient service, and requires a lot of manpower and material resources. Inspired by the above questions, by mining user comment information, we propose a method to generate multiple recommendations based on keywords. First, the keywords in the comment information are extracted through STF-IDF, and then the recommendation explanation is generated through the classic network GRU generated by natural language. Experiments show that our proposed method not only has better recommendation accuracy but is also has a higher quality of recommended interpretation compared to classic methods},
  keywords={Automation;Conferences;Natural languages;Information management;Data mining;Recommender systems;recommender systems;explainable recommendation;natural language generation;keyword extraction},
  doi={10.1109/IMCEC51613.2021.9482221},
  ISSN={2693-2776},
  month={June},}

@INPROCEEDINGS{10658914,
  author={Chun, Hong Wei and Ong, Rongqing Kenneth and Khong, Andy W. H.},
  booktitle={2024 IEEE 67th International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
  title={Reasonable Sense of Direction: Making Course Recommendations Understandable with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1408-1412},
  abstract={Course recommendation systems play an essential role in academic institutions for students to find courses that align with their interests and graduation requirements. However, due to their “black-box” nature, recommendation systems often lack transparency and interpretability, leading to challenges in trust and usability. Our proposed framework leverages Large Language Models (LLMs) to generate clear, human-readable explanations based on course content by drawing connections between the existing courses taken by the student and recommended courses.},
  keywords={Circuits and systems;Large language models;Closed box;Cognition;Usability;Integrated circuit modeling;Recommender systems;Course Recommendation Systems;Educational Technology;Large Language Models},
  doi={10.1109/MWSCAS60917.2024.10658914},
  ISSN={1558-3899},
  month={Aug},}

@INPROCEEDINGS{10334552,
  author={Chen, Zhanghui and Ai, Xinbo and Guo, Yanjun and Huang, Yitian and Yang, Jing},
  booktitle={2023 IEEE 11th International Conference on Computer Science and Network Technology (ICCSNT)}, 
  title={Explainable Recommendation for Hazard Inspection Reasoning Through Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={37-42},
  abstract={In the process of hazards inspecting in safety production, the number and types of hazard entities are often vast and varied. Introducing of existing recommendation algorithms may lead to low recommendation quality and lack of explain ability. To address these challenges, achieving dual improvement in accuracy and reliability of hazard inspection recommendations. We propose three metrics that represent the explanation quality of recommendation results: Inspection Recency of Hazard, Risk Level of Entity and Utilization Rate of Graph. And then we propose two optimization methods on model inner-training and post-training: Pruning-Strategy Optimization and Re-Rank Optimization. In hazards inspection dataset of safety production, hazard inspection recommendation NDCG@10 reaches 0.433(5.1 % higher than baseline) and overall path explanation metric scores reaches 1.928(74.8% higher than baseline). Compared with previous algorithms, our methods achieve higher recommendation performance and explainability quality.},
  keywords={Measurement;Computer science;Law enforcement;Optimization methods;Production;Knowledge graphs;Inspection;recommendation system;hazard inspection;ex- plainability},
  doi={10.1109/ICCSNT58790.2023.10334552},
  ISSN={2690-5892},
  month={Oct},}

@INPROCEEDINGS{10825771,
  author={Turgut, Özlem and Kök, İbrahim and Özdemir, Suat},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={AgroXAI: Explainable AI-Driven Crop Recommendation System for Agriculture 4.0}, 
  year={2024},
  volume={},
  number={},
  pages={7208-7217},
  abstract={Today, crop diversification in agriculture is a critical issue to meet the increasing demand for food and to improve food safety and quality. This issue is considered to be the most important challenge for the next generation of agriculture due to diminishing natural resources, limited arable land and unpredictable climatic conditions caused by climate change. In this paper, we employ emerging technologies such as the Internet of Things (IoT), machine learning (ML) and explainable artificial intelligence (XAI) to improve operational efficiency and productivity in the agricultural sector. Specifically, we propose an edge computing-based explainable crop recommendation system, AgroXAI, which suggests suitable crops for a region based on weather and soil conditions. In this system, we provide local and global explanations of ML model decisions with methods such as ELI5, LIME, SHAP, which we integrate into ML models. More importantly, we provide regional alternative crop recommendations with the Counterfactual explainability method. In this way, we envision that our proposed AgroXAI system will be a platform that provides regional crop diversity in the next generation agriculture.},
  keywords={Productivity;Explainable AI;Computational modeling;Crops;Soil;Agriculture;Internet of Things;Sustainable development;Recommender systems;Next generation networking;Explainable Artificial Intelligence (XAI);Agriculture 4.0;Internet of Things;edge computing;crop recommendation},
  doi={10.1109/BigData62323.2024.10825771},
  ISSN={2573-2978},
  month={Dec},}

@INPROCEEDINGS{10308154,
  author={Das, Samiran and Chatterjee, Sujoy},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Explainable Machine Learning for Crop Recommendation from Agriculture Sensor Data- a New Paradigm}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The dwindling agricultural earnings and decrease in crop yield in recent years due to improper crop selection and fluctuation/ uncertainty in weather necessitate proper machine learning-based analysis. Machine learning methods can potentially alleviate the predicament caused by the lack of appropriate soil testing, consultation, and bias in manual suggestion. This work attempted to comprehend the agricultural sensor data and weather conditions and formulated the task in terms of supervised classification. The work obtained accurate suggestions in the presence of missing data, noise, etc. by using advanced machine learning methods. But recommendation alone is insufficient to convince farmers and other stakeholders to adopt this approach. Hence, this paper introduced explainable machine learning to completely comprehend the decision-making process. This work quantified the importance of features, explained individual prediction outcomes, and uncovered the rationale for decisions. The work employed state-of-the-art local interpretable model-agnostic, post-hoc explanation methods to provide in-depth insights. The insights obtained from the explanations can help the farmers develop a knowledge base and assist the farmers in choosing the appropriate sensors for the task. The human interpretable analysis enables the farmers to obtain satisfactory yields in these ever-changing and extreme weather conditions and environmental degradation.},
  keywords={Uncertainty;Pollution control;Machine learning;Soil;Pollution measurement;Stakeholders;Resource management;Agricultural data analytics;Sensor data;Crop recommendation;Explainable machine learning},
  doi={10.1109/ICCCNT56998.2023.10308154},
  ISSN={2473-7674},
  month={July},}

@Comment{jabref-meta: databaseType:bibtex;}
